\documentclass[../../../main_math.tex]{subfiles}

% posar Bautin theoremW
\begin{document}
\changecolor{DS}
\begin{multicols}{2}[\section{Dynamical systems}]
  \subsection{Dynamical systems in Euclidean spaces}
  \subsubsection{Introduction}
  \begin{definition}
    Let $(X,G,\Pi)$ be a dynamical system. In the continuous case, we say that $x\in X$ is an \emph{equilibrium point} if $\Pi(x,t)=x$ $\forall t\in G$. In the discrete case, a point $x\in X$ satisfying this property is called a \emph{fixed point}.
  \end{definition}
  \begin{definition}
    Let $(X,G,\Pi)$ be a dynamical system. A \emph{periodic orbit of period $T$} is an orbit of the system that satisfies $\Pi(x,t+T)=\Pi(x,t)$ $\forall t\in G$ and for some $x\in X$.
  \end{definition}
  \begin{theorem}
    Let $(X,G,\Pi)$ be a dynamical system and $\gamma_x$ be an orbit. Then, there are 3 possible cases for $\gamma_x$.

    In the continuous case:
    \begin{enumerate}
      \item $\gamma_x$ is an equilibrium point.
      \item $\gamma_x$ is a periodic orbit.
      \item $\gamma_x\cong\RR$.
    \end{enumerate}
    In the discrete case:
    \begin{enumerate}
      \item $\gamma_x$ is a fixed point.
      \item $\gamma_x$ is a periodic orbit.
      \item $\gamma_x\cong\ZZ$.
    \end{enumerate}
  \end{theorem}
  \begin{theorem}
    Let $(X,\ZZ_{\geq 0},\Pi)$ be a discrete semidynamical system and $\gamma_x$ be an orbit. Then, apart form the above possibilities the orbit can also be of the form:
    \begin{enumerate}
      \item $\gamma_x=\{x_1,\ldots,x_{n-1},x_n,x_n,x_n,x_n,\ldots\}$
      \item $\gamma_x=\{x_1,\ldots,x_{n-1},x_n,\ldots,x_{n+T},x_n,\ldots,x_{n+T},\ldots\}$
    \end{enumerate}
  \end{theorem}
  \begin{definition}
    Let $f,g:\RR^2\rightarrow\RR$ be two functions and consider the system ofODEs:
    \begin{equation}\label{DS:plane}
      \left\{
      \begin{aligned}
        x' & =p(x,y) \\
        y' & =q(x,y)
      \end{aligned}
      \right.
    \end{equation}
    We say that the system is \emph{symmetric with respect to the $x$-axis} if it is invariant under the transformation $(x,y,t)\rightarrow(-x,y,-t)$. Analogously, we say that the system is \emph{symmetric with respect to the $y$-axis} if it is invariant under the transformation $(x,y,t)\rightarrow(x,-y,-t)$.
  \end{definition}
  \begin{theorem}
    Consider the system \mcref{DS:plane} and suppose that the origin is an equilibrium point. If the system is symmetric with respect to the $x$-axis or $y$-axis, and if the origin is a center of the linear part of the system, then the origin is a center of the nonlinear system \mcref{DS:plane}.
  \end{theorem}
  \begin{theorem}
    Consider the differential system in $\CC$ defined by:
    $$z'=\ii z+ a_2z^2+a_3z^3+\cdots=:\ii z+f(z)$$ This is a \emph{holomorphic differential equation}. Then, there exists a conjugaction that conjugates this system with $z'=\ii z$. This process of finding the conjugacy is called \emph{linearization} of the first system. In particular, the periods of the periodic orbits are always the same.
  \end{theorem}
  \begin{theorem}
    Consider the differential system
    $$
      \left\{
      \begin{aligned}
        {x}' & = \lambda x+ p(x,y) \\
        {y}' & = \mu y+ q(x,y)
      \end{aligned}
      \right.
    $$
    where $p,q\in\RR[x,y]$ and $\deg p,\deg q\geq 2$. If $\frac{\lambda}{\mu}\notin\QQ$, then there exists a conjugacy of class $\mathcal{C}^\omega$ between them.
  \end{theorem}
  \begin{definition}
    Let $(X,G,\Pi)$ be a dynamical system and $A\subseteq \RR^n$ be an invariant subset. We say that $A$ is \emph{minimal} if it doesn't contain any proper invariant subset.
  \end{definition}
  \begin{definition}
    A \emph{Kolmogorov system} is a dynamical system of the form:
    \begin{equation}
      \left\{
      \begin{aligned}
        {x_1}' & =x_1 f_1(\vf{x}) \\
               & \;\;\vdots       \\
        {x_n}' & =x_n f_n(\vf{x})
      \end{aligned}
      \right.
    \end{equation}
  \end{definition}
  \subsubsection{Homogeneous systems}
  \begin{definition}
    We say that function $f:\RR^n\rightarrow\RR$ is \emph{homogeneous of degree $k$} if $\forall\lambda\in\RR$ we have:
    $$f(\lambda x_1,\ldots,\lambda x_n)=\lambda^k f(x_1,\ldots,x_n)$$
  \end{definition}
  \begin{definition}
    We say that differential system $\vf{x}'=\vf{f}(\vf{x})$ is \emph{homogeneous of degree $k$} if the components of $\vf{f}$ are homogeneous functions of degree $k$. That is, if $\vf{f}(\lambda \vf{x})=\lambda^k\vf{f}(\vf{x})$ $\forall \lambda\in \RR$.
  \end{definition}
  \begin{proposition}
    The study of the global dynamics of a homogeneous system with only one equilibrium point (at the origin) is the same as the study of local dynamics at the origin.
  \end{proposition}
  \subsubsection{Poincaré map}
  \begin{proposition}
    Let $\vf{f}\in\mathcal{C}^1(\RR^2)$, $\vf{x}'=\vf{f}(\vf{x})$ be a planar differential system and $\Sigma\subset \RR^2$ be a transversal section. Then, the Poincaré map $\vf\Pi:\Sigma\rightarrow\Sigma$ is monotone.
  \end{proposition}
  \begin{proposition}
    Let $\vf{f}\in\mathcal{C}^k(\RR^n)$, $\vf{x}'=\vf{f}(\vf{x})$ be a differential system and $\Sigma\subset \RR^k$ be a transversal section. Then, $\vf\Pi\in\mathcal{C}^k(\RR^n)$.
  \end{proposition}
  \subsubsection{Discrete maps}
  \begin{definition}
    A \emph{discrete map of order $m$} is a recurrence of the form:
    \begin{equation}
      f(n,x_n,x_{n+1},\ldots,x_{n+m})=0
    \end{equation}
    where $f:\RR^{m+1}\rightarrow\RR^m$ is a function. Sometimes we will be able to express it in its explicit form as:
    \begin{equation}\label{DS:discretemap}
      x_{n+m}=f(x_n,x_{n+1},\ldots,x_{n+m-1})
    \end{equation}
  \end{definition}
  \begin{proposition}
    Let $f:\RR^{m}\rightarrow\RR^m$ be a function. Consider a discrete map of \mcref{DS:discretemap}. Then, we can transform this map into a map of order 1 of $m$ equations:
    \begin{equation*}
      \left\{
      \begin{aligned}
        {(y_1)}_{n+1}     & ={(y_2)}_{n}                                   \\
        {(y_2)}_{n+1}     & ={(y_3)}_{n}                                   \\
                          & \;\;\vdots                                     \\
        {(y_{m-1})}_{n+1} & ={(y_m)}_{n}                                   \\
        {(y_m)}_{n+1}     & =f(n,{(y_1)}_n,{(y_2)}_n,\ldots,{(y_{m-1})}_n) \\
      \end{aligned}
      \right.
    \end{equation*}
    where ${(y_i)}_n=x_{n+i-1}$ for $i=1,\ldots,m$.
  \end{proposition}
  \begin{proposition}
    Let $\vf{f}:\RR^m\rightarrow\RR^m$ be an invertible function and consider the discrete map of \mcref{DS:discretemap}. Then, $\Pi(\vf{x},n):=\vf{f}^n(\vf{x})$ defines a discrete dynamical system.
  \end{proposition}
  \begin{proposition}[Characteristic equation]
    Consider the following \emph{linear discrete map}:
    \begin{equation*}
      x_{n+m}+a_{m-1}x_{n+m-1} + \cdots + a_1 x_{n+1} + a_0 x_n = 0
    \end{equation*}
    Let:
    $$p(y):=y^m + a_{m-1}y^{m-1} + \cdots + a_1 y + a_0 = 0$$
    Suppose $p$ has $r$ distinct real roots and $2(s-r)$ distinct complex roots.
    $$\lambda_1,\ldots,\lambda_r,\lambda_{r+1},\overline{\lambda_{r+1}},\ldots,\lambda_{s},\overline{\lambda_s}$$
    Here, $\lambda_i\in\RR$ $\forall i=1,\ldots,r$ and $\lambda_{i}=\alpha_i+\ii\beta_i\in\CC$ $\forall i=r+1,\ldots,s$. Assume, each of these roots have multiplicity $k_i\in\NN$. Then, the general solution to that discrete map is:
    \begin{multline*}
      \vf{x}_n=\sum_{i=1}^r\left(c_{i,0}+c_{i,1}n+\cdots+c_{i,k_i-1}n^{k_i-1}\right){\lambda_i}^n+\\
      +\sum_{i=r+1}^s\sum_{j=0}^{k_i-1}n^{j}{\rho_i}^n\left(c_{i,j,1}\cos(\theta_i n)+c_{i,j,2}\sin(\theta_i n)\right)
    \end{multline*}
    where $c_{i,j,k}\in\RR$ are constants and $\lambda_i=\rho_i\exp{\ii\theta_i}$.
  \end{proposition}
  \begin{proposition}
    Consider the discrete map $$\vf{x}_{n+1}=\vf{f}(\vf{x}_n)$$
    and let $\vf{p}$ be a fixed point of $\vf{f}$.
    \begin{itemize}
      \item If $\forall \lambda\in\sigma(\vf{Df}(\vf{p}))$ we have $\abs{\lambda}<1$, then $\vf{p}$ is asymptotically stable.
      \item If $\forall \lambda\in\sigma(\vf{Df}(\vf{p}))$ we have $\abs{\lambda}>1$, then $\vf{p}$ is repelling and negatively stable.
      \item If $\vf{p}$ is positively stable, then $\abs{\lambda}\leq 1$ $\forall\lambda\in\sigma(\vf{Df}(\vf{p}))$.
      \item If $\vf{p}$ is negatively stable, then $\abs{\lambda}\geq 1$ $\forall\lambda\in\sigma(\vf{Df}(\vf{p}))$.
    \end{itemize}
  \end{proposition}
  \begin{theorem}[Hartman-Grobman theorem]
    Consider the discrete map $$\vf{x}_{n+1}=\vf{f}(\vf{x}_n)$$ where $\vf{f}:\RR^2\rightarrow\RR^2$. Let $\vf{p}\in U$ be a fixed point of $\vf{f}$ and suppose $\sigma(\vf{Df}(\vf{p}))=\{\lambda_1,\lambda_2\}$. Then, $\vf{p}$ will be a
    \begin{itemize}
      \item {stable node} if $\lambda_1,\lambda_2\in\RR$ and $\abs{\lambda_1},\abs{\lambda_2}<1$.
      \item {unstable node} if $\lambda_1,\lambda_2\in\RR$ and $\abs{\lambda_1},\abs{\lambda_2}>1$.
      \item {saddle point} if $\lambda_1,\lambda_2\in\RR$ and $\abs{\lambda_1}<1$ and $\abs{\lambda_2}>1$ (or viceversa).
      \item {stable focus} if $\lambda_1,\lambda_2\in\CC$ and $\abs{\lambda_1}<1$.
      \item {unstable focus} if $\lambda_1,\lambda_2\in\CC$ and $\abs{\lambda_1}>1$.
    \end{itemize}
  \end{theorem}
  \subsection{Study of local dynamics}
  \subsubsection{Stable manifold and center manifold theorems}
  \begin{theorem}[The stable manifold theorem]
    Let $E\subseteq\RR^n$ be an open subset containing the origin, $\vf{f}\in\mathcal{C}^1(E)$ and $\vf\phi_t$ be the flow of the following system of $n$ equations:
    \begin{equation}\label{DS:general}
      \vf{x}' =\vf{f}(\vf{x})
    \end{equation}
    Suppose that $\vf{f}(\vf{0})=\vf{0}$ and that $\vf{Df}(\vf{0})$ has $n_+$ eigenvalues with positive real part and $n_-=n-n_+$ eigenvalues with negative real part. Then, there exists a unique $n_+$-dimensional differentiable manifold $S$ tangent to the stable eigenspace $E^\text{s}$ of the linear system at $\vf{0}$ such that $\forall t\geq 0$, $\vf\phi_t(S)\subseteq S$ and $\forall \vf{x}_0\in S$: $$\lim_{t\to\infty}\vf\phi_t(\vf{x}_0)=\vf{0}$$
    This manifold is called \emph{stable manifold}.
    Analogously, there exists a unique $n_-$-dimensional differentiable manifold $U$ tangent to the stable eigenspace $E^\text{u}$ of the linear system at $\vf{0}$ such that $\forall t\leq 0$, $\vf\phi_t(U)\subseteq U$ and $\forall \vf{x}_0\in U$: $$\lim_{t\to-\infty}\vf\phi_t(\vf{x}_0)=\vf{0}$$
    This manifold is called \emph{unstable manifold}.
  \end{theorem}
  \begin{definition}
    Let $E\subseteq\RR^n$ be an open subset containing the origin, $\vf{f}\in\mathcal{C}^1(E)$ and $\vf\phi_t$ be the flow of the system of \mcref{DS:general}. The \emph{global stable manifold} and \emph{global unstable manifold} at $\vf{0}$ are defined respectively by:
    $$W^\text{s}(\vf{0})=\bigcup_{t\leq 0}\vf\phi_t(S)\qquad W^\text{u}(\vf{0})=\bigcup_{t\geq 0}\vf\phi_t(U)$$
  \end{definition}
  \begin{proposition}
    Let $E\subseteq\RR^n$ be an open subset containing the origin, $\vf{f}\in\mathcal{C}^1(E)$ and $\vf\phi_t$ be the flow of the system of \mcref{DS:general}. Then, the manifolds $W^\text{s}$ and $W^\text{u}$ are unique and invariant with respect to the flow $\vf\phi_t$
  \end{proposition}
  \begin{theorem}[The center manifold theorem]
    Let $E\subseteq\RR^n$ be an open subset containing the origin, $\vf{f}\in\mathcal{C}^r(E)$, $r\geq 1$ and consider the system of \mcref{DS:general}. Suppose that $\vf{f}(\vf{0})=\vf{0}$ and that $\vf{Df}(\vf{0})$ has $n_+$ eigenvalues with positive real part, $n_-$ eigenvalues with negative real part and $n_0=n-n_+-n_-$ eigenvalues with zero real part. Then, there exists a $n_0$-dimensional differentiable manifold $W^\text{c}$ (called \emph{central manifolds}) of class $\mathcal{C}^{r-1}$ tangent to the center eigenspace $E^\text{c}$ of the linear system at $\vf{0}$; there exists a $n_+$-dimensional differentiable manifold $S$ tangent to the stable eigenspace $E^\text{s}$ of the linear system at $\vf{0}$, and there exists a $n_-$-dimensional differentiable manifold $U$ tangent to the stable eigenspace $E^\text{u}$ of the linear system at $\vf{0}$. Furthermore, $W^\text{c}$, $W^\text{s}$ and $W^\text{u}$ are invariant under the flow $\vf\phi_t$. If moreover, $\vf{f}\in\mathcal{C}^\omega(E)$, the the manifold $W^\text{c}$ is also of class $\mathcal{C}^{\omega}$ and it is unique\footnote{Unique in the sense that there is no other manifold of class $\mathcal{C}^{\omega}$ tangent to $E^\text{c}$ at $\vf{0}$ but it may be other manifolds of class $\mathcal{C}^{r}$, $r\in\NN\cup\{\infty\}$, satisfying this property.}.
  \end{theorem}
  \subsubsection{Local bifurcation theory}
  \begin{definition}
    A \emph{local bifurcation} on a differential systems
    \begin{equation}\label{DS:mu-system}
      \vf{x}'=\vf{f}(\vf{x},\vf\mu)
    \end{equation}
    is the study of the changes in the local stability properties of equilibrium points, periodic orbits or other invariant sets as the parameter $\vf\mu$ cross through critical thresholds.
  \end{definition}
  \begin{definition}
    The \emph{normal form} of a dynamical system is a simplified form that can be useful in determining the system's behavior.
  \end{definition}
  \begin{definition}
    The \emph{codimension} of a bifurcation is the number of parameters which must be varied for the bifurcation to occur.
  \end{definition}
  \begin{definition}[Saddle-node bifurcation]
    The normal form of the codimension-one \emph{saddle-node bifurcation} is: $$x'=\mu+x^2$$
    \mcref{DS:sn} shows the qualitative behavior of that system\footnote{In these images, the red lies means that the point $(\mu,x)$ is repelling. The blue lines means that the point $(\mu,x)$ is attracting.}.
  \end{definition}
  \begin{definition}[Transcritical bifurcation]
    The normal form of the codimension-one \emph{transcritical bifurcation} is: $$x'=\mu x+x^2$$
    \mcref{DS:trans} shows a qualitative behavior of the stability of the equilibria.
  \end{definition}
  \begin{definition}[Pitchfork bifurcation]
    The normal form of the codimension-one \emph{pitchfork bifurcation} is: $$x'=\mu x+x^3$$
    \mcref{DS:fork} shows a qualitative behavior of the stability of the equilibria.
  \end{definition}
  \begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.32\linewidth}
      \centering
      \includestandalone[mode=image|tex,width=\linewidth]{Images/sn-bif}
      \caption{Saddle-node}
      \label{DS:sn}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.32\linewidth}
      \centering
      \includestandalone[mode=image|tex,width=\linewidth]{Images/trans-bif}
      \caption{Transcritical}
      \label{DS:trans}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.32\linewidth}
      \centering
      \includestandalone[mode=image|tex,width=\linewidth]{Images/fork-bif}
      \caption{Pitchfork}
      \label{DS:fork}
    \end{subfigure}
    \caption{Bifurcation diagrams of the principal bifurcations in 1-dimensional systems}
  \end{figure}
  \begin{theorem}
    Consider the system of \mcref{DS:mu-system}. Then, it will have a saddle-node bifurcation at the origin if $\vf{f}(0,0)=0$, $\vf{f}_x(0,0)=0$, $\vf{f}_{xx}(0,0)\ne 0$ and $\vf{f}_\mu(0,0)\ne0$.
  \end{theorem}
  \begin{theorem}
    Consider the system of \mcref{DS:mu-system}. Then, it will have a transcritical bifurcation at the origin if $\vf{f}(0,0)=0$, $\vf{f}_x(0,0)=0$, $\vf{f}_{xx}(0,0)\ne 0$, $\vf{f}_\mu(0,0)=0$ and $\vf{f}_{x\mu}(0,0)\ne 0$.
  \end{theorem}
  \begin{theorem}
    Consider the system of \mcref{DS:mu-system}. Then, it will have a pitchfork bifurcation at the origin if $\vf{f}(0,0)=0$, $\vf{f}_x(0,0)=0$, $\vf{f}_{xx}(0,0)=0$, $\vf{f}_{xxx}(0,0)\ne 0$, $\vf{f}_\mu(0,0)=0$ and $\vf{f}_{x\mu}(0,0)\ne 0$.
  \end{theorem}
  \subsubsection{Non-hyperbolic equilibrium points}
  \begin{theorem}[Lyapunov's theorem]
    Let $U\subseteq \RR^n$ be an open set and $\vf{f}:U\rightarrow\RR^n$ be a vector field of class $\mathcal{C}^1$ and $\vf{p}\in U$ be a critical point of $\vf{f}$. Suppose there exists a function $V:U\rightarrow\RR$ of class $\mathcal{C}^1$ and a neighbourhood $\tilde{U}\subseteq U$ of $\vf{p}$ such that $V(\vf{p})=0$ and $V(\vf{x})>0$ $\forall \vf{x}\in\tilde{U}\setminus\{\vf{p}\}$. Then:
    \begin{itemize}
      \item If $V'(\vf{q})\leq 0$ $\forall \vf{q}\in \tilde{U}$, then $\vf{p}$ is stable.
      \item If $V'(\vf{q})< 0$ $\forall \vf{q}\in \tilde{U}$, then $\vf{p}$ is asymptotically stable.
      \item If $V'(\vf{q})\leq 0$ $\forall \vf{q}\in \tilde{U}$ and $\omega(\tilde{U})=\{\vf{p}\}$, then $\vf{p}$ is asymptotically stable.
      \item If $V'(\vf{q})> 0$ $\forall \vf{q}\in \tilde{U}$, then $\vf{p}$ is unstable.
    \end{itemize}
  \end{theorem}
  \begin{theorem}[Lyapunov's theorem]
    Let $U\subseteq \RR^n$ be an open set, $\vf{f}:U\rightarrow\RR^n$ be a continuous function and consider the iteration $\vf{x}_{n+1}=\vf{f}(\vf{x}_n)$. Let $\vf{p}\in U$ be a fixed point of $\vf{f}$. Suppose there exists a continuous function $V:U\rightarrow\RR$ and a neighbourhood $\tilde{U}\subseteq U$ of $\vf{p}$ such that $V(\vf{p})=0$ and $V(\vf{x})>0$ $\forall \vf{x}\in\tilde{U}\setminus\{\vf{p}\}$. Then:
    \begin{itemize}
      \item If $V(\vf{x}_{n+1})-V(\vf{x}_{n})\leq 0$ $\forall \vf{x}_{n}\in \tilde{U}$, then $\vf{p}$ is stable.
      \item If $V(\vf{x}_{n+1})-V(\vf{x}_{n})< 0$ $\forall  \vf{x}_{n}\in \tilde{U}$, then $\vf{p}$ is asymptotically stable.
    \end{itemize}
  \end{theorem}
  \begin{theorem}[Semi-hyperbolic singular points classification theorem]\label{DS:thmA}
    Consider the differential system
    $$
      \left\{
      \begin{aligned}
        {x}' & = X(x,y)    \\
        {y}' & = y+ Y(x,y)
      \end{aligned}
      \right.
    $$
    where $X,Y\in\mathcal{C}^\omega$ have order $\geq 2$ in their Taylor's series. Hence, the differential of the system at the origin is:
    $$\begin{pmatrix}
        0 & 0 \\
        0 & 1
      \end{pmatrix}$$ Suppose the origin is an equilibrium point, let $y=f(x)$ the solution to the equation $y+Y(x,y)=0$ given by the implicit function theorem and $g(x)=X(x,f(x))=a_mx^m+\O{x^{m+1}}$, where $a_m\ne 0$ and $m\geq 2$. Then:
    \begin{enumerate}
      \item If $m$ is odd and $a_m>0$, the origin is a repelling node.
      \item If $m$ is odd and $a_m<0$, the origin is a saddle.
      \item If $m$ is even, the origin is a \emph{saddle-node} (See \mcref{DS:meven}).
    \end{enumerate}
    \begin{figure}[H]
      \centering
      \begin{subfigure}[b]{0.45\linewidth}
        \centering
        \includestandalone[mode=image|tex,width=\linewidth]{Images/saddle-node_neg}
        \caption{$a_m<0$}
      \end{subfigure}
      \hfill
      \begin{subfigure}[b]{0.45\linewidth}
        \centering
        \includestandalone[mode=image|tex,width=\linewidth]{Images/saddle-node_pos}
        \caption{$a_m>0$}
      \end{subfigure}
      \caption{Local phase portraits of the saddle-node system when $m$ is even.}
      \label{DS:meven}
    \end{figure}
  \end{theorem}
  \begin{definition}
    A singular point of a differential system is called \emph{nilpotent} if the differential at this point is nilpotent.
  \end{definition}
  \begin{theorem}[Nilpotent singular points classification theorem]\label{DS:thmB}
    Consider the differential system
    $$
      \left\{
      \begin{aligned}
        {x}' & = y + X(x,y) \\
        {y}' & = Y(x,y)
      \end{aligned}
      \right.
    $$
    where $X,Y\in\mathcal{C}^\omega$ have order $\geq 2$ in their Taylor's series. Hence, the differential of the system at the origin is:
    $$\begin{pmatrix}
        0 & 1 \\
        0 & 0
      \end{pmatrix}$$
    Suppose the origin is an equilibrium point, let $y=f(x)$ the solution to the equation $y+X(x,y)=0$ given by the implicit function theorem and $g(x)=Y(x,f(x))$. Moreover, define $\Phi(x)=\div(X,Y)(x,f(x))$. Then:
    \begin{enumerate}
      \renewcommand{\crefpairconjunction}{ or~}
      \item If $g(x)=\Phi(x)= 0$, the phase portrait at the origin is given by \mcref{DS:nilpot-a}.
      \item If $g(x)=0$ and $\Phi(x)=bx^n +\O{x^{n+1}}$ with $n\geq 1$ and $b\ne 0$, then the phase portrait at the origin is given by \mcref{DS:nilpot-b,DS:nilpot-c}.
      \item If $\Phi(x)=0$ and $g(x)=ax^m +\O{x^{m+1}}$ with $m\geq 2$ and $a\ne 0$, then:
            \begin{enumerate}
              \item If $m$ is odd and
                    \begin{enumerate}
                      \item $a>0$, the origin is a saddle (\mcref{DS:nilpot-d}).
                      \item $a<0$, the origin is a center or a focus (\mcref{DS:nilpot-e,DS:nilpot-f,DS:nilpot-g}).
                    \end{enumerate}
              \item If $m$ is even, the origin is a \emph{cusp} (it consists of two hyperbolic sectors, \mcref{DS:nilpot-h}).
            \end{enumerate}
      \item If $g(x)=ax^m +\O{x^{m+1}}$ and $\Phi(x)=bx^n +\O{x^{n+1}}$ with $m\geq 2$, $n\geq 1$ and $a,b\ne 0$, then:
            \begin{enumerate}
              \item If $m$ is even and
                    \begin{enumerate}
                      \item $m >2n + 1$, the origin is a saddle-node (\mcref{DS:nilpot-i,DS:nilpot-j}).
                      \item $m <2n + 1$, the origin is a cusp (\mcref{DS:nilpot-h}).
                    \end{enumerate}
              \item If $m$ is odd and $a >0$, the origin is a saddle (\mcref{DS:nilpot-d}).
              \item If $m$ is odd, $a <0$ and
                    \begin{enumerate}
                      \item $n$ is even and either $m >2n + 1$, or  $m =2n + 1$ and $b^2+4a(n +1)\geq 0$,, then the origin is a node. The node is attracting if $b<0$ (\mcref{DS:nilpot-m}) and repelling if $b>0$ (\mcref{DS:nilpot-l}).
                      \item $n$ is odd and either $m >2n + 1$, or  $m =2n + 1$ and $b^2+4a(n +1)\geq 0$, then the origin consists of an elliptic sector and a hyperbolic sector (\mcref{DS:nilpot-k}).
                      \item either $m <2n + 1$, or  $m =2n + 1$ and $b^2+4a(n +1)< 0$, then the origin is a center or a focus (\mcref{DS:nilpot-e,DS:nilpot-f,DS:nilpot-g}).
                    \end{enumerate}
            \end{enumerate}
    \end{enumerate}
    \begin{figure}[H]
      \centering
      \begin{subfigure}[b]{0.3\linewidth}
        \centering
        \includestandalone[mode=image|tex,width=\linewidth]{Images/nilpot-a}
        \caption{}
        \label{DS:nilpot-a}
      \end{subfigure}
      \hfill
      \begin{subfigure}[b]{0.3\linewidth}
        \centering
        \includestandalone[mode=image|tex,width=\linewidth]{Images/nilpot-b}
        \caption{}
        \label{DS:nilpot-b}
      \end{subfigure}
      \hfill
      \begin{subfigure}[b]{0.3\linewidth}
        \centering
        \includestandalone[mode=image|tex,width=\linewidth]{Images/nilpot-c}
        \caption{}
        \label{DS:nilpot-c}
      \end{subfigure}\\
      \begin{subfigure}[b]{0.3\linewidth}
        \centering
        \includestandalone[mode=image|tex,width=\linewidth]{Images/nilpot-d}
        \caption{}
        \label{DS:nilpot-d}
      \end{subfigure}
      \hfill
      \begin{subfigure}[b]{0.3\linewidth}
        \centering
        \includestandalone[mode=image|tex,width=\linewidth]{Images/nilpot-e}
        \caption{}
        \label{DS:nilpot-e}
      \end{subfigure}
      \hfill
      \begin{subfigure}[b]{0.3\linewidth}
        \centering
        \includestandalone[mode=image|tex,width=\linewidth]{Images/nilpot-f}
        \caption{}
        \label{DS:nilpot-f}
      \end{subfigure}\\
      \begin{subfigure}[b]{0.3\linewidth}
        \centering
        \includestandalone[mode=image|tex,width=\linewidth]{Images/nilpot-g}
        \caption{}
        \label{DS:nilpot-g}
      \end{subfigure}
      \hfill
      \begin{subfigure}[b]{0.3\linewidth}
        \centering
        \includestandalone[mode=image|tex,width=\linewidth]{Images/nilpot-h}
        \caption{}
        \label{DS:nilpot-h}
      \end{subfigure}
      \hfill
      \begin{subfigure}[b]{0.3\linewidth}
        \centering
        \includestandalone[mode=image|tex,width=\linewidth]{Images/nilpot-i}
        \caption{}
        \label{DS:nilpot-i}
      \end{subfigure}\\
      \begin{subfigure}[b]{0.3\linewidth}
        \centering
        \includestandalone[mode=image|tex,width=\linewidth]{Images/nilpot-j}
        \caption{}
        \label{DS:nilpot-j}
      \end{subfigure}
      \hfill
      \begin{subfigure}[b]{0.3\linewidth}
        \centering
        \includestandalone[mode=image|tex,width=\linewidth]{Images/nilpot-k}
        \caption{}
        \label{DS:nilpot-k}
      \end{subfigure}
      \hfill
      \begin{subfigure}[b]{0.3\linewidth}
        \centering
        \includestandalone[mode=image|tex,width=\linewidth]{Images/nilpot-l}
        \caption{}
        \label{DS:nilpot-l}
      \end{subfigure}\\
      \begin{subfigure}[b]{0.3\linewidth}
        \centering
        \includestandalone[mode=image|tex,width=\linewidth]{Images/nilpot-m}
        \caption{}
        \label{DS:nilpot-m}
      \end{subfigure}
      \caption{Phase portraits of nilpotent singular points}
    \end{figure}
  \end{theorem}
  \begin{theorem}[Blow-up in polar coordinates]\label{DS:blowpolar}
    Consider a planar differential system with an equilibrium at the origin such that its differential at $(0,0)$ is:
    $$\begin{pmatrix}
        0 & 0 \\
        0 & 0
      \end{pmatrix}$$
    Hence, a change form cartesian coordinates to polar coordinates will transform the equations into the following ones:
    $$
      \left\{
      \begin{aligned}
        \dot{r}      & = \sum_{k=3}^\infty r^{k-1}f_{k}(\theta) \\
        \dot{\theta} & = \sum_{k=3}^\infty r^{k-2}g_{k}(\theta)
      \end{aligned}
      \right.
    $$
    where $f_k(\theta)$ and $g_k(\theta)$ are trigonometric polynomials of degree $k$. The above system has the same phase portrait as:
    $$
      \left\{
      \begin{aligned}
        \dot{r}      & = \sum_{k=3}^\infty r^{k-2}f_{k}(\theta) \\
        \dot{\theta} & = \sum_{k=3}^\infty r^{k-3}g_{k}(\theta)
      \end{aligned}
      \right.
    $$
    We are interested in the local behavior of the origin so we should first think this problem in the cylinder $(r,\theta)\in[0,\infty]\times[0,2\pi)$. The equilibrium points of that system at $r=0$ will be the isolated zeros of $g_3(\theta)$. Let $Z(g_3)$ be the set of such zeros. Now we want to study the behavior on each of these points. To do so, we can apply either Hartman's theorem, \mcref{DS:thmA} or \mcref{DS:thmB}. If none of these are applicable of some $\theta^*\in Z(g_3)$, we should repeat the procedure by doing another polar transformation centered at $\theta^*$\footnote{See \mcref{DS:blowcarte} for a bettern solution to this problem.}. We can then represent all these local behavior by \emph{blowing-up} the origin to $\S^1$ and once done, we should \emph{blow-down} until contract $\S^1$ into the origin (See the example \mcref{DS:blowup} for a better understanding).
  \end{theorem}
  \begin{figure}[H]
    \centering
    \begin{subfigure}[b]{\linewidth}
      \centering
      \includestandalone[mode=image|tex,width=\linewidth]{Images/cylinder}
      \caption{System on the cylinder}
    \end{subfigure}
    \\
    \begin{subfigure}[b]{0.48\linewidth}
      \centering
      \includestandalone[mode=image|tex,width=\linewidth]{Images/blowup}
      \caption{Blow-up}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\linewidth}
      \centering
      \includestandalone[mode=image|tex,width=\linewidth]{Images/blowdown}
      \caption{Blow-down}
    \end{subfigure}
    \caption{Blowing-up of a non-hyperbolic critical point. The kinds of equilibrium points in the cylinder (here $Z(g_3)=\{0,\frac{\pi}{4},\frac{\pi}{2}, \pi, \frac{5\pi}{4}, \frac{3\pi}{2}\}$) are three saddles, two saddle-node and one node. These are transformed in parabolic, hyperbolic and elliptic sectors when blowing-down the origin.}
    \label{DS:blowup}
  \end{figure}
  \begin{corollary}[Blow-up in generalized polar coordinates]
    If, in the above theorem, in a neighbourhood of the origin we have $x^\alpha \sim y^\beta$ where $\alpha,\beta>0$, then a better change of variables instead of the ordinary change to polars would be:
    \begin{align*}
      x & =r^\beta\cos\theta  \\
      y & =r^\alpha\sin\theta
    \end{align*}
  \end{corollary}
  \begin{theorem}[Blow-up in cartesian coordinates]\label{DS:blowcarte}
    Consider a planar differential system with an equilibrium at the origin such that its differential at $(0,0)$ is:
    $$\begin{pmatrix}
        0 & 0 \\
        0 & 0
      \end{pmatrix}$$
    We would like to do not a blow-up equally-weighted in all directions (as in the polar blow-up) but two blow-ups: one by leaving one axis undefined and the other one covering that axis left. Thus, if at the origin $x^\alpha \sim y^\beta$ where $\alpha,\beta>0$ we seek transformations of the form $(x,y)\rightarrow\left(x,\frac{y^\beta}{x^\alpha}\right)$, which is undefined at $x=0$, and transformations of the form $(x,y)\rightarrow\left(\frac{x^\alpha}{y^\beta},y\right)$, which is undefined at $y=0$. From here, we proceed as in \mcref{DS:blowpolar}.
  \end{theorem}
  \begin{proposition}[Lyapunov's method]
    Consider the differential system:
    \begin{equation}\label{DS:eqhopf}
      \left\{
      \begin{aligned}
        x' & =\mu x-y + X(x,y) \\
        y' & =x+\mu y + Y(x,y)
      \end{aligned}
      \right.
    \end{equation}
    where $X,Y\in\mathcal{C}^\omega$ have order $\geq 2$ in their Taylor's series. In polar coordinates this system is transformed into:
    $$
      \left\{
      \begin{aligned}
        r'      & =\mu r+  \sum_{k=3}^\infty f_{k}(\theta) r^{k-1} \\
        \theta' & =1+\sum_{k=3}^\infty g_{k}(\theta) r^{k-1}
      \end{aligned}
      \right.
    $$
    where $f_k(\theta)$ and $g_k(\theta)$ are trigonometric homogeneous polynomials of degree $k$. And so, in a neighbourhood of the origin, we can express $\dv{r}{\theta}$ as:
    $$\dv{r}{\theta}=\mu r +\sum_{k=3}^\infty h_{k}(\theta) r^{k-1}$$
    where $h_k(\theta)$ are trigonometric polynomials of degree $k$. If we impose $r(0)=\rho\simeq 0$ and assume $\mu=0$, then the solution $r(\theta,\rho)$ can be written as: $$r(\theta,\rho)=\rho+v_2(\theta)\rho^2+v_3(\theta)\rho^3+\cdots\footnote{Because of the differentiable dependence on initial conditions.}$$
    We define the \emph{$n$-th Lyapunov constant} as: $$\lyapunov{n}:=v_{2n+1}(2\pi)\footnote{Note that this has a strong relation with the Poincaré map $\Pi(\rho)=r(2\pi,\rho)$ given the section $\{(r,0):r\simeq 0\}$.}\footnote{In practice we will only compute the $\lyapunov{n}$ coefficient if $v_k(2\pi)=0$ for $k=2,\ldots,2n$.}$$
  \end{proposition}
  \begin{theorem}[Hopf bifurcation theorem]
    Consider the system of \mcref{DS:eqhopf} with $\mu=0$ and suppose $\lyapunov{1}\ne 0$. Then, for $\mu\gtrsim 0$ there exists a unique periodic orbit that bifurcates at the origin. If $\lyapunov{1}> 0$ the periodic orbit is an unstable limit cycle, and if $\lyapunov{1}< 0$ the periodic orbit is an stable limit cycle (see \mcref{DS:hopf}). This codimension-one bifurcation is called \emph{Hopf-bifurcation}.
  \end{theorem}
  \begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.48\linewidth}
      \centering
      \includestandalone[mode=image|tex,width=\linewidth]{Images/hopf1}
      \caption{$\mu\leq 0$}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\linewidth}
      \centering
      \includestandalone[mode=image|tex,width=\linewidth]{Images/hopf2}
      \caption{$\mu\gtrsim 0$}
    \end{subfigure}
    \caption{Hopf bifurcation with $\lyapunov{1}< 0$}
    \label{DS:hopf}
  \end{figure}
  \begin{theorem}
    Consider the system of \mcref{DS:eqhopf} with $\mu=0$ and the functions $v_k(\theta)$. We have that $v_{2n}(2\pi)=0$.
  \end{theorem}
  \begin{corollary}
    Consider the system of \mcref{DS:eqhopf} with $\mu=0$. Then, the origin is a center if and only if: $$\lyapunov{n}=0\qquad \forall n\in\NN$$
  \end{corollary}
  \hypersetup{linkcolor = \col}
  \begin{theorem}[Poincaré's method]
    Consider the system of \mcref{DS:eqhopf} with $\mu=0$. Then, there exists a function $H(x,y)$\footnote{This $H$ will be either a first integral of the system or a Lyapunov function. In the first case, we obtain a center for the system; in the second one, a focus.} of the form $$H(x,y)=x^2+y^2+H_3(x,y)+H_4(x,y)+\cdots$$
    where each $H_j(x,y)$ is an homogeneous polynomial of degree $j$, such that: $$H'=\sum_{k=1}^\infty \poincare{k}{(x^2+y^2)}^{k+1}\footnote{Note that finding such a function $H$ is computationally more efficient that finding the values of $v_{2n+1}(2\pi)$ of Lyapunov's method.}$$
    Note that due to the given stability of the problem, if $k = k_0$ is the index of the first non-zero Lyapunov coefficient, we must have $\lyapunov{k} = a_k\poincare{k}$, with $a_k>0$.
  \end{theorem}
  \subsection{Global dynamics in continuous systems}
  \subsubsection{Bifurcation of periodic orbits}
  \begin{theorem}[Bautin's theorem]
    Consider the differential system:
    \begin{equation}
      \left\{
      \begin{aligned}
        x' & =\alpha x-y + p_2(x,y,\vf{\mu}) \\
        y' & =x+ \alpha y +q_2(x,y,\vf{\mu})
      \end{aligned}
      \right.
    \end{equation}
    where $p_2$ and $q_2$ are homogeneous polynomials of degree 2. Then, in a neighbourhood of the origin and for $(\alpha,\vf\mu)\simeq 0$ there are at most 3 limit cycles that born from the origin.
  \end{theorem}
  \begin{definition}[Homoclinic bifurcation]
    A \emph{homoclinic bifurcation} is a bifurcation in which a limit cycle collides with a saddle point.
  \end{definition}
  \begin{theorem}[Bogdanov-Takens bifurcation]
    The normal form of the codimension-two \emph{Bogdanov-Takens bifurcation} is:
    \begin{equation}
      \left\{
      \begin{aligned}
        x' & =y                       \\
        y' & =\beta_1+\beta_2x+x^2-xy
      \end{aligned}
      \right.
    \end{equation}
    Observe that three codimension-one bifurcations occur nearby: a saddle-node bifurcation, a Hopf bifurcation and a homoclinic bifurcation.
  \end{theorem}
  \begin{proposition}[Routh-Hurwitz stability criterion]
    Consider the following polynomial: $$p(x)=a_nx^n+a_{n-1}x^{n-1}+\cdots+a_1x+1$$
    The \emph{Routh-Hurwitz stability criterion} gives a method to conclude whether all the real parts of the roots of $p$ are negative or not. Construct a table as follows:
    \begin{center}
      \def\arraystretch{1}
      \begin{tabular}{|c|c|c|c|}
        \hline
        $a_n$     & $a_{n-2}$ & $a_{n-4}$ & $\cdots$ \\
        \hline
        $a_{n-1}$ & $a_{n-3}$ & $a_{n-5}$ & $\cdots$ \\
        \hline
        $b_{11}$  & $b_{12}$  & $b_{13}$  & $\cdots$ \\
        \hline
        $b_{21}$  & $b_{22}$  & $b_{23}$  & $\cdots$ \\
        \hline
        $\vdots$  & $\vdots$  & $\vdots$  & $\ddots$ \\
        \hline
      \end{tabular}
      \captionof{table}{}
      \label{DS:routhhurwitz}
    \end{center}
    where the coefficient $b_{ij}$  is obtained by computing the determinant of the matrix whose first column is formed by the the first two elements of the two rows just above $b_{ij}$, and the second column is formed by the two elements of the $(i+1)$-th column in the two rows just above $b_{ij}$. Finally this determinant is divided by the first by minus the first coefficient of the row just above $b_{ij}$. That is:
    \begin{align*}
      b_{1j} & =-\frac{1}{a_{n-1}}\begin{vmatrix}
                                    a_n     & a_{n-2j}   \\
                                    a_{n-1} & a_{n-2j-1}
                                  \end{vmatrix}                  \\
      b_{2j} & =-\frac{1}{b_{11}}\begin{vmatrix}
                                   a_{n-1} & a_{n-2j-1} \\
                                   b_{11}  & b_{1(j+1)}
                                 \end{vmatrix}                   \\
      b_{ij} & =-\frac{1}{b_{(i-1)1}}\begin{vmatrix}
                                       b_{(i-2)1} & b_{(i-2)(j+1)} \\
                                       b_{(i-1)1} & b_{(i-1)(i+1)}
                                     \end{vmatrix} \quad\forall i\geq 3
    \end{align*}
    When completed, the number of sign changes in the first column of \mcref{DS:routhhurwitz} will be the number of non-negative roots.
  \end{proposition}
  \subsubsection{Rotated vector fields}
  \begin{definition}
    Let $\vf{f}(\vf{x})=(X(\vf{x}),Y(\vf{x}))$ be a vector field in $\RR$. We say that $\{\vf{f}(\cdot,\mu):\mu\in\RR\}$ is a \emph{one-parameter family of rotated vector fields} if the equilibrium points of $\vf{x}'=\vf{f}(\vf{x},\mu)$ are isolated and:
    $$\vf{f}\crossprod\pdv{\vf{f}}{\mu}=
      \begin{vmatrix}
        X     & Y     \\
        X_\mu & Y_\mu
      \end{vmatrix}\ne 0
    $$
    The vector field is \emph{positively rotated} if $\vf{f}\crossprod\pdv{\vf{f}}{\mu}>0$. Otherwise it is \emph{negatively rotated}.
  \end{definition}
  \begin{remark}
    The word ``rotated'' can be explained by the following the expression of the rate of rotation in terms of $\mu$ is:
    $$\pdv{\theta}{\mu}=\frac{XY_\mu-YX_\mu}{X^2+Y^2}=\frac{\vf{f}\crossprod\pdv{\vf{f}}{\mu}}{X^2+Y^2}$$
  \end{remark}
  \begin{theorem}
    Stable and unstable limit cycles of a family of rotated vector fields expand or contract monotonically as the parameter $\mu$ varies in a fixed sense and the motion covers an annular neighbourhood of the initial position.
  \end{theorem}
  \begin{theorem}
    A semiestable limit cycle $\Gamma_\mu$ of a family of rotated vector fields splits into two simple limit cycles, one stable and one unstable, as the parameter $\mu$ is varied in one sense and it disappears as $\mu$ is varied in the opposite sense.
  \end{theorem}
  \begin{theorem}[Melnikov's method]
    Let $\vf{f}\in\mathcal{C}^1(\RR^2)$, $\vf{g}\in\mathcal{C}^1(\RR^2\times\RR^m)$ and $\varepsilon\simeq 0$. Consider the followingODE:
    \begin{equation}\label{DS:melnikov}
      \vf{x}'=\vf{f}(\vf{x})+\varepsilon\vf{g}(\vf{x},\vf{\mu})
    \end{equation}
    Suppose that for $\varepsilon =0$ the system has a one-parameter family of periodic orbits $\vf\gamma_h(t)$ of period $T_h$. Then for any simple zero $(\vf\mu_0,h_0)$ of the function $$M(\vf\mu, h)=\int_{0}^{T_h}\vf{f}(\vf\gamma_h(t))\times \vf{g}(\vf\gamma_h(t))\dd{t}$$ there exists a unique limit cycle $\vf\Gamma_\varepsilon$ for $\varepsilon\simeq 0$ such that $\displaystyle\lim_{\varepsilon\to 0}\vf\Gamma_\varepsilon=\vf\gamma_{h_0}$. On the other hand, if $M(\vf\mu_0,h_0)\ne 0$, for sufficiently small $\varepsilon$, the system of \mcref{DS:melnikov} with $\vf\mu=\vf\mu_0$ has no limit cycle in any sufficiently small neighborhood of $\vf\gamma_{h_0}$.
  \end{theorem}
  \begin{corollary}[Melnikov's method]
    Let $H\in\mathcal{C}^2(\RR^2)$, $P,Q\in\mathcal{C}^1(\RR^2\times\RR^m)$ and $\varepsilon\simeq 0$. Consider the following system ofODEs:
    \begin{equation*}
      \left\{
      \begin{aligned}
        x' & =-H_y -\varepsilon Q(x,y,\vf\mu) \\
        y' & =H_x +\varepsilon P(x,y,\vf\mu)
      \end{aligned}
      \right.
    \end{equation*}
    Suppose the system has a center and let $\vf\gamma_h=\{H(x,y)=h\}$ be a one-parameter family of periodic orbits of it. Then: $$M(\vf\mu,h)=\int_{\vf\gamma_h}P\dd{x}+Q\dd{y}$$
  \end{corollary}
  \subsubsection{Graphs}
  \begin{definition}
    A \emph{graph} in a continuous dynamical system is the collection of a set of equilibrium points joined together with orbits which have them as $\alpha$- and $\omega$-limits.
  \end{definition}
  \begin{definition}
    We say that a graph in the system $\vf{x}'=\vf{f}(\vf{x})$ is \emph{non-degenerated} if all the equilibrium points on it are \emph{linear saddles}, that is, saddles $p\in\RR^n$ such that $\det\vf{Df}(p)\ne 0$.
  \end{definition}
  \begin{proposition}
    Consider a system with a non-degenerated graph $\Gamma$ with $n$ equilibria and such that the differential at each of the $n$ saddles has eigenvalues $\lambda_i > 0$ and $\mu_i<0$. Then:
    \begin{enumerate}
      \item If $\displaystyle\prod_{i=1}^n\abs{\frac{\mu_i}{\lambda_i}}<1$, then $\Gamma$ is unstable.
      \item If $\displaystyle\prod_{i=1}^n\abs{\frac{\mu_i}{\lambda_i}}>1$, then $\Gamma$ is stable.
    \end{enumerate}
  \end{proposition}
  \begin{corollary}
    Suppose that the system $\vf{x}'=\vf{f}(\vf{x})$ has a homoclinic orbit $\vf\gamma$ which has $p$ as $\alpha$- and $\omega$-limit. Then:
    \begin{enumerate}
      \item If $\div \vf{f}(p)>0$, then $\vf\gamma$ is unstable.
      \item If $\div \vf{f}(p)<0$, then $\vf\gamma$ is stable.
    \end{enumerate}
  \end{corollary}
  \subsubsection{Liénard system}
  \begin{definition}
    Let $f,g:\RR\rightarrow\RR$ be functions of class $\mathcal{C}^1$. A \emph{Liénard system} is a system of the form:
    \begin{equation}\label{DS:lienard}
      x''+f(x)x'+g(x)=0\iff\left\{
      \begin{aligned}
        x' & =y-F(x) \\
        y' & =-g(x)
      \end{aligned}
      \right.
    \end{equation}
    where we have denoted $F(x):=\int_0^xf(\xi)\dd{\xi}$.
  \end{definition}
  \begin{theorem}[Liénard's theorem]
    Let $F,g\in \mathcal{C}^1(\RR)$ be odd functions such that:
    \begin{itemize}
      \item $xg(x)>0$ for $x\ne 0$.
      \item $F'(0)<0$.
      \item $F$ has a single positive zero at $x=a$.
      \item $F$ increases monotonically to infinity for $x\geq a$ as $x\to\infty$.
    \end{itemize}
    Then, the Liénard system of \mcref{DS:lienard} has exactly one limit cycle and it is stable.
  \end{theorem}
  \begin{definition}
    Let $\mu\in\RR$. A \emph{Van der Pol oscillator} is a Liénard system of the form:
    \begin{equation}\label{DS:vanderpol}
      x''+\mu(x^2-1)x'+x=0\iff\left\{
      \begin{aligned}
        x' & =y              \\
        y' & =-x +\mu(1-x^2)
      \end{aligned}
      \right.
    \end{equation}
  \end{definition}
  \begin{corollary}
    For $\mu>0$, Van der Pol oscillator has a unique limit cycle and it is stable.
  \end{corollary}
  \subsubsection{Dynamics on \texorpdfstring{$\RR^3$}{R3}}
  \begin{proposition}
    Let $\vf{f}:\RR^3\rightarrow\RR^3$ be a vector field and $\vf\gamma(t)$ be a periodic orbit of period $T$ of it. Consider a transversal section $\Sigma\subset \RR^3$ that cuts $\vf{\gamma}$ and let $\vf\Pi:\Sigma\rightarrow\Sigma$ be the Poincaré map on it. If $\vf{M}(t)$ is the solution to the variational equation
    $$
      \begin{cases}
        \vf{M}'      =\vf{D}\vf{f}(\vf{\gamma}(t))\vf{M} \\
        \vf{M}(0)  =\vf{I}_n
      \end{cases}
    $$
    then, $\sigma(\vf{M}(T))=\sigma(\vf{D\Pi})\cup\{1\}$. Hence, the stability of the orbit can be studied from $\vf{M}(T)$.
  \end{proposition}
  \subsubsection{Lorenz System}
  \begin{definition}
    The \emph{Lorenz system} is defined as:
    $$
      \left\{
      \begin{aligned}
        x' & =\sigma(y-x)   \\
        y' & = x(\rho-z) -y \\
        z' & = xy -\beta z
      \end{aligned}
      \right.
    $$
  \end{definition}
  \subsection{Global dynamics in discrete systems}
  \subsubsection{Periodic orbits}
  \begin{definition}
    Let $\vf{f}:\RR^m\rightarrow\RR^m$ be a function and consider the discrete map
    \begin{equation}\label{DS:po_discrets}
      \vf{x}_{n+1}=\vf{f}(\vf{x}_n)
    \end{equation} A \emph{periodic point} $\vf{y}$ of period $m$ is a solution to the equation $\vf{f}^m(\vf{x})=\vf{x}$. If moreover it satisfies that $\vf{f}^k(\vf{y})\ne\vf{y}$ $\forall k=1,\ldots,m-1$, then $m$ is called \emph{prime period} of $\vf{y}$. We denote the \emph{set of periodic points} of period (not necessarily prime) $n$ by $\Per_n(\vf{f})$. Finally we define the \emph{set of periods} $\Per(\vf{f})\subseteq\NN$ as follows:
    \begin{align*}
      m\in\Per(\vf{f})\iff & \exists\vf{y}\in\RR^m\text{ such that $\vf{y}$ is a periodic} \\
                           & \text{point of prime period $m$ under $\vf{f}$}
    \end{align*}
  \end{definition}
  \begin{proposition}
    Consider the one-dimensional discrete map $x_{n+1}=f(x_n)$ and let $\gamma=\{x^1,\ldots,x^k\}$ be a periodic orbit of period $k$ of $f$. Then, the orbit is stable if: $$\prod_{i=1}^k\abs{f'(x^i)}<1$$ Analogously, it is unstable if: $$\prod_{i=1}^k\abs{f'(x^i)}>1$$
  \end{proposition}
  \begin{proof}
    The orbit $\gamma$ is stable if $\abs{{(f^k(x^1))}'}<1$ as $x^1$ is a fixed point of $f^k$. But by the \mnameref{RVF:chainrule} we have:
    $$(f^k(x^1))'=\prod_{i=1}^kf'(f^{k-i}(x^1))=\prod_{i=1}^kf'(x^{k+1-i})=\prod_{i=1}^kf'(x^i)$$
    The unstable case is analogous.
  \end{proof}
  \subsubsection{Logistic map}
  \begin{definition}
    The \emph{logistic map} is the one-dimensional iteration
    \begin{equation}\label{DS:logistic}
      x_{n+1}=\mu x_n(1-x_n)=:f_\mu(x_n)
    \end{equation}
    where $\mu\in\RR^*$.
  \end{definition}
  \begin{proposition}
    The logistic map of \mcref{DS:logistic} satisfies that $f_\mu(0)=f_\mu(1)=0$ and $f_\mu(p_\mu)=p_\mu$, where $p_\mu=1-\frac{1}{\mu}$. Moreover for $\mu > 1$ we have the following properties:
    \begin{itemize}
      \item $0<p_\mu<1$
      \item If $x>1$ or $x<0$, then $\displaystyle\lim_{n\to\infty} \omega(x)=-\infty$.
    \end{itemize}
  \end{proposition}
  \begin{proposition}
    The logistic map of \mcref{DS:logistic} has a transcritical bifurcation at $\mu = 1$.
  \end{proposition}
  \begin{proposition}
    Consider the logistic map of \mcref{DS:logistic} with $\mu\in(1,3)$. Then:
    \begin{itemize}
      \item $p_\mu$ is attracting and 0 i repelling.
      \item If $0<x<1$, then $\displaystyle\lim_{n\to\infty} \omega(x)=p_\mu$.
    \end{itemize}
  \end{proposition}
  \begin{definition}[Period-doubling bifurcation]
    A \emph{period-doubling bifurcation} occurs when a slight change in a system's parameters causes a new periodic trajectory to emerge from an existing periodic trajectory, the new one having double the period of the original. A \emph{period-halving bifurcation} occurs when a system switches to a new behavior with half the period of the original system.
  \end{definition}
  \begin{definition}
    A \emph{period-doubling cascade} is an infinite sequence of period-doubling bifurcations.
  \end{definition}
  \begin{theorem}
    The logistic map of \mcref{DS:logistic} has a period-doubling cascade starting at $\mu = 3$.
  \end{theorem}
  \begin{definition}[Sharkovskii's order]
    Consider the following order relation $\sharkgeq$ on $\NN$:
    \begin{center}
      \def\arraystretch{1}
      \begin{tabular}{c@{ $\sharkgeq$ }c@{ $\sharkgeq$ }c@{ $\sharkgeq$ }c@{ $\sharkgeq$ }c@{ $\sharkgeq$ }c}
        \multicolumn{1}{c}{} & $3$                                   & $5$                                  & $\cdots$             & $(2n+1)$                             & $\cdots$             \\
        $\cdots$             & $2\cdot 3$                            & $2\cdot5$                            & $\cdots$             & $2\cdot(2n+1)$                       & $\cdots$             \\
        $\cdots$             & $2^2\cdot 3$                          & $2^2\cdot5$                          & $\cdots$             & $2^2\cdot(2n+1)$                     & $\cdots$             \\
        \multicolumn{1}{c}{} & \multicolumn{1}{c}{$\vdots\quad\ \ $} & \multicolumn{1}{c}{$\vdots\qquad\!$} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{$\vdots\qquad\!$} & \multicolumn{1}{c}{} \\
        $\cdots$             & $2^k\cdot 3$                          & $2^k\cdot5$                          & $\cdots$             & $2^k\cdot(2n+1)$                     & $\cdots$             \\
        $\cdots$             & $2^k$                                 & $\cdots$                             & $2^2$                & $2$                                  & $1$                  \\
      \end{tabular}
    \end{center}
  \end{definition}
  \begin{lemma}
    $(\NN,\sharkgeq)$ is a totally ordered set.
  \end{lemma}
  \begin{proposition}[Expansive fixed point theorem]
    Let $I\subseteq\RR$ be a closed bounded interval and $f:I\rightarrow \RR$ be a continuous function such that $I\subseteq f(I)$. Then, $f$ has a fixed point.
  \end{proposition}
  \begin{proof}
    Suppose $I=[a_1,a_2]$. Then, $\exists b_1,b_2\in I$ such that $f(b_1)=a_1$ and $f(b_2)=a_2$. Now use the \mnameref{RVF:ivt}.
  \end{proof}
  \begin{lemma}[Itinerary lemma]
    Let $f:\RR\rightarrow \RR$ be a continuous function and suppose that there exists closed bounded intervals $I_0,I_1,\ldots, I_{n-1}$ such that:
    $$f(I_0)\subseteq I_1,f(I_1)\subseteq I_2,\ldots, f(I_{n-2})\subseteq I_{n-1}, f(I_{n-1})\subseteq I_0$$
    Then, $\exists x\in I_0$ such that $f^n(x)=x$ and $f^j(x)\in I_j$ $\forall j\in\NN$.
  \end{lemma}
  \begin{theorem}[Sharkovskii's theorem]\hfill
    \begin{enumerate}
      \item Let $I\subseteq\RR$ be a closed bounded interval and $f:I\rightarrow I$ be a continuous function. If $n\in\Per(f)$, then $m\in\Per(f)$ $\forall m\sharkleq n$.
      \item Given $n\in\NN$, there exists a continuous function $f:I\rightarrow I$ defined on a closed bounded interval $I\subseteq\RR$ such that $n\in\Per(f)$ and $\forall m\sharkgeq n$, $m\notin\Per(f)$.
    \end{enumerate}
  \end{theorem}
  \begin{corollary}[Period three theorem]
    Let $I\subseteq\RR$ be an interval and $f:I\rightarrow I$ be a continuous function. If $3\in \Per(f)$, then $\Per(f)=\NN$.
  \end{corollary}
  \begin{definition}
    Consider the logistic map of \mcref{DS:logistic} with $\mu >4$ and define the following set: $$A_0:=\{x\in [0,1]: f_\mu(x)\notin [0,1]\}$$ Note that $A_0$ breaks the interval $[0,1]$ in itself and two other intervals: one on the right of it, $I_0$, and one on its left, $I_1$. Thus, $[0,1]=I_0\cup A_0\cup I_1$.
  \end{definition}
  \begin{proposition}
    Consider the logistic map of \mcref{DS:logistic} with $\mu >4$ and let $(s_0,s_1,s_2,\ldots)\in\{0,1\}$ be a sequence of zeros and ones. We define the following sets
    \begin{multline*}
      I_{s_0s_1\cdots s_n}:=\\:=\{x\in I: x\in I_{s_0}, f_\mu(x)\in I_{s_1},\ldots,{f_\mu}^n(x)\in I_{s_n}\}
    \end{multline*}
    Then, $\Lambda_\mu:=\bigcap_{n=0}^\infty I_{s_0s_1\cdots s_n}$ is homeomorphic to the Cantor set.
  \end{proposition}
  \begin{proposition}
    Consider the logistic map of \mcref{DS:logistic} with $\mu >4$. Then, $\Lambda_\mu$ is invariant under $f_\mu$.
  \end{proposition}
  \subsubsection{Symbolic dynamics}
  \begin{definition}
    Consider the set $$\Sigma_2:=\{(s_0,s_1,s_2,\ldots):s_n\in\{0,1\}\ \forall n\in\NN\cup\{0\}\}$$ and define the following distance on $\Sigma_2$: $$d_2((s_0,s_1,s_2,\ldots),(t_0,t_1,t_2,\ldots))=\sum_{n=0}^\infty \frac{\abs{s_n-t_n}}{2^n}$$
    In order to simplify the notation we will write from now on $s=(s_0,s_1,s_2,\ldots)$ and $t=(t_0,t_1,t_2,\ldots)$.
  \end{definition}
  \begin{lemma}
    $(\Sigma_2,d_2)$ is a metric space.
  \end{lemma}
  \begin{proposition}[Proximity theorem]
    Let $s, t\in\Sigma_2$. Then, $s_i=t_i$ for $i=0,\ldots,n$ if and only if $d_2(s,t)\leq \frac{1}{2^n}$.
  \end{proposition}
  \begin{definition}[Shift map]
    The \emph{shift map} is defined as:
    $$\function{\sigma}{\Sigma_2}{\Sigma_2}{(s_0,s_1,s_2,\ldots)}{(s_1,s_2,s_3,\ldots)}$$
  \end{definition}
  \begin{proposition}
    The shift map is continuous.
  \end{proposition}
  \begin{proof}
    Let $\varepsilon>0$ and $s,t\in\Sigma_2$ with $d_2(s,t)<\delta$. Then: $$d_2(\sigma(s),\sigma(t))=\abs{s_0-t_0} + 2d_2(\sigma(s),\sigma(t))<\varepsilon$$ if $\delta<\frac{\varepsilon - \abs{s_0-t_0}}{2}$.
  \end{proof}
  \begin{proposition}
    The triplet $(\Sigma_2, \ZZ_{\geq 0}, \sigma)$ is a discrete semidynamical system.
  \end{proposition}
  \begin{proposition}\hfill
    \begin{enumerate}
      \item $\abs{\Per_n(\sigma)}=2^n$
      \item There exists a dense orbit for $\sigma$ in $\Sigma_2$.
      \item The set of periodic orbits of $\sigma$ is dense in the set of orbits of $\sigma$.
    \end{enumerate}
  \end{proposition}
  \begin{sproof}
    \begin{enumerate}
      \item Just note that there are $2^n$ different sequences in $\Sigma_2$ of the form:
            $$(s_0,\ldots,s_{n-1},s_0,\ldots,s_{n-1},s_0,\ldots,s_{n-1},\ldots)$$
      \item Consider the sequence of ``all sequences":
            \begin{multline*}
              (0,1,0,0,0,1,1,0,1,1,0,0,0,0,0,1,0,1,0,1,0,0,\\ 0,1,1,1,0,1,1,1,0,1,1,1,\ldots)
            \end{multline*}
      \item Let $\varepsilon>0$, take $k\in\NN$ such that $\sum_{n=k}^{\infty}\frac{1}{2^n}<\varepsilon$ and let $s=(s_n)\in\Sigma_2$. The element $$t_s:=(s_0,\ldots,s_{k-1},s_0,\ldots,s_{k-1},s_0,\ldots,s_{k-1},\ldots)$$
            is periodic and satisfies $d_2(s,t_s)<\varepsilon$.
    \end{enumerate}
  \end{sproof}
  \begin{definition}
    Consider the logistic map of \mcref{DS:logistic}. We define the \emph{itinerary} of $x\in\Lambda_\mu$ as the function $S_\mu:\Lambda_\mu\rightarrow\Sigma_2$ defined by $S_\mu(x)=(s_n)$, where:
    $$s_n=
      \begin{cases}
        0 & \text{if ${f_\mu}^n\in I_0$} \\
        1 & \text{if ${f_\mu}^n\in I_1$}
      \end{cases}
    $$
  \end{definition}
  \begin{proposition}
    For $\mu>2+\sqrt{5}$, the itinerary map is a homeomorphism.
  \end{proposition}
  \begin{theorem}
    Consider the logistic map of \mcref{DS:logistic}. Then, $S_\mu\circ f_\mu=\sigma\circ S_\mu$.
  \end{theorem}
  \begin{corollary}
    Consider the logistic map of \mcref{DS:logistic} for $\mu>2+\sqrt{5}$. Then:
    \begin{enumerate}
      \item $\abs{\Per_n(f_\mu)}=2^n$
      \item There exists a dense orbit for $f_\mu$ in $\Lambda_\mu$.
      \item The set of periodic orbits of $f_\mu$ is dense in $\Sigma_2$.
    \end{enumerate}
  \end{corollary}
  \subsubsection{Introduction to chaos}
  \begin{definition}
    Let $f : I\rightarrow I$ be a function. The iteration $x_{n+1}=f(x_n)$ is \emph{topologically transitive} if for any pair of open subsets $U,V\subseteq I$, $\exists k\in\NN$ such that $f^k(U)\cap V\ne\varnothing$.
  \end{definition}
  \begin{definition}
    Let $f : I\rightarrow I$ be a function. The iteration $x_{n+1}=f(x_n)$ has \emph{sensitive dependence on initial conditions} on $I$ if $\exists\delta >0$ such that for each $x\in I$ and any neighborhood $N$ of $x$, exists $y \in N$ and $n \geq  0$ such that $\abs{f^n(x)-f^n(y)} > \delta$.
  \end{definition}
  \begin{lemma}
    Let $f : I\rightarrow I$ be a function such that the iteration $x_{n+1}=f(x_n)$ is topologically transitive. Then, it has a dense orbit.
  \end{lemma}
  \begin{definition}[Chaos]
    Let $f : I\rightarrow I$ be a function. The iteration $x_{n+1}=f(x_n)$ is said to be \emph{chaotic} on $I$ if $f$ has the following properties:
    \begin{enumerate}
      \item Periodic points are dense in $I$.
      \item $f$ is topologically transitive.
      \item $f$ has sensitive dependence on initial conditions\footnote{Although this is the classical definition of chaos, it has been shown that the first two properties imply the third one.}.
    \end{enumerate}
  \end{definition}
  \begin{theorem}
    The logistic maps $x_{n+1}=\mu x_n(1-x_n)$ are chaotic on $\Lambda$ for $\mu>2+\sqrt{5}$.
  \end{theorem}
  \begin{theorem}
    The logistic map $x_{n+1}=4x_n(1-x_n)$ is chaotic on $[0,1]$.
  \end{theorem}
\end{multicols}
\end{document}