\documentclass[../../../main_math.tex]{subfiles}


\begin{document}
\changecolor{SP}
\begin{multicols}{2}[\section{Stochastic processes}]
  \subsection{Preliminaries}
  \begin{proposition}
    Let $(\Omega,\mathcal{A},\Prob)$ be a probability space and $(X_n)$ be sequence of random variables such that: $$\sum_{n=1}^{\infty}\Exp(\abs{X_n})<\infty$$
    Then, $\sum_{n=1}^{\infty}X_n$ is a random variable and: $$
      \Exp\left(\sum_{n=1}^{\infty}X_n\right)=\sum_{n=1}^{\infty}\Exp(X_n)
    $$
  \end{proposition}
  \begin{proof}
    By the \mnameref{P:monotone} we have that
    $$\Exp\left(\sum_{n=1}^{\infty}\abs{X_n}\right)=\sum_{n=1}^{\infty}\Exp(\abs{X_n})<\infty$$
    so the random variable $Y:=\sum_{n=1}^{\infty}\abs{X_n}$ is integrable and $\forall N\in\NN$ satisfies: $$\abs{\sum_{n=1}^{N}X_n}\leq Y$$
    Now use the \mnameref{P:dominated}.
  \end{proof}
  \begin{proposition}[Law of total probability]
    Let $(\Omega,\mathcal{A},\Prob)$ be a probability space and $\{A_n:1\leq n\leq N\}\subset\mathcal{A}$, $N\in\NN\cup\{\infty\}$, be such that $\bigsqcup_{n=1}^N A_n=\Omega'$ with $\Prob(\Omega')=1$. Then, $\forall A\in\mathcal{A}$: $$\Prob(A)=\sum_{n=1}^N\Prob(A_n)\Prob(A\mid A_n)$$
  \end{proposition}
  \begin{sproof}
    See the proof of \mnameref{P:totalprob}.
  \end{sproof}
  \begin{remark}
    Note that if there is some $A_n$ for which $\Prob(A_n)=0$, the conditional probability is not well-defined. But note that:
    $$0\leq \Prob(A_n)\Prob(A\mid A_n)=\Prob(A\cap A_n)\leq \Prob(A_n)=0$$
    So we can omit this term in the sum.
  \end{remark}
  \subsubsection{Conditional expectation}
  \begin{proposition}[Substitution principle]\label{SP:substitutionPrinciple}
    Let $(\Omega,\mathcal{A},\Prob)$ be a probability space, $\vf{X}$ be a discrete random vector with outcomes in $S_{\vf{X}}$, $Y$ be a discrete random variable with outcomes in $S_Y$, $h:S_{\vf{X}}\times S_Y\rightarrow\RR$ be a function and $y\in S_Y$. Then:
    $$\Exp(h(\vf{X},Y=y)\mid Y=y)=\Exp((h(\vf{X}),Y)\mid Y=y)$$
  \end{proposition}
  \begin{proposition}[Law of total expectation]\label{SP:totalexp}
    Let $(\Omega,\mathcal{A},\Prob)$ be a probability space, $\vf{X}$ is a discrete random vector with outcomes in $S_{\vf{X}}$, $\{A_n:1\leq n\leq N\}\subset\mathcal{A}$, $N\in\NN\cup\{\infty\}$, be such that $\bigsqcup_{n=1}^N A_n=\Omega'$ with $\Prob(\Omega')=1$ and $h:S_{\vf{X}}\rightarrow\RR$ be a function. If $h(\vf{X})$ has finite expectation or $h\geq 0$, then: $$\Exp(h(\vf{X}))=\sum_{n=1}^N\Exp(h(\vf{X})\mid A_n)\Prob(A_n)$$
  \end{proposition}
  \begin{sproof}
    See the proof of \mnameref{P:totalexp}.
  \end{sproof}
  \begin{definition}
    Let $(\Omega,\mathcal{A},\Prob)$ be a probability space, $\vf{X}$ be a discrete random vector with outcomes in $S_{\vf{X}}$, $Y$ be a discrete random variable with outcomes in $S_Y$ and $h:S_{\vf{X}}\rightarrow\RR$ be a function. For all $\omega\in\Omega$ we define the random variable $\Exp(h(\vf{X})\mid Y)$ as
    $$\Exp(h(\vf{X})\mid Y)(\omega)=\Exp(h(\vf{X})\mid Y=y)$$
    provided that $Y(\omega)=y$.
    Note that it can also be written as:
    $$\Exp(h(\vf{X})\mid Y)=\sum_{y\in S_Y}\Exp(h(\vf{X})\mid Y=y)\indi{\{Y=y\}}$$
  \end{definition}
  \begin{proposition}
    Let $(\Omega,\mathcal{A},\Prob)$ be a probability space, $\vf{X}$ be a discrete random vector with outcomes in $S_{\vf{X}}$, $Y$ be a discrete random variable with outcomes in $S_Y$, $h,h_1,h_2:S_{\vf{X}}\rightarrow\RR$ be functions and $a,b\in\RR$. Then:
    \begin{enumerate}
      \item $\Exp(ah_1(\vf{X})+bh_2(\vf{X})\mid Y)=a\Exp(h_1(\vf{X})\mid Y)+b\Exp(h_1(\vf{X})\mid Y)$
      \item If $\vf{X}$ and $Y$ are independent, then $\Exp(h(\vf{X})\mid Y)=\Exp(h(\vf{X}))$.
      \item $\Exp(\Exp(h(\vf{X})\mid Y))=\Exp(h(\vf{X}))$.
    \end{enumerate}
  \end{proposition}
  \begin{sproof}
    The first two properties are consequence of the fact that the conditional expectation is an expectation. For the last one note that:
    \begin{align*}
      \Exp(\Exp(h(\vf{X})\mid Y)) & =\sum_{y\in S_y}\Exp(h(\vf{X})\mid Y=y)\Prob(Y=y) \\
                                  & =\Exp(h(\vf{X}))
    \end{align*}
    where the last equality is due to the \mnameref{SP:totalexp}.
  \end{sproof}
  \begin{theorem}[Wald theorem]
    Let $(\Omega,\mathcal{A},\Prob)$ be a probability space, $(Z_n)$ be a sequence of random variables, all of them with expectation $\mu\in\RR$, such that $\sup_{n\geq 1}\Exp(\abs{Z_n})=A<\infty$. If $N$ is an integrable random variable with outcomes in $\NN$ independent of $Z_n$ $\forall n\in\NN$, we have that:
    $$\Exp\left(\sum_{n=1}^NZ_n\right)=\mu\Exp(N)$$
  \end{theorem}
  \begin{proof}
    Note that $\Exp\left(\sum_{n=1}^NZ_n\right)=\Exp\left(\sum_{n=1}^\infty Z_n\indi{N\geq n}\right)$ and it is integrable because:
    \begin{align*}
      \Exp\left(\sum_{n=1}^\infty \abs{Z_n\indi{N\geq n}}\right) & =\sum_{n=1}^\infty \Exp(\abs{Z_n})\Exp(\indi{N\geq n}) \\
                                                                 & \leq A\sum_{n=1}^\infty \Prob(N\geq n)                 \\
                                                                 & =A\Exp(N)                                              \\
                                                                 & <\infty
    \end{align*}
    where we have used the Independence of $(Z_n)$ and $N$ in the first equality.
    And so:
    $$\Exp\left(\sum_{n=1}^NZ_n\right)=\sum_{n=1}^\infty \Exp(Z_n)\Exp(\indi{N\geq n})=\mu\Exp(N)$$
  \end{proof}
  \begin{remark}
    Note that the equality remains true if $Z_n\geq 0$ $\forall n\in\NN$ even if $\Exp(N)=\infty$ because the equality $\sum_{n=1}^\infty \Prob(N\geq n)=\Exp(N)$ remains true.
  \end{remark}
  \subsubsection{Probability-generating function}
  \begin{definition}
    Let $(\Omega,\mathcal{A},\Prob)$ be a probability space and $X$ be a random variable with outcomes in $\NN\cup\{0\}$. The \emph{probability-generating function} (or \emph{pgf}) of $X$ is the function $g_X:\mathcal{D}_X\rightarrow \RR$ defined as:
    \begin{equation}\label{SP:probgenfunc}
      g_X(s)=\sum_{k=0}^\infty s^k\Prob(X=k)=\Prob(X=0)+\sum_{k=1}^\infty s^k\Prob(X=k)
    \end{equation}
    The set $\mathcal{D}_X$ is defined as a all the points for which the series of \mcref{SP:probgenfun} converges absolutely.
  \end{definition}
  \begin{lemma}
    Let $(\Omega,\mathcal{A},\Prob)$ be a probability space and $X$ be a random variable with outcomes in $\NN\cup\{0\}$. Then, $[-1,1]\subseteq \mathcal{D}_X$ and if $s\ne 0$, $g_X(s)=\Exp(s^X)$.
  \end{lemma}
  \begin{proof}
    Clearly $g_X(s)=\Exp(s^X)$ and furthermore $\forall s\in[-1,1]$ we have $s\in \mathcal{D}_X$ because:
    $$\sum_{k=0}^\infty \abs{s}^k\Prob(X=k)\leq \sum_{k=0}^\infty \Prob(X=k)=1<\infty$$
  \end{proof}
  \begin{theorem}
    Let $(\Omega,\mathcal{A},\Prob)$ be a probability space and $X$, $Y$ be random variables with outcomes in $\NN\cup\{0\}$. Then: $$X\overset{\text{d}}{=}Y\iff g_X=g_Y$$
    Moreover: $$\Prob(X=k)=\frac{{g_X}^{(k)}(0)}{k!}\quad \forall k\geq 0$$
  \end{theorem}
  \begin{sproof}
    Note that $g_X(s)$ is a power series defined in a neighbourhood of $s=0$.
  \end{sproof}
  \begin{theorem}
    Let $(\Omega,\mathcal{A},\Prob)$ be a probability space and $X$, $Y$ be independent random variables with outcomes in $\NN\cup\{0\}$. Then, $\forall s\in\mathcal{D}_X\cap \mathcal{D}_Y$ we have: $$g_{X+Y}(s)=g_X(s)g_Y(s)$$
  \end{theorem}
  \begin{proof}
    Note that if $s\in \in\mathcal{D}_X\cap \mathcal{D}_Y$, then $s\in\mathcal{D}_{X+Y}$ because
    $$g_{X+Y}(\abs{s})=\Exp\left(\abs{s}^{X+Y}\right)=\Exp\left(\abs{s}^X\right)\Exp\left(\abs{s}^Y\right)<\infty$$
    due to the independence of $X$ and $Y$.
    To show the equality if $s=0$, we have:
    $$\Prob(X+Y=0)=\Prob(X=0,Y=0)=\Prob(X=0)\Prob(Y=0)$$
    where the first equality is due to $X,Y\in\NN\cup\{0\}$ and the second one is becuse of the independence.
    If $s\ne 0$, as before: $$g_{X+Y}({s})=\Exp({s}^{X+Y})=\Exp({s}^X)\Exp({s}^Y)=g_{X}({s})g_{Y}({s})$$
  \end{proof}
  \begin{theorem}
    Let $(\Omega,\mathcal{A},\Prob)$ be a probability space and $X$ be a random variable with outcomes in $\NN\cup\{0\}$. Then, $\forall k\geq 1$ we have:
    $$\lim_{s\to 1^-}{g_X}^{(k)}(s)=\Exp(X(X-1)\cdots(X-k+1))$$
  \end{theorem}
  \begin{sproof}
    Differentiate term by term and use \mnameref{MA:abelthm}.
  \end{sproof}
  \begin{center}
    \def\arraystretch{1.3}
    \begin{tabular}{|c|c|c|}
      \hline
      $X$                     & Probability-generating function     \\
      \hline
      $c\in\RR$               & $\displaystyle s^{c}$               \\
      %\hline
      $U(\{x_1,\ldots,x_n\})$ & $\frac{1}{n}\sum_{i=1}^n s^{x_i}$   \\
      %\hline
      $\text{B}(n,p)$         & $\displaystyle {(ps+1-p)}^n$        \\
      %\hline
      $\text{Pois}(\lambda)$  & $\displaystyle \exp{\lambda(s-1)}$  \\
      %\hline
      $\text{Geo}(p)$         & $\displaystyle \frac{ps}{1-(1-p)s}$ \\
      %\hline
      \hline
    \end{tabular}
    \captionof{table}{Probability-generating functions of common distributions.}
  \end{center}
  \subsection{Discrete-time Markov chain}
  \subsubsection{Galton-Watson process}
  \begin{model}\label{SP:galtonwatsonModel}
    Let $(X_n)$, $n\in\NN\cup\{0\}$ be a sequence of discrete random vairables representing the number of new individuals of a certain population at the $n$-th generation. Suppose they are defined as $$X_{n+1}=\sum_{k=1}^{X_n}Y_{n+1}^{(k)}$$ and $X_0=1$. Here $Y_{n+1}^{(k)}$ has outcomes in $\NN\cup\{0\}$ $\forall n,k$ and represent the number of descendants (to the next generation) of the $k$-th individual of the $n$-th generation. Suppose that $Y_{n+1}^{(k)}\sim Y$ are \iid We would like to study the probability $\rho$ of extinction of this population: $$\rho=\Prob(\{X_n=0:\text{for some $n\in\NN$}\})=\Prob\left(\bigcup_{n=1}^\infty\{X_n=0\}\right)$$
  \end{model}
  \begin{lemma}\label{SP:lemmaGaltonWatson}
    Let $(Y_n)$ be a sequence of \iid random variables distributed as $Y$, whose outcomes are in $\NN\cup\{0\}$, and $N$ be a random variable also with outcomes in $\NN\cup\{0\}$ and independent to $(Y_n)$. Let $X=\sum_{k=1}^NY_k$. Then, $\forall s\in[-1,1]$ we have: $$g_X(s)=g_N(g_Y(s))$$
  \end{lemma}
  \begin{proof}
    First suppose $N\leq M$ with $M\in\NN$ fixed. Then using the independence, the \mnameref{P:totalexp} and the \mnameref{SP:substitutionPrinciple}:
    \begin{align*}
      g_X(s)=\Exp(s^X) & =\sum_{k=1}^M\Exp(s^X\mid N=k)\Prob(N=k)                                        \\
                       & = \sum_{k=1}^{M} \Exp\left(s^{\sum_{i=1}^{N}Y_i} \mid N = k\right) \Prob(N = k) \\
                       & = \sum_{k=1}^{M} \Exp\left(s^{\sum_{i=1}^{k}Y_i}\right) \Prob(N = k)            \\
                       & = \sum_{k=1}^{M} {g_Y(s)}^k \Prob(N = k)                                        \\
                       & = g_N(g_Y(s))
    \end{align*}
    Now if $N$ can take any value of $\NN\cup\{0\}$ we have that:
    \begin{align*}
      g_X(s) & =\Exp(s^{\sum_{i=1}^{N}Y_i})                                     \\
             & =\Exp\left(\lim_{M\to\infty}s^{\sum_{i=1}^{\min(N,M)}Y_i}\right) \\
             & =\lim_{M\to\infty}\Exp\left(s^{\sum_{i=1}^{\min(N,M)}Y_i}\right) \\
             & =\lim_{M\to\infty}g_{\min(N,M)}(g_Y(s))                          \\
             & =\lim_{M\to\infty}\Exp\left({(g_Y(s))}^{\min(N,M)}\right)        \\
             & =\Exp\left(\lim_{M\to\infty}{(g_Y(s))}^{\min(N,M)}\right)        \\
             & =g_N(g_Z(s))
    \end{align*}
    where both limit exchangings are due to the \mnameref{P:dominated} using the intagrable random variable 1.
  \end{proof}
  \begin{theorem}
    In the hypothesis of \mcref{SP:galtonwatsonModel}, we have that: $$\rho=g_Y(\rho)$$
  \end{theorem}
  \begin{proof}
    Note that $\{X_n=0\}\subseteq \{x_{n+1}=0\}$. Hence:
    $$\rho=\Prob\left(\bigcup_{n=1}^\infty\{X_n=0\}\right)\!=\lim_{n\to\infty}\Prob(X_n=0)=\lim_{n\to\infty}g_{X_n}(0)$$
    Now, using \mcref{SP:lemmaGaltonWatson} we have:
    $$g_{X_{n}}(s)=g_{X_{n-1}}(g_Y(s))=\cdots=g_{X_1}({g_Y}^n(s))$$
    But $X_1=1$ and so $g_{X_1}(s)=s$. So $g_{X_{n}}(s)={g_Y}^n(s)$ and therefore
    $g_{X_{n+1}}(0)=g_Y(g_{X_{n}}(0))$.
    Taking the limit as $n\to\infty$ and using the continuity of the pgf we get the result.
  \end{proof}
  \begin{theorem}
    In the hypothesis of \mcref{SP:galtonwatsonModel} and the additional assumption that $0<\Prob(Y=0)<1$ we have:
    \begin{enumerate}
      \item If $\Exp(Y)\leq 1$, $g_Y$ has only 1 fixed point (the trivial one, 1). Hence, the population will extinct with probability 1.
      \item If $\Exp(Y)> 1$, $g_Y$ has a unique non-trivial fixed point on (0,1).
    \end{enumerate}
  \end{theorem}
  \begin{proof}
    First suppose $\Prob(Y=0)+\Prob(Y=1)=1$. Thus, $Y\almoste{\leq}1$ and so $\Exp(Y)\leq 1$. Moreover, $g_Y(s)=\Prob(Y=0)+s\Prob(Y=1)$, which is a line with slope $\Prob(Y=1)<1$. Hence, it has a unique fixed point, which is $s=1$.

    Now assume $\Prob(Y=0)+\Prob(Y=1)<1$. Then, $\exists k\geq 2$ with $\Prob(Y=k)>0$. Hence, ${g_Y}'(s)>0$ and ${g_Y}''(s)>0$ $\forall s\in (0,1)$. Now consider $f(s)=g(s)-s$. Note that $f$ is strictly convex in $(0,1)$ and $f(0)=g(0)=\Prob(Y=0)>0$. Finally note that $$\lim_{t\to 1^-} f'(s)=\lim_{t\to 1^-}g(s)-1=\Exp(Y)-1$$
    and so $\displaystyle\lim_{t\to 1^-} f'(s)$ is negative in the first case and positive in the second case. This imply that $f$ has no zeros on $(0,1)$ in the first case and exactly 1 zero in $(0,1)$ in the second case.

    It's missing to see that in the second case the probability of extinction $\rho$ is given by the fixed point in $(0,1)$, rather than 1. We have that:
    $$\rho=\lim_{n\to\infty}g_{X_n}(0)=\lim_{n\to\infty}{g_Y}^n(0)$$
    Since $g'>0$, we have that $g$ is increasing and so it is $g^n$ $\forall n\in\NN$. Moreover if $g(x_0)=x_0$, we have that $g^n(x_0)=x_0$ $\forall n\in\NN$. Therefore $$0<g(0)<g^2(0)<\cdots<g^n(0)<\cdots <x_0<\cdots <1$$
    And so the limit has to be $x_0$ (note that the limit does exist because $({g_Y}^n(0))$ is an increasing bounded sequence).
  \end{proof}
  \subsubsection{Random walk}
  \begin{definition}
    A \emph{random walk} is a sequence $(\vf{S}_n)$ with $\vf{S}_0=0$ and $\vf{S}_n=\sum_{k=1}^{n}\vf{X}_n$, where $(\vf{X}_n)$ is a sequence of \iid random vectors.
  \end{definition}
  \begin{definition}
    A \emph{simple random walk} is a random walk in which $X_k$ are random variables such that:
    $$
      X_k=\begin{cases}
        1  & \text{with probability $p$}   \\
        -1 & \text{with probability $1-p$}
      \end{cases}
    $$
  \end{definition}
\end{multicols}
\end{document}