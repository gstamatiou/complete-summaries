\documentclass[../../../main_math.tex]{subfiles}


\begin{document}
\changecolor{SP}
\begin{multicols}{2}[\section{Stochastic processes}]
  \subsection{Preliminaries}
  \begin{proposition}
    Let $(\Omega,\mathcal{A},\Prob)$ be a probability space and $(X_n)$ be sequence of random variables such that: $$\sum_{n=1}^{\infty}\Exp(\abs{X_n})<\infty$$
    Then, $\sum_{n=1}^{\infty}X_n$ is a random variable and: $$
      \Exp\left(\sum_{n=1}^{\infty}X_n\right)=\sum_{n=1}^{\infty}\Exp(X_n)
    $$
  \end{proposition}
  \begin{proof}
    By the \mnameref{P:monotone} we have that
    $$\Exp\left(\sum_{n=1}^{\infty}\abs{X_n}\right)=\sum_{n=1}^{\infty}\Exp(\abs{X_n})<\infty$$
    so the random variable $Y:=\sum_{n=1}^{\infty}\abs{X_n}$ is integrable and $\forall N\in\NN$ satisfies: $$\abs{\sum_{n=1}^{N}X_n}\leq Y$$
    Now use the \mnameref{P:dominated}.
  \end{proof}
  \begin{proposition}[Law of total probability]
    Let $(\Omega,\mathcal{A},\Prob)$ be a probability space and $\{A_n:1\leq n\leq N\}\subset\mathcal{A}$, $N\in\NN\cup\{\infty\}$, be such that $\bigsqcup_{n=1}^N A_n=\Omega'$ with $\Prob(\Omega')=1$. Then, $\forall A\in\mathcal{A}$: $$\Prob(A)=\sum_{n=1}^N\Prob(A_n)\Prob(A\mid A_n)$$
  \end{proposition}
  \begin{sproof}
    See the proof of \mnameref{P:totalprob}.
  \end{sproof}
  \begin{remark}
    Note that if there is some $A_n$ for which $\Prob(A_n)=0$, the conditional probability is not well-defined. But note that:
    $$0\leq \Prob(A_n)\Prob(A\mid A_n)=\Prob(A\cap A_n)\leq \Prob(A_n)=0$$
    So we can omit this term in the sum.
  \end{remark}
  \subsubsection{Conditional expectation}
  \begin{proposition}[Substitution principle]\label{SP:substitutionPrinciple}
    Let $(\Omega,\mathcal{A},\Prob)$ be a probability space, $\vf{X}$ be a discrete random vector with support $S_{\vf{X}}$, $Y$ be a discrete random variable with support $S_Y$, $h:S_{\vf{X}}\times S_Y\rightarrow\RR$ be a function and $y\in S_Y$. Then:
    $$\Exp(h(\vf{X},Y)\mid Y=y)=\Exp(h(\vf{X},y)\mid Y=y)$$
  \end{proposition}
  \begin{proposition}[Law of total expectation]\label{SP:totalexp}
    Let $(\Omega,\mathcal{A},\Prob)$ be a probability space, $\vf{X}$ is a discrete random vector with support $S_{\vf{X}}$, $\{A_n:1\leq n\leq N\}\subset\mathcal{A}$, $N\in\NN\cup\{\infty\}$, be such that $\bigsqcup_{n=1}^N A_n=\Omega'$ with $\Prob(\Omega')=1$ and $h:S_{\vf{X}}\rightarrow\RR$ be a function. If $h(\vf{X})$ has finite expectation or $h\geq 0$, then: $$\Exp(h(\vf{X}))=\sum_{n=1}^N\Exp(h(\vf{X})\mid A_n)\Prob(A_n)$$
  \end{proposition}
  \begin{sproof}
    See the proof of \mnameref{P:totalexp}.
  \end{sproof}
  \begin{definition}
    Let $(\Omega,\mathcal{A},\Prob)$ be a probability space, $\vf{X}$ be a discrete random vector with support $S_{\vf{X}}$, $Y$ be a discrete random variable with support $S_Y$ and $h:S_{\vf{X}}\rightarrow\RR$ be a function. For all $\omega\in\Omega$ we define the random variable $\Exp(h(\vf{X})\mid Y)$ as
    $$\Exp(h(\vf{X})\mid Y)(\omega)=\Exp(h(\vf{X})\mid Y=y)$$
    provided that $Y(\omega)=y$.
    Note that it can also be written as:
    $$\Exp(h(\vf{X})\mid Y)=\sum_{y\in S_Y}\Exp(h(\vf{X})\mid Y=y)\indi{\{Y=y\}}$$
  \end{definition}
  \begin{proposition}
    Let $(\Omega,\mathcal{A},\Prob)$ be a probability space, $\vf{X}$ be a discrete random vector with support $S_{\vf{X}}$, $Y$ be a discrete random variable with support $S_Y$, $h,h_1,h_2:S_{\vf{X}}\rightarrow\RR$ be functions and $a,b\in\RR$. Then:
    \begin{enumerate}
      \item $\Exp(ah_1(\vf{X})+bh_2(\vf{X})\mid Y)=a\Exp(h_1(\vf{X})\mid Y)+b\Exp(h_1(\vf{X})\mid Y)$
      \item If $\vf{X}$ and $Y$ are independent, then $\Exp(h(\vf{X})\mid Y)=\Exp(h(\vf{X}))$.
      \item $\Exp(\Exp(h(\vf{X})\mid Y))=\Exp(h(\vf{X}))$
    \end{enumerate}
  \end{proposition}
  \begin{sproof}
    The first two properties are consequence of the fact that the conditional expectation is an expectation. For the last one note that:
    \begin{align*}
      \Exp(\Exp(h(\vf{X})\mid Y)) & =\sum_{y\in S_Y}\Exp(h(\vf{X})\mid Y=y)\Prob(Y=y) \\
                                  & =\Exp(h(\vf{X}))
    \end{align*}
    where the last equality is due to the \mnameref{SP:totalexp}.
  \end{sproof}
  \begin{theorem}[Wald theorem]
    Let $(\Omega,\mathcal{A},\Prob)$ be a probability space, $(Z_n)$ be a sequence of random variables, all of them with expectation $\mu\in\RR$, such that $\sup_{n\geq 1}\Exp(\abs{Z_n})=A<\infty$. If $N$ is an integrable random variable with support $\NN$ independent of $Z_n$ $\forall n\in\NN$, we have that:
    $$\Exp\left(\sum_{n=1}^NZ_n\right)=\mu\Exp(N)$$
  \end{theorem}
  \begin{proof}
    Note that $\Exp\left(\sum_{n=1}^NZ_n\right)=\Exp\left(\sum_{n=1}^\infty Z_n\indi{N\geq n}\right)$, and it is integrable because:
    \begin{multline*}
      \Exp\left(\sum_{n=1}^\infty \abs{Z_n\indi{N\geq n}}\right) =\sum_{n=1}^\infty \Exp(\abs{Z_n})\Exp(\indi{N\geq n}) \leq              \\
      \leq A\sum_{n=1}^\infty \Prob(N\geq n) =A\Exp(N)<\infty
    \end{multline*}
    where we have used the Independence of $(Z_n)$ and $N$ in the first equality.
    And so:
    $$\Exp\left(\sum_{n=1}^NZ_n\right)=\sum_{n=1}^\infty \Exp(Z_n)\Exp(\indi{N\geq n})=\mu\Exp(N)$$
  \end{proof}
  \begin{remark}
    Note that the equality remains true if $Z_n\geq 0$ $\forall n\in\NN$ even if $\Exp(N)=\infty$ because the equality $\sum_{n=1}^\infty \Prob(N\geq n)=\Exp(N)$ remains true.
  \end{remark}
  \subsubsection{Probability-generating function}
  \begin{definition}
    Let $(\Omega,\mathcal{A},\Prob)$ be a probability space and $X$ be a random variable with support $\NN\cup\{0\}$. The \emph{probability-generating function} (or \emph{pgf}) of $X$ is the function $g_X:\mathcal{D}_X\rightarrow \RR$ defined as:
    \begin{equation}\label{SP:probgenfunc}
      g_X(s)=\sum_{k=0}^\infty s^k\Prob(X=k)=\Prob(X=0)+\sum_{k=1}^\infty s^k\Prob(X=k)
    \end{equation}
    The set $\mathcal{D}_X$ is defined as all the points for which the series of \mcref{SP:probgenfunc} converges absolutely.
  \end{definition}
  \begin{lemma}
    Let $(\Omega,\mathcal{A},\Prob)$ be a probability space and $X$ be a random variable with support $\NN\cup\{0\}$. Then, $[-1,1]\subseteq \mathcal{D}_X$ and $g_X(s)=\Exp(s^X)$ (with the convention that $0^0=1$).
  \end{lemma}
  \begin{proof}
    Clearly $g_X(s)=\Exp(s^X)$ and furthermore $\forall s\in[-1,1]$ we have $s\in \mathcal{D}_X$ because:
    $$\sum_{k=0}^\infty \abs{s}^k\Prob(X=k)\leq \sum_{k=0}^\infty \Prob(X=k)=1<\infty$$
  \end{proof}
  \begin{theorem}
    Let $(\Omega,\mathcal{A},\Prob)$ be a probability space and $X$, $Y$ be random variables with support $\NN\cup\{0\}$. Then: $$X\overset{\text{d}}{=}Y\iff g_X=g_Y$$
    Moreover: $$\Prob(X=k)=\frac{{g_Y}^{(k)}(0)}{k!}\quad \forall k\geq 0$$
  \end{theorem}
  \begin{sproof}
    Note that $g_X(s)$ is a power series defined in a neighbourhood of $s=0$ (recall \mcref{MA:derivk_powerseries}).
  \end{sproof}
  \begin{theorem}
    Let $(\Omega,\mathcal{A},\Prob)$ be a probability space and $X$, $Y$ be independent random variables with support $\NN\cup\{0\}$. Then, $\forall s\in\mathcal{D}_X\cap \mathcal{D}_Y$ we have: $$g_{X+Y}(s)=g_X(s)g_Y(s)$$
  \end{theorem}
  \begin{proof}
    Note that if $s\in\mathcal{D}_X\cap \mathcal{D}_Y$, then $s\in\mathcal{D}_{X+Y}$ because
    $$g_{X+Y}(\abs{s})=\Exp\left(\abs{s}^{X+Y}\right)=\Exp\left(\abs{s}^X\right)\Exp\left(\abs{s}^Y\right)<\infty$$
    due to the independence of $X$ and $Y$.
    To show the equality if $s=0$, we have:
    $$\Prob(X+Y=0)=\Prob(X=0,Y=0)=\Prob(X=0)\Prob(Y=0)$$
    where the first equality is due to $X,Y\in\NN\cup\{0\}$ and the second one is becuse of the independence.
    If $s\ne 0$, as before: $$g_{X+Y}({s})=\Exp({s}^{X+Y})=\Exp({s}^X)\Exp({s}^Y)=g_{X}({s})g_{Y}({s})$$
  \end{proof}
  \begin{theorem}
    Let $(\Omega,\mathcal{A},\Prob)$ be a probability space and $X$ be a random variable with support $\NN\cup\{0\}$. Then, $\forall k\geq 1$ we have:
    $$\lim_{s\to 1^-}{g_X}^{(k)}(s)=\Exp(X(X-1)\cdots(X-k+1))$$
  \end{theorem}
  \begin{sproof}
    Take $(s_n)\in\RR$ such that $s_n\nearrow 1$. Differentiating term by term we have that:
    $$
      g_{X}^{(k)}(s_n)=\Exp(X(X-1)\cdots (X-k+1){(s_n)}^{X-k})
    $$
    for all $n\in\NN$. Moreover, note that $X(X-1)\cdots (X-k+1){(s_n)}^{X-k}\nearrow X(X-1)\cdots (X-k+1)$. Now use the \mnameref{P:monotone}.
  \end{sproof}
  \begin{center}
    \def\arraystretch{1.3}
    \begin{tabular}{|c|c|c|}
      \hline
      $X$                     & $g_X(s)$                            & $\mathcal{D}_X$                                          \\
      \hline
      $k\in\NN$               & $\displaystyle s^{k}$               & $\RR$                                                    \\
      %\hline
      $U(\{k_1,\ldots,k_n\})$ & $\frac{1}{n}\sum_{i=1}^n s^{k_i}$   & $\RR$                                                    \\
      %\hline
      $\text{B}(n,p)$         & $\displaystyle {(ps+1-p)}^n$        & $\RR$                                                    \\
      %\hline
      $\text{Pois}(\lambda)$  & $\displaystyle \exp{\lambda(s-1)}$  & $\RR$                                                    \\
      %\hline
      $\text{Geo}(p)$         & $\displaystyle \frac{ps}{1-(1-p)s}$ & $\displaystyle\left(\frac{-1}{1-p},\frac{1}{1-p}\right)$ \\
      %\hline
      \hline
    \end{tabular}
    \captionof{table}{Probability-generating functions of common distributions.}
  \end{center}
  \subsection{Discrete-time Markov chains}
  \subsubsection{Stochastic processes}
  \begin{definition}[Stochastic process]
    Let $T\subseteq \RR^n$ be a set, $(E,\mathcal{E})$ be a measurable space and $(\Omega,\mathcal{A},\Prob)$ be a probability space. A \emph{stochastic process} on $(\Omega,\mathcal{A},\Prob)$ with \emph{parameter set} $T$ and \emph{state space} $(E,\mathcal{E})$ is a family of random variables ${\{X_t\}}_{t\in T}$ from $(\Omega,\mathcal{A})$ to $(E,\mathcal{E})$. That is, $X_t:\Omega\to E$ satisfies ${X_t}^{-1}(B)\in\mathcal{A}$ for all $B\in\mathcal{E}$ and all $t\in T$.
  \end{definition}
  \begin{remark}
    In general, we wil consider stochastic processes with parameter sets $T=\NN,\NN\cup\{0\},\ZZ,\RR,\RR_{\geq 0}$ and state spaces $(\NN\cup\{0\},\mathcal{P}(\NN \cup \{0\}))$ or $(\RR,\mathcal{B}(\RR))$.
  \end{remark}
  \begin{definition}
    Let ${(X_t)}_{t\in T}$, ${(Y_t)}_{t\in T}$ be two stochastic processes defined on the same probability space $(\Omega,\mathcal{A},\Prob)$. We say that ${(X_t)}_{t\in T}$ and ${(Y_t)}_{t\in T}$ are \emph{independent} if $\forall n,k\in\NN$ and all $t_1,\ldots,t_n,s_1,\ldots,s_k\in T$ we have that the random vectors $(X_{t_1},\ldots,X_{t_n})$ and $(Y_{s_1},\ldots,Y_{s_k})$ are independent.
  \end{definition}
  \subsubsection{Galton-Watson process}
  \begin{model}\label{SP:galtonwatsonModel}
    Let $(X_n)$, $n\in\NN\cup\{0\}$ be a sequence of discrete random variables representing the number of new individuals of a certain population at the $n$-th generation. Suppose they are defined as $$X_{n+1}=\sum_{k=1}^{X_n}Z_{n+1}^{(k)}$$ and $X_0=1$. Here $Z_{n+1}^{(k)}$ has support $\NN\cup\{0\}$ $\forall n,k$ and represent the number of descendants (to the next generation) of the $k$-th individual of the $n$-th generation. Suppose that $Z_{n+1}^{(k)}\sim Z$ are \iid and independent of $(X_n)$. We would like to study the probability $\rho$ of extinction of this population: $$\rho=\Prob(\{X_n=0:\text{for some $n\in\NN$}\})=\Prob\left(\bigcup_{n=1}^\infty\{X_n=0\}\right)$$
  \end{model}
  \begin{lemma}\label{SP:lemmaGaltonWatson}
    Let $(Z_n)$ be a sequence of \iid random variables distributed as $Z$ with support $\NN\cup\{0\}$, and $N$ be a random variable also with support $\NN\cup\{0\}$ and independent to $(Z_n)$. Let $X=\sum_{k=1}^NZ_k$. Then, $\forall s\in[-1,1]$ we have: $$g_X(s)=g_N(g_Z(s))$$
  \end{lemma}
  \begin{proof}
    First suppose $N\leq M$ with $M\in\NN$ fixed. Then using the independence, the \mnameref{SP:totalexp} and the \mnameref{SP:substitutionPrinciple}:
    \begin{align*}
      g_X(s)=\Exp(s^X) & =\sum_{k=1}^M\Exp(s^X\mid N=k)\Prob(N=k)                                        \\
                       & = \sum_{k=1}^{M} \Exp\left(s^{\sum_{i=1}^{N}Z_i} \mid N = k\right) \Prob(N = k) \\
                       & = \sum_{k=1}^{M} \Exp\left(s^{\sum_{i=1}^{k}Z_i}\right) \Prob(N = k)            \\
                       & = \sum_{k=1}^{M} {g_Z(s)}^k \Prob(N = k)                                        \\
                       & = g_N(g_Z(s))
    \end{align*}
    Now if $N$ can take any value of $\NN\cup\{0\}$ we have that:
    \begin{align*}
      g_X(s) & =\Exp\left(s^{\sum_{i=1}^{N}Z_i}\right)                          \\
             & =\Exp\left(\lim_{M\to\infty}s^{\sum_{i=1}^{\min(N,M)}Z_i}\right) \\
             & =\lim_{M\to\infty}\Exp\left(s^{\sum_{i=1}^{\min(N,M)}Z_i}\right) \\
             & =\lim_{M\to\infty}g_{\min(N,M)}(g_Z(s))                          \\
             & =\lim_{M\to\infty}\Exp\left({(g_Z(s))}^{\min(N,M)}\right)        \\
             & =\Exp\left(\lim_{M\to\infty}{(g_Z(s))}^{\min(N,M)}\right)        \\
             & =g_N(g_Z(s))
    \end{align*}
    where both limit exchangings are due to the \mnameref{P:dominated} using the intagrable random variable 1.
  \end{proof}
  \begin{theorem}
    In the hypothesis of \mcref{SP:galtonwatsonModel}, we have that: $$\rho=g_Z(\rho)$$
  \end{theorem}
  \begin{proof}
    Note that $\{X_n=0\}\subseteq \{X_{n+1}=0\}$. Hence:
    $$\rho=\Prob\left(\bigcup_{n=1}^\infty\{X_n=0\}\right)\!=\lim_{n\to\infty}\Prob(X_n=0)=\lim_{n\to\infty}g_{X_n}(0)$$
    Now, using \mcref{SP:lemmaGaltonWatson} we have:
    $$g_{X_{n}}(s)=g_{X_{n-1}}(g_Z(s))=\cdots=g_{X_1}({g_Z}^n(s))$$
    But $X_1=1$ and so $g_{X_1}(s)=s$. So $g_{X_{n}}(s)={g_Z}^n(s)$ and therefore
    $g_{X_{n+1}}(0)=g_Z(g_{X_{n}}(0))$.
    Taking the limit as $n\to\infty$ and using the continuity of the pgf we get the result.
  \end{proof}
  \begin{theorem}
    In the hypothesis of \mcref{SP:galtonwatsonModel} and the additional assumption that $0<\Prob(Z=0)<1$ we have:
    \begin{enumerate}
      \item If $\Exp(Z)\leq 1$, $g_Z$ has only 1 fixed point (the trivial one, $s=1$). Hence, the population will extinct with probability 1.
      \item If $\Exp(Z)> 1$, $g_Z$ has a unique non-trivial fixed point on (0,1).
    \end{enumerate}
  \end{theorem}
  \begin{proof}
    First suppose $\Prob(Z=0)+\Prob(Z=1)=1$. Thus, $Z\almoste{\leq}1$ and so $\Exp(Z)\leq 1$. Moreover, $g_Z(s)=\Prob(Z=0)+s\Prob(Z=1)$, which is a line with slope $\Prob(Z=1)<1$. Hence, it has a unique fixed point, which is $s=1$.

    Now assume $\Prob(Z=0)+\Prob(Z=1)<1$. Then, $\exists k\geq 2$ with $\Prob(Z=k)>0$. Hence, ${g_Z}'(s)>0$ and ${g_Z}''(s)>0$ $\forall s\in (0,1)$. Now consider $f(s)=g(s)-s$. Note that $f$ is strictly convex in $(0,1)$ and $f(0)=g(0)=\Prob(Z=0)>0$. Finally, note that $$\lim_{t\to 1^-} f'(s)=\lim_{t\to 1^-}g(s)-1=\Exp(Z)-1$$
    and so $\displaystyle\lim_{t\to 1^-} f'(s)$ is negative in the first case and positive in the second case. This implies that $f$ has no zeros on $(0,1)$ in the first case and exactly 1 zero in $(0,1)$ in the second case.

    It's missing to see that in the second case the probability of extinction $\rho$ is given by the fixed point in $(0,1)$, rather than 1. We have that:
    $$\rho=\lim_{n\to\infty}g_{X_n}(0)=\lim_{n\to\infty}{g_Z}^n(0)$$
    Since ${g_Z}'>0$, we have that ${g_Z}$ is increasing and so it is ${g_Z}^n$ $\forall n\in\NN$. Moreover, if ${g_Z}(x_0)=x_0$, we have that ${g_Z}^n(x_0)=x_0$ $\forall n\in\NN$. Therefore, $$0<{g_Z}(0)<{g_Z}^2(0)<\cdots<{g_Z}^n(0)<\cdots <x_0<\cdots <1$$
    And so the limit has to be $x_0$ (note that the limit does exist because $({g_Z}^n(0))$ is an increasing bounded sequence).
  \end{proof}
  \subsubsection{Gambler's ruin}
  \begin{definition}[Gambler's ruin problem]
    Consider a gambler with an initial capital $z\in\ZZ$ and suppose that he plays a game in which wins 1 unit of capital with probability $p$ and loses 1 unit of capital with probability $q:=1-p$. The game ends whenever the player is ruined or if he arrives to a capital of $a\in\ZZ$. All the plays are independent. We denote by $(X_k)$ the variables that measure the $k$-th play. That is: $$\Prob(X_k=1)=p\qquad\Prob(X_k=-1)=q$$
    We define $q_z$ as the probability of ruining himself starting with a capital of $z$, $p_z$ as the probability of winning the game starting with a capital of $z$ and $D_z$ as the duration of the game starting with a capital of $z$.
  \end{definition}
  \begin{proposition}
    Consider the Gambler's ruin problem. Then:
    $$q_z=\begin{cases}
        \frac{-{\left(\frac{q}{p}\right)}^a+{\left(\frac{q}{p}\right)}^z}{1-{\left(\frac{q}{p}\right)}^a} & \text{if $p\ne 1/2$} \\
        1-\frac{z}{a}                                                                                     & \text{if $p= 1/2$}
      \end{cases}$$
  \end{proposition}
  \begin{sproof}
    We have that $q_k$ solves the difference equation
    \begin{multline*}
      q_k =\Prob(\text{ruin}\mid X_k=1)\Prob(X_1=1)+\\
      +\Prob(\text{ruin}\mid X_k=-1)\Prob(X_1=-1) =q_{k+1}p+q_{k-1}q
    \end{multline*}
    with $q_0=1$ and $q_a=0$, whose solution is straightforward.
  \end{sproof}
  \begin{proposition}
    Consider the Gambler's ruin problem. Suppose that we play against another player (and so when we lose, he wins and viceversa). Let $p_z^*$, $q_z^*$ be the respective probabilities for the other player. Then:
    $$q_z+q_z^*=1$$
    Hence, $D_z\almoste{<}\infty$.
  \end{proposition}
  \begin{sproof}
    Note that
    $$q_z^*=\begin{cases}
        \frac{-{\left(\frac{p}{q}\right)}^a+{\left(\frac{p}{q}\right)}^{a-z}}{1-{\left(\frac{p}{q}\right)}^a} & \text{if $p\ne 1/2$} \\
        1-\frac{a-z}{a}                                                                                       & \text{if $p= 1/2$}
      \end{cases}$$
  \end{sproof}
  \begin{proposition}
    Let $d_z=\Exp(D_z)$ and suppose that this expectation is finite. Then:
    $$
      d_z=\begin{cases}
        \frac{z}{q-p}-\frac{a}{q-p}\frac{1-{\left(\frac{q}{p}\right)}^z}{1-{\left(\frac{q}{p}\right)}^a} & \text{if $p\ne 1/2$} \\
        z(a-z)                                                                                           & \text{if $p= 1/2$}
      \end{cases}
    $$
  \end{proposition}
  \begin{proof}
    We have that $q_k$ solves the difference equation:
    \begin{multline*}
      d_k =\Exp(D_k\mid X_k=1)\Prob(X_1=1)+\\
      +\Exp(D_k\mid X_k=-1)\Prob(X_1=-1) =\\=\Exp(D_{k+1}+1)p+\Exp(D_{k-1}+1)q= d_{k+1}p+d_{k-1}q+1
    \end{multline*}
    with $d_0=0$ and $d_a=0$, whose solution is straightforward ($d_k=\frac{k}{p-q}$ and $d_k=-k^2$ are particular solutions for the case $p\ne q$ and $p=q$, respectively).
  \end{proof}
  \subsubsection{Markov chains}
  \begin{definition}
    A \emph{Markov chain} is a sequence of discrete random variables $(X_n)$ with support $I$ such that:
    \begin{multline*}
      \Prob(X_{n+1}=j\mid X_0=i_0,\ldots,X_{n-1}=i_{n-1},X_n=i)=\\=\Prob(X_{n+1}=j\mid X_n=i)
    \end{multline*} for all $n\geq 0$ and all $i_0,\ldots,i_{n-1},i,j\in I$. This property is usually called \emph{Markov property}.
    If moreover $\Prob(X_{n+1}=j\mid X_n=i)$ does not depend on $n$, that is
    $$\Prob(X_{n+1}=j\mid X_n=i)=\Prob(X_{1}=j\mid X_0=i)$$
    then we say that the Markov chain is a \emph{time-homogeneous Markov chain}. The set $I$ is called \emph{state space} and its elements are called \emph{states} of the Markov chain.
  \end{definition}
  \begin{definition}[Stochastic matrix]
    Let $I$ be an index set. A matrix $\vf{P}=(p_{ij})_{i,j\in I}$ is called a \emph{stochastic matrix} if $p_{ij}\geq 0$ $\forall i,j\in I$ and: $$\sum_{j\in I}p_{ij}=1$$
  \end{definition}
  \begin{definition}
    Let $(X_n)$ be a time-homogeneous Markov chain. We define the \emph{transition probabilities} $p_{ij}$ as the probability of going from state $i$ to state $j$. That is: $$p_{ij}=\Prob(X_{1}=j\mid X_0=i)$$
    The matrix $\vf{P}=(p_{ij})_{i,j\in I}$ is called the \emph{transition matrix} of the Markov chain. Finally, we define the probabilities $\pi_i$ as $\pi_i=\Prob(X_0=i)$. We define the vector $\vf{\pi}=(\pi_i)_{i\in I}$ as the \emph{initial distribution} of the Markov chain.
  \end{definition}
  \begin{proposition}
    Let $(X_n)$ be a time-homogeneous Markov chain. Then:
    \begin{enumerate}
      \item $\vf{P}$ is a stochastic matrix.
      \item $\sum_{i\in I}\pi_i=1$.
    \end{enumerate}
  \end{proposition}
  \begin{lemma}
    Let $I$, $F$ be finite or countable set, $(Z_n)$ be a sequence of random variables with support $F$, $X_0$ be a random variable with support $I$ and $f:I\times F\rightarrow I$ be a function. Consider the sequence $(X_n)$ defined by:
    $$
      X_{n+1}=f(X_n,Z_{n+1})
    $$
    If $\forall i_0,\ldots,i_{n-1},i\in I$ and $\forall k\in F$ we have:
    \begin{multline*}
      \Prob(Z_{n+1}=k\mid X_0=i_0,\ldots,X_{n-1}=i_{n-1},X_n=i)=\\=\Prob(Z_{n+1}=k\mid X_n=i)=\Prob(Z_{1}=k\mid X_0=i)
    \end{multline*}
    then $(X_n)$ is a time-homogeneous Markov chain with transition matrix $\vf{P}=(p_{ij})_{i,j\in I}$ given by:
    $$
      p_{ij}=\Prob(f(i,Z_1)=j\mid X_0=i)
    $$
  \end{lemma}
  \begin{proof}
    Let $C=\{X_0=i_0,\ldots,X_{n-1}=i_{n-1},X_n=i\}$ and let $A_{i,j}:=\{k\in F:f(i,k)=j\}$. We have:
    \begin{align*}
      \Prob(X_{n+1}=j\mid C) & =\Prob(f(i,Z_{n+1})=j\mid C)                 \\
                             & =\Prob(Z_{n+1}\in A_{i,j}\mid C)             \\
                             & =\sum_{k\in A_{i,j}}\Prob(Z_{n+1}=k\mid C)   \\
                             & =\sum_{k\in A_{i,j}}\Prob(Z_{1}=k\mid X_0=i) \\
                             & =\Prob(f(i,Z_{1})=j\mid X_0=i)
    \end{align*}
  \end{proof}
  \begin{definition}[Random walk]
    A \emph{random walk} is a sequence $(\vf{S}_n)$ with $\vf{S}_0=\vf{X}_0$ and $\vf{S}_n=\sum_{k=0}^{n}\vf{X}_k$, where $(\vf{X}_k)_{k\geq 1}$ is a sequence of \iid random vectors and $\vf{X}_0$ is a random vector independent of $(\vf{X}_k)$.
  \end{definition}
  \begin{definition}
    A \emph{simple random walk} is a random walk in which in one step we can only pass from one state to its neighbours. That is, if the random walk is in $\ZZ$, $X_k$ are random variables such that:
    $$
      X_k=\begin{cases}
        1  & \text{with probability $p$}   \\
        -1 & \text{with probability $1-p$}
      \end{cases}
    $$
  \end{definition}
  \begin{figure}[H]
    \centering
    \includestandalone[mode=image|tex,width=0.75\linewidth]{Images/randomWalk}
    \caption{A simple random walk of 10000 steps in $\ZZ^2$. The green and blue dots are the respective initial and final positions of the random walk.}
    \label{fig:simple_random_walk}
  \end{figure}
  \begin{lemma}
    A sequence of \iid random variables, a random walk and a Galton-Watson process are all time-homogeneous Markov chains.
  \end{lemma}
  \begin{definition}
    Let $(X_n)$ be a time-homogeneous Markov chain. We define the \emph{$n$-step transition probabilities} $p_{ij}^{(n)}$ as the probability of going from state $i$ to state $j$ in $n$ steps. That is: $$p_{ij}^{(n)}=\Prob(X_{n}=j\mid X_0=i)$$ The matrix $\vf{P}^{(n)}=(p_{ij}^{(n)})_{i,j\in I}$ is called \emph{$n$-step transition matrix} of the Markov chain.
  \end{definition}
  \begin{definition}
    Let $(X_n)$ be a time-homogeneous Markov chain. We define the probabilities $\pi_i^{(n)}$ as the probability of being in state $i$ after $n$ steps. That is: $$\pi_i^{(n)}=\Prob(X_n=i)$$
    We define the vector $\vf{\pi}^{(n)}=(\pi_i^{(n)})_{i\in I}$ as \emph{$n$-step distribution} of the Markov chain.
  \end{definition}
  \begin{lemma}\label{SP:lema1Markov}
    Let $A$, $B$, $C$ be events in a probability space such that $\Prob(B\cap C)>0$. Then:
    $$\Prob(A\cap B\mid C)=\Prob(B\mid C)\Prob(A\mid B\cap C)$$
  \end{lemma}
  \begin{proof}
    \begin{align*}
      \Prob(A\cap B\mid C) & =\frac{\Prob(A\cap B\cap C)}{\Prob(C)}\frac{\Prob(B\cap C)}{\Prob(B\cap C)} \\
                           & =\Prob(B\mid C)\Prob(A\mid B\cap C)
    \end{align*}
  \end{proof}
  \begin{lemma}\label{SP:lema2Markov}
    Let $I$ be a finite or countable set and $A$ and $D_i$ for $i\in I$ be events in a probability space such that $\Prob(A\mid D_i)=p$ for all $i\in I$ and such that the $D_i$ are pairwise disjoint. Then:
    $$\Prob\left(A\mid \bigsqcup_{i\in I}D_i\right)=p$$
  \end{lemma}
  \begin{proof}
    \begin{align*}
      \Prob\left(A\mid \bigsqcup_{i\in I}D_i\right) & =\frac{\Prob(A\cap \bigsqcup_{i\in I}D_i)}{\Prob(\bigsqcup_{i\in I}D_i)} \\
                                                    & =\frac{\sum_{i\in I}\Prob(A\cap D_i)}{\sum_{i\in I}\Prob(D_i)}           \\
                                                    & =\frac{\sum_{i\in I}\Prob(A\mid D_i)\Prob(D_i)}{\sum_{i\in I}\Prob(D_i)} \\
                                                    & =\frac{\sum_{i\in I}p\Prob(D_i)}{\sum_{i\in I}\Prob(D_i)}                \\
                                                    & =p
    \end{align*}
  \end{proof}
  \begin{theorem}
    Let $(X_n)$ be a time-homogeneous Markov chain. Then, $\vf{P}^{(n)}=\vf{P}^n$.
  \end{theorem}
  \begin{proof}
    By induction on $n$. The case $n=1$ is clear. For $n\geq 2$ we have:
    \begin{align*}
      p_{ij}^{(n+1)} & =\Prob(X_{n+1}=j\mid X_0=i)                     \\
                     & =\sum_{k\in I}\Prob(X_{n+1}=j, X_n=k\mid X_0=i) \\
      \begin{split}
        &=\sum_{k\in I}\Prob(X_{n}=k\mid X_0=i)\cdot\\
        &\hspace{2.5cm}\cdot\Prob(X_{n+1}=j\mid X_n=k, X_0=i)
      \end{split}             \\
                     & =\sum_{k\in I}p_{ik}^{(n)}p_{kj}^{(1)}
    \end{align*}
    where the penultimate equality follows from \mcref{SP:lema1Markov} and the last equality follows from \mcref{SP:lema2Markov} and the Markov property because if $D=\{X_n=k, X_0=i\}$ we have that:
    \begin{multline*}
      D=\bigsqcup_{i_1,\ldots,i_{n-1}\in I}\{X_n=k, X_0=i,X_1=i_1,\ldots, X_{n-1}=\\=i_{n-1}\}
    \end{multline*}
    and so:
    \begin{multline*}
      \Prob(X_{n+1}=j\mid X_n=k, X_0=i)=\Prob(X_{n+1}=j\mid X_n=k,\\ X_0=i,X_1=i_1,\ldots,X_{n-1}=i_{n-1})=\\=\Prob(X_{n+1}=j\mid X_n=k)
    \end{multline*}
    Therefore, $\vf{P}^{(n+1)}=\vf{P}^n\vf{P}$, by induction hypothesis.
  \end{proof}
  \begin{theorem}[Chapman-Kolmogorov equation]\label{SP:ChapKolmo}
    Let $(X_n)$ be a time-homogeneous Markov chain and $i,j\in I$. Then:
    $$p_{ij}^{(m+n)}=\sum_{k\in I}p_{ik}^{(m)}p_{kj}^{(n)}$$
  \end{theorem}
  \begin{proposition}
    Let $(X_n)$ be a time-homogeneous Markov chain. Then:
    \begin{enumerate}
      \item $\vf{P}^{(0)}=\vf{I}_I$
      \item $\vf{\pi}^{(n)}=\vf{\pi}^{(0)}\vf{P}^n$
      \item $\Prob(X_0=i_0,\ldots,X_n=i_n)=\pi_{i_0}^{(0)}p_{i_0i_1}\cdots p_{i_{n-1}i_n}$
    \end{enumerate}
  \end{proposition}
  \begin{sproof}
    \begin{enumerate}
      \item $p_{ij}^{(0)}=\Prob(X_1=j\mid X_0=i)=\delta_{ij}$.
      \item
            \begin{multline*}
              \pi_i^{(n)}=\Prob(X_n=i)=\sum_{k\in I}\Prob(X_n=i\mid X_0=k)\cdot\\\cdot\Prob(X_0=k)=\sum_{k\in I}\pi_k^{(0)}p_{ki}^{(n)}
            \end{multline*}
      \item Use the \mnameref{P:totalprob} and the Markov property.
    \end{enumerate}
  \end{sproof}
  \subsubsection{Classification of states}
  \begin{definition}
    Let $(X_n)$ be a time-homogeneous Markov chain. We say that a state $j\in I$ is \emph{reachable} from $i\in I$ if $\exists n\in \NN\cup\{0\}$ such that $p_{ij}^{(n)}>0$. In this case we will write $i\to j$.
  \end{definition}
  \begin{definition}
    Let $(X_n)$ be a time-homogeneous Markov chain. We say that two states $i,j\in I$ \emph{communicate} if $i\to j$ and $j\to i$. In this case we will write $i\leftrightarrow j$.
  \end{definition}
  \begin{lemma}
    Let $(X_n)$ be a time-homogeneous Markov chain. Then, the relation $\leftrightarrow$ is an equivalence relation.
  \end{lemma}
  \begin{proof}
    The reflexivity and symmetry are clear. For the transitivity, suppose $i\leftrightarrow j$ and $j\leftrightarrow k$. Then, $\exists n,m\in I$ such that $p_{ij}^{(n)}>0$ and $p_{jk}^{(m)}>0$. Then by \mnameref{SP:ChapKolmo}:
    \begin{equation}\label{SP:corolariChapKolmo}
      p_{ik}^{(n+m)}=\sum_{\ell\in I} p_{i\ell}^{(n)}p_{\ell k}^{(m)}\geq p_{ij}^{(n)}p_{jk}^{(m)}>0
    \end{equation}
    Similarly, we have $p_{ki}^{(r+s)}>0$ for some $r,s\in I$. Therefore, $i\leftrightarrow k$.
  \end{proof}
  \begin{definition}
    Let $(X_n)$ be a time-homogeneous Markov chain. A subset $C\subseteq I$ is called \emph{irreducible class} if for any $i,j\in C$ we have $i\leftrightarrow j$. That is, if $C$ is an equivalence class of $\leftrightarrow$. If all the states are in the same equivalence class, then the Markov chain is called an \emph{irreducible chain}.
  \end{definition}
  \begin{definition}
    Let $(X_n)$ be a time-homogeneous Markov chain and $i\in I$. We define the \emph{period} of $i$ as:
    $$d(i):=\gcd\{n\in\NN:p_{ii}^{(n)}>0\}$$
    with the convention that if $\{n\in\NN:p_{ii}^{(n)}>0\}=\varnothing$, then $d(i)=\infty$. If $d(i)=1$ we say that $i$ is \emph{aperiodic}.
  \end{definition}
  \begin{proposition}\label{SP:period_classes}
    Let $(X_n)$ be a time-homogeneous Markov chain and $i,j\in I$. Then: $$i\leftrightarrow j\implies d(i)=d(j)$$
  \end{proposition}
  \begin{proof}
    Suppose $i\ne j$. We will see that if $p_{jj}^{(n)}>0$, then $d(i)\mid n$. Since $i\leftrightarrow j$, then $\exists r,s\in I$ such that $p_{ij}^{(r)}>0$ and $p_{ji}^{(s)}>0$. So as in \mcref{SP:corolariChapKolmo}, we have $p_{ii}^{(r+s)}>0$. Thus, $d(i)\mid r+s$. Moreover, if $p_{jj}^{(n)}>0$, then:
    $$p_{ii}^{(r+n+s)}\geq p_{ij}^{(r)}p_{jj}^{(n)}p_{ji}^{(s)}>0$$
    So $d(i)\mid r+n+s$. Thus, $d(i)\mid n$ and so $d(j)\geq d(i)$ because $d(j)$ is the greatest common divisor of all such $n$. Repeating the argument exchanging $i$ and $j$ we get $d(j)= d(i)$.
  \end{proof}
  \begin{definition}
    Let $(X_n)$ be a time-homogeneous Markov chain. If the chain is irreducible, we will denote the common period by $d$. If $d=1$ we say that the chain is \emph{aperiodic}.
  \end{definition}
  \begin{proposition}
    Let $(X_n)$ be a time-homogeneous Markov chain. Suppose we have an irreducible chain of period $d>1$. Then, there exist subsets $C_0,\ldots,C_{d-1}\subseteq I$ such that $I=C_0\sqcup\cdots\sqcup C_{d-1}$ and such that if $j\in C_\alpha$, then:
    $$p_{jk}>0\implies k\in C_{{[\alpha+1]}_d}$$
    for all $k\in I$. Here ${[\alpha+1]}_d$ denotes $\alpha+1\mod{d}$.
  \end{proposition}
  \begin{proof}
    Let $i\in I$ and define
    $$C_\alpha:=\{j\in I:\exists n\in\NN\cup\{0\}\text{ with }p_{ij}^{(n d+\alpha)}>0\}$$
    Clearly $C_0\cup\cdots\cup C_{d-1}=I$. Let's see that $C_\alpha\cap C_\beta=\varnothing$ if $\alpha\ne\beta$. Suppose $k\in C_\alpha\cap C_\beta$. Note that since the chain is irreducible, $\exists m\in\NN\cup\{0\}$ such that $p_{ki}^{(m)}>0$. And so, as in \mcref{SP:corolariChapKolmo} we have $p_{kk}^{(n d+\alpha+m)}>0$ because $k\in C_\alpha$. Thus, $d\mid \alpha+m$. The same argument with $\beta$ implies $d\mid \beta+m$. So $d\mid \beta -\alpha$ and $\beta=\alpha$ because $\alpha,\beta\in\{0,\cdots,d-1\}$.

    Finally, if $j\in C_\alpha$ is such that $p_{jk}>0$ for $k\in I$, then as in \mcref{SP:corolariChapKolmo} we have $p_{ik}^{(n d+\alpha +1)}>0$. So, if $\alpha+1\leq d-1$, then $k\in C_{\alpha+1}$. Otherwise, $k\in C_0=C_{[\alpha+1]_d}$.
  \end{proof}
  \subsubsection{Stopping time and strong Markov property}
  \begin{proposition}\label{SP:MarkovImproved}
    Let $(X_n)$ be a time-homogeneous Markov chain, $k\in\NN$ and $A\subseteq I^k$ and $B\subseteq I^n$. Then:
    \begin{multline*}
      \Prob((X_{n+1},\ldots,X_{n+k})\in A\mid\!(X_0,\ldots,X_{n-1})\in B,X_n=i)=\\
      =\Prob((X_{n+1},\ldots,X_{n+k})\in A\mid X_n=i)=\\
      =\Prob((X_{1},\ldots,X_{k})\in A\mid X_0=i)
    \end{multline*}
    for all $n\geq 0$.
  \end{proposition}
  \begin{proof}
    By \mcref{SP:lema2Markov} it suffices to prove the statement for $B=\{i_0\}\times\cdots\times\{i_{n-1}\}$. Moreover, since $A$ is countable we can suppose $A=\{j_1\}\times\cdots\times\{j_k\}$. We will prove it by induction on $k$ the homogeneous equality (the other one is even easier). The case $k=1$ is by definition. Now suppose $k\geq 2$. Then, denoting $C:=\{X_0=i_0,\ldots,X_{n-1}=i_{n-1},X_n=i\}$ we have:
    \begin{multline*}
      \Prob(X_{n+1}=j_1,\ldots,X_{n+k+1}=j_{k+1}\mid C) \\
      =\Prob(X_{n+k+1}=j_{k+1}\mid C,X_{n+1}=j_1,\ldots,X_{n+k}=j_k)\cdot\\
      \cdot\Prob(X_{n+1}=j_1,\ldots,X_{n+k}=j_k\mid C) \\
      =\Prob(X_{k+1}=j_{k+1}\mid X_0=i,X_{1}=j_1,\ldots,X_{k}=j_k)\cdot\\
      \cdot\Prob(X_{1}=j_1,\ldots,X_{k}=j_k\mid X_0=i) \\
      =\Prob(X_{1}=j_1,\ldots,X_{k+1}=j_{k+1}\mid X_0=i)
    \end{multline*}
    where in the second equality we have used the Markov property, the homogeneous property and induction hypothesis.
  \end{proof}
  \begin{definition}
    Let $(\Omega,\mathcal{A},\Prob)$ be a probability space and let $I$ be a finite or countable set. For each $i\in I$, let $\mathcal{F}_i$ be a sub $\sigma$-algebra of $\mathcal{A}$, that is a subset of $\mathcal{A}$ which also $\sigma$-algebra. We say that $(\mathcal{F}_i)_{i\in I}$ is \emph{filtration} if for all $i\in I$ we have $\mathcal{F}_i\subseteq\mathcal{F}_{i+1}$. The tuple $(\Omega,\mathcal{A},(\mathcal{F}_i)_{i\in I},\Prob)$ is called a \emph{filtration space}.
  \end{definition}
  \begin{definition}
    Let $(\Omega,\mathcal{A},\Prob)$ be a probability space and $\vf{X}$ be a random vector. The \emph{$\sigma$-algebra generated by $\vf{X}$} is:
    $$\sigma(\vf{X}):=\{\vf{X}^{-1}(B):B\in\mathcal{B}(\RR^n)\}$$
  \end{definition}
  \begin{proposition}
    Let $(\Omega,\mathcal{A},\Prob)$ be a probability space and $(X_n)$ be a time-homogeneous Markov chain. Then, if $\mathcal{F}_n:=\sigma(X_0,\ldots,X_n)$, the sequence $(\mathcal{F}_n)_{n\geq 0}$ is a filtration.
  \end{proposition}
  \begin{proof}
    Take $F\in\mathcal{F}_n$. Then:
    \begin{multline*}
      F=\{(X_0,\ldots,X_n)\in B\subseteq I^{n+1}\}=\\=\{(X_0,\ldots,X_n,X_{n+1})\in B\times I\subseteq I^{n+2}\}\in\mathcal{F}_{n+1}
    \end{multline*}
  \end{proof}
  \begin{definition}
    Let $(\Omega,\mathcal{F},(\mathcal{F}_n)_{n\geq 0},\Prob)$ be a filtration space and $\tau$ a random variable on it with support $\NN\cup\{0\}$. We say that $\tau$ is a \emph{stopping time} if $\forall n\geq 0$ we have:
    $$\{\tau= n\}\in\mathcal{F}_n$$
  \end{definition}
  \begin{remark}
    Intuitively, this condition means that the ``decision" of whether to stop at time $n$ must be based only on the information present at time $n$, not on any future information.
  \end{remark}
  \begin{lemma}
    Let $(\Omega,\mathcal{F},(\mathcal{F}_n)_{n\geq 0},\Prob)$ be a filtration space and $\tau$ be a random variable. Then:
    $$\tau\text{ is a stopping time}\iff\{\tau\leq n\}\in\mathcal{F}_n$$
  \end{lemma}
  \begin{proof}
    \begin{itemizeiff}
      $\displaystyle\{\tau\leq n\}=\bigsqcup_{m=1}^n\{\tau=m\}\in \mathcal{F}_n$
      because $\{\tau=m\}\in \mathcal{F}_{m}\subseteq \mathcal{F}_{n}$ $\forall m\leq n$.
      \item $\displaystyle\{\tau = n\}=\{\tau\leq n\}\setminus\{\tau\leq n-1\}\in \mathcal{F}_n$
      because $\{\tau\leq n-1\}\in \mathcal{F}_{n-1}\subseteq \mathcal{F}_{n}$.
    \end{itemizeiff}
  \end{proof}
  \begin{proposition}
    Let $(X_n)$ be a time-homogeneous Markov chain, $(\Omega,\mathcal{F},(\mathcal{F}_n)_{n\geq 0},\Prob)$ be a filtration space defined with $(X_n)$, $i\in I$ and $\tau_i$ be the random variable with support $\NN\cup\{0,\infty\}$ defined by:
    \begin{equation}\label{SP:tau_i}
      \tau_i(\omega)=\inf\{n\geq 1:X_n(\omega)=i\}
    \end{equation}
    with the convention that $\inf\varnothing=+\infty$.
    Then, $\tau_i$ is a stopping time.
  \end{proposition}
  \begin{proof}
    If $n=0$, then $\{\tau_i=0\}=\varnothing\in\mathcal{F}_0$. If $n=1$, then $\{\tau_i=1\}=\{X_0\in I,X_1=i\}\in\mathcal{F}_1$. If $n\geq 2$, then:
    $$\{\tau_i=n\}=\{X_0\in I,X_1,\ldots,X_{n-1}\in  \{i\}^c,X_n=i\}\in\mathcal{F}_n$$
  \end{proof}
  \begin{theorem}[Strong Markov property]\label{SP:MarkovStrong}
    Let $(X_n)$ be a time-homogeneous Markov chain, $(\Omega,\mathcal{F},(\mathcal{F}_n)_{n\geq 0},\Prob)$ be a filtration space defined with $(X_n)$ and $\tau$ be a stopping time. Suppose that $\Prob(\tau<\infty)>0$. Then:
    \begin{multline*}
      \Prob(X_{\tau+n+1}=j\mid X_{\tau}=i_0,\ldots,X_{\tau+n-1}=i_{n-1},X_{\tau +n}=i,\\\tau<\infty)=\Prob(X_{\tau+n+1}=j\mid X_{\tau+n}=i,\tau<\infty)=\\=\Prob(X_{1}=j\mid X_0=i)
    \end{multline*}
    on account that $\Prob(A)>0$, where $A:=\{X_{\tau}=i_0,\ldots,X_{\tau+n-1}=i_{n-1},X_{\tau +n}=i,\tau<\infty\}$.
  \end{theorem}
  \begin{proof}
    \begin{multline*}
      \Prob(X_{\tau+n+1}=j\mid A) =\sum_{m=0}^{\infty}\Prob(X_{\tau+n+1}=j,\tau=m\mid A)= \\
      =\sum_{\substack{m=0 \\\Prob(\tau=m,A)>0}}^{\infty}\Prob(X_{m+n+1}\mid A,\tau=m)\Prob(\tau=m\mid A)
    \end{multline*}
    Now note that since $\{\tau=m\}\in\mathcal{F}_m$, we can write:
    \begin{equation*}
      \{\tau=m\}=\bigsqcup_{j_0,\ldots,j_m}\{X_0=j_0,\ldots,X_m=j_m\}
    \end{equation*}
    for some $j_0,\ldots,j_m\in I$. But since $\Prob(\tau=m,A)>0$, we have that in this last expression $j_m=i_0$ and so using \mcref{SP:MarkovImproved} we get:
    \begin{multline*}
      \Prob(X_{\tau+n+1}=j\mid A) =\sum_{\substack{m=0 \\\Prob(\tau=m,A)>0}}^{\infty}\Prob(X_1=j\mid X_0=i)\cdot\\\cdot\Prob(\tau=m\mid A)=\Prob(X_1=j\mid X_0=i)
    \end{multline*}
  \end{proof}
  \begin{corollary}[Strong Markov property]\label{SP:MarkovStrong2}
    Let $(X_n)$ be a time-homogeneous Markov chain, $(\Omega,\mathcal{F},(\mathcal{F}_n)_{n\geq 0},\Prob)$ be a filtration space defined with $(X_n)$, $\tau$ be a stopping time, $k\in\NN$ and $A\subseteq I^k$ and $B\subseteq I^n$. Suppose that $\Prob(\tau<\infty)>0$. Then:
    \begin{multline*}
      \Prob((X_{\tau+n+1},\ldots,X_{\tau+n+k})\in A\mid (X_{\tau},,\ldots,X_{\tau+n-1})\in B, \\X_{\tau +n}=i,\tau<\infty)=\Prob((X_{1},\ldots,X_{k})\in A\mid X_0=i)
    \end{multline*}
    for all $n\geq 0$.
  \end{corollary}
  \subsubsection{Recurrence and transience}
  From now on we will omit saying that a stopping time $\tau$ is defined in a filtration space $(\Omega,\mathcal{F},(\mathcal{F}_n)_{n\geq 0},\Prob)$. Moreover, given a Markov chain $(X_n)$, we will denote by $\Prob_i(A):=\Prob(A\mid X_0=i)$ and $\Exp_i(A):=\Exp(A\mid X_0=i)$, for any event $A$.
  \begin{definition}
    Let $(X_n)$ be a time-homogeneous Markov chain, $i,j\in I$ and consider the stopping time $\tau_j$ of \mcref{SP:tau_i}. We define $f_{ij}:=\Prob_i(\tau_j<\infty)$. We say that $i$ is \emph{transient} if $f_{ii}<1$ and \emph{recurrent} if $f_{ii}=1$. Finally, we define $N_i$ as:
    $$
      N_i:=\abs{\{n\in\NN:X_n=i\}}=\sum_{n=1}^{\infty}\indi{\{X_n=i\}}
    $$
  \end{definition}
  \begin{remark}
    Roughly speaking, if $i$ is recurrent it means that the chain will return at least once to $i$. On the other hand, if $i$ is transient, it means that the chain may never return to $i$.
  \end{remark}
  \begin{definition}
    Let $(X_n)$ be a time-homogeneous Markov chain, $i,j\in I$ and consider the stopping time $\tau_j$ of \mcref{SP:tau_i}. For $k\geq 2$, we define the \emph{$k$-th hitting time} of $i$ by:
    $$
      \tau_i^k:= \inf\{n>\tau_i^{k-1}:X_n=i\}
    $$
    with the convention that $\tau_i^1=\tau_i$ and $\tau_i^0=0$. Moreover, we define the time difference $T_i^k:=\tau_i^k-\tau_i^{k-1}$.
  \end{definition}
  \begin{lemma}
    Let $(X_n)$ be a time-homogeneous Markov chain. Then, $\tau_i^k$ is a stopping time $\forall k\in\NN$ and moreover $T_i^k$ are \iid random variables distributed as $\tau_i$ with respect to the probability $\Prob_i$.
  \end{lemma}
  \begin{proof}
    We need to check that $\forall m_1,\ldots,m_k\in\NN$:
    $$
      \Prob_i(T_i^1=m_1,\ldots,T_i^k=m_k)=\Prob_i(\tau_i=m_1)\cdots\Prob_i(\tau_i=m_k)
    $$
    We expand the left-hand side using the \mnameref{P:compound}. Now we examine each term of the product, which have the form:
    $$
      p_{\ell}:=\Prob_i(T_i^\ell=m_\ell\mid T_i^1=m_1,\ldots,T_i^{\ell-1}=m_{\ell-1})
    $$
    We have that:
    \begin{equation*}
      p_\ell=\Prob_i(\tau_i^{\ell}-\tau_i^{\ell-1}=m_\ell\mid A)
    \end{equation*}
    where $A=\{X_0=i,X_1\ne i, \ldots, X_{m_1-1}\ne i,X_{m_1}=i, X_{m_1+1}\ne i,\ldots, X_{m_1+\cdots+m_{\ell-1}}=i\}$. So, by the \mnameref{SP:substitutionPrinciple} we have:
    \begin{align*}
      \begin{split}
        p_\ell&=\Prob_i(X_{m_1+\cdots+m_\ell}=i,X_{m_1+\cdots+m_\ell-1}\ne i,\ldots,\\
        &\hspace{4cm}X_{m_1+\cdots+m_{\ell-1}+1}\ne i\mid A)
      \end{split} \\
       & =\Prob_i(X_{m_\ell}=i,X_{m_\ell-1}\ne i,\ldots,X_{1}\mid X_{0}=i)          \\
       & =\Prob(\tau_i=m_\ell)
    \end{align*}
  \end{proof}
  \begin{proposition}\label{SP:recurrence}
    Let $(X_n)$ be a time-homogeneous Markov chain and $i\in I$. Then:
    $$
      \Prob_i(N_i\geq k)={(f_{ii})}^k
    $$
  \end{proposition}
  \begin{proof}
    First suppose $f_{ii}=0$. Then:
    $$
      \Prob_i(N_i\geq k)\leq\Prob_i(N_i\geq 1)=\Prob_i(\tau_i<\infty)=f_{ii}=0
    $$
    Now assume $f_{ii}=\Prob_i(\tau_i<\infty)>0$. We will prove the statement by induction on $k$. The case $k=1$ is clear. Note that $\{\tau_i^k<\infty\}\subseteq \{\tau_i^{k-1}<\infty\}$. Thus:
    \begin{multline*}
      \Prob_i(N_i\geq k) =\Prob_i(\tau_i^k<\infty)=\Prob_i(\tau_i^k<\infty,\tau_i^{k-1}<\infty)\\=\Prob_i(\tau_i^{k-1}<\infty)\Prob_i(\tau_i^k<\infty\mid\tau_i^{k-1}<\infty)=\\={(f_{ii})}^{k-1}\Prob_i(\tau_i^k<\infty\mid\tau_i^{k-1}<\infty)
    \end{multline*}
    So it's missing to prove that $\Prob_i(\tau_i^k<\infty\mid\tau_i^{k-1}<\infty)={f_{ii}}$. But:
    \begin{multline*}
      \Prob_i(\tau_i^k<\infty\mid\tau_i^{k-1}<\infty)=\\=\sum_{m=1}^{\infty}\Prob_i(\tau_i^k=m+\tau_i^{k-1}\mid\tau_i^{k-1}<\infty)\\=\sum_{m=1}^{\infty}\Prob_i(\tau_i^k=m+\tau_i^{k-1}\mid X_{\tau_i^{k-1}}=i,\tau_i^{k-1}<\infty)
      \\=\sum_{m=1}^{\infty}\Prob_i( X_{\tau_i^{k-1}+1}\ne i,\ldots,X_{\tau_i^{k-1}+m-1}\ne i,\\X_{\tau_i^{k-1}+m}=i\mid X_{\tau_i^{k-1}}=i,\tau_i^{k-1}<\infty)
      \\=\sum_{m=1}^{\infty}\Prob_i( X_{1}\ne i,\ldots,X_{m-1}\ne i,X_{m}=i)=\\=\sum_{m=1}^{\infty}\Prob_i(\tau_i=m)=\Prob_i(\tau_i<\infty)=f_{ii}
    \end{multline*}
    where we have used the \mnameref{SP:MarkovStrong}.
  \end{proof}
  \begin{theorem}
    Let $(X_n)$ be a time-homogeneous Markov chain and $i\in I$. Then:
    \begin{itemize}
      \item $i$ is recurrent $\implies\Prob_i(N_i=\infty)=1$
      \item $i$ is transient $\implies\Prob_i(N_i<\infty)=1$
    \end{itemize}
  \end{theorem}
  \begin{proof}
    Note that $\{N_i\geq k\}\searrow\{N_i=\infty\}$, so by \mcref{SP:recurrence} we get:
    \begin{multline*}
      \Prob_i(N_i=\infty)=\lim_{k\to\infty}\Prob_i(N_i\geq k)={(f_{ii})}^k=\\=\begin{cases}
        1 & \text{if }i\text{ is recurrent} \\
        0 & \text{if }i\text{ is transient}
      \end{cases}
    \end{multline*}
  \end{proof}
  \begin{definition}
    Let $(X_n)$ be a time-homogeneous Markov chain, $i, j\in I$ and $n\in\NN$. We define $f_{ij}^{(n)}$ as:
    $$f_{ij}^{(n)}:=\Prob_i(\tau_j=n)$$
    Note that in these conditions we have:
    $$
      f_{ij}=\sum_{n=1}^{\infty}f_{ij}^{(n)}
    $$
  \end{definition}
  \begin{proposition}\label{SP:pij-fij}
    Let $(X_n)$ be a time-homogeneous Markov chain, $i, j\in I$ and $n\in\NN$. Then:
    $$
      p_{ij}^{(n)}=\sum_{m=1}^{n} f_{ij}^{(m)}p_{jj}^{(n-m)}
    $$
  \end{proposition}
  \begin{proof}
    Note that $\{X_n=j\}\subseteq \{\tau_j\leq n\}=\bigsqcup_{m=1}^n\{\tau_j=m\}$. Hence, $\{X_n=j\}=\bigsqcup_{m=1}^n[\{X_n=j\}\cap \{\tau_j=m\}]$. Thus:
    \begin{align*}
      p_{ij}^{(n)} & =\Prob_i(X_n=j)                                              \\
                   & =\sum_{m=1}^n \Prob_i(X_n=j,\tau_j=m)                        \\
                   & =\sum_{m=1}^n \Prob_i(X_n=j\mid\tau_j=m)\Prob_i(\tau_j=m)    \\
      \begin{split}
        & =\sum_{m=1}^n \Prob_i(X_n=j\mid X_m=j,X_{m-1}\ne j,\ldots, X_1\ne j)\cdot \\
        &\hspace{7cm}\cdot f_{ij}^{(m)}
      \end{split} \\
                   & =\sum_{m=1}^n \Prob_j(X_{n-m}=j)f_{ij}^{(m)}                 \\
                   & =\sum_{m=1}^nf_{ij}^{(m)}p_{jj}^{(n-m)}
    \end{align*}
  \end{proof}
  \begin{proposition}
    Let $(X_n)$ be a time-homogeneous Markov chain, $i, j\in I$. Then:
    $$
      i\to j\iff f_{ij}>0
    $$
  \end{proposition}
  \begin{proof}
    First note that $f_{ij}>0\iff \exists m\in\NN$ such that $f_{ij}^{(m)}>0$. So, we have:
    \begin{itemizeiff}
      If $i\to j$, $\exists n\in\NN$ such that $p_{ij}^{(n)}>0$. So by \mcref{SP:pij-fij} we have that $ \exists m\in\NN$ such that $f_{ij}^{(m)}>0$.
      \item Now suppose $f_{ij}^{(m)}>0$ for some $m\in\NN$. Then:
      $$
        0<f_{ij}^{(m)}=\Prob_i(\tau_j=m)\leq \Prob_i(X_m=j)=p_{ij}^{(m)}
      $$
      Thus, $i\to j$.
    \end{itemizeiff}
  \end{proof}
  \begin{definition}
    Let $(X_n)$ be a time-homogeneous Markov chain, $i, j\in I$. We define: $S_{ij}:=\sum_{n=1}^{\infty}p_{ij}^{(n)}$.
  \end{definition}
  \begin{lemma}\label{SP:lemaPrerec}
    Let $(X_n)$ be a time-homogeneous Markov chain and $j\in I$ be such that $S_{jj}<\infty$. Then, $\forall i\in I$ we have:
    $$
      S_{ij}=f_{ij}(1+S_{jj})
    $$
  \end{lemma}
  \begin{proof}
    \begin{multline*}
      \sum_{n=1}^\infty p_{ij}^{(n)}= \sum_{n=1}^\infty \sum_{m=1}^n f_{ij}^{(m)}p_{jj}^{(n-m)}=\sum_{m=1}^\infty \sum_{n=m}^\infty f_{ij}^{(m)}p_{jj}^{(n-m)}=\\=\sum_{m=1}^\infty f_{ij}^{(m)}(1+S_{jj})=f_{ij}(1+S_{jj})
    \end{multline*}
  \end{proof}
  \begin{lemma}\label{SP:lemaPrerec2}
    Let $(X_n)$ be a time-homogeneous Markov chain and $j\in I$. Then, $\forall i\in I$ and all $N\in\NN$ we have:
    $$
      \sum_{n=1}^Np_{ij}^{(n)}\leq f_{ij}\left(1+\sum_{n=1}^Np_{jj}^{(n)}\right)
    $$
  \end{lemma}
  \begin{sproof}
    Same as in \mcref{SP:lemaPrerec}.
  \end{sproof}
  \begin{theorem}\label{SP:thmRec}
    Let $(X_n)$ be a time-homogeneous Markov chain and $i,j\in I$. Then:
    \begin{enumerate}
      \item\label{SP:thmRecA} $i$ is recurrent $\iff S_{ii}=\infty$.
      \item\label{SP:thmRecB} If $i\leftrightarrow j$, then $i$ is recurrent $\iff j$ is recurrent.
      \item\label{SP:thmRecC} If $j$ is recurrent and $i\to j$, then $i$ is recurrent.
      \item\label{SP:thmRecD} If $j$ is transient, then $S_{ij}<\infty$ $\forall i\in I$. In particular, $\forall i\in I$, we have $\displaystyle \lim_{n\to\infty}p_{ij}^{(n)}=0$.
    \end{enumerate}
  \end{theorem}
  \begin{proof}
    \begin{enumerate}
      \item \begin{itemizeiff}
              Suppose $S_{ii}<\infty$. Then, since $f_{ii}=1$, \mcref{SP:lemaPrerec} implies $S_{ii}=1+S_{ii}$, which is a contradiction.
              \item Using \mcref{SP:lemaPrerec2} we have:
              $$
                f_{ii}\geq\frac{\sum_{n=1}^Np_{ii}^{(n)}}{1+\sum_{n=1}^Np_{ii}^{(n)}}\overset{N\to\infty}{\longrightarrow}1
              $$
            \end{itemizeiff}
      \item If $i\leftrightarrow j$, then $\exists r,s\geq 1$ such that $p_{ij}^{(r)}, p_{ji}^{(s)}>0$. So by \mcref{SP:corolariChapKolmo} we have that $\forall n\geq 0$:
            $$
              p_{jj}^{(n+r+s)} \geq p_{ji}^{(s)}p_{ii}^{(n)}p_{ij}^{(r)}=:C p_{ii}^{(n)}
            $$
            And so, $\sum p_{ii}^{(n)}=\infty\implies \sum p_{jj}^{(n)} = \infty$ by \mcref{SP:thmRecA}.
      \item Similarly, as before, since $i\to j$, $\exists r\geq 1$ such that $p_{ij}^{(r)}>0$. Thus, $p_{ii}^{(n+r)}\geq p_{ij}^{(r)}p_{jj}^{(n)}$. So, $\sum p_{jj}^{(n)}=\infty\implies \sum p_{ii}^{(n)} = \infty$.
      \item It follows from \mcref{SP:thmRecA} and \mcref{SP:lemaPrerec}.
    \end{enumerate}
  \end{proof}
  \begin{definition}
    Let $(X_n)$ be a time-homogeneous Markov chain. We say that the chain is \emph{recurrent} if $i$ is recurrent for all $i\in I$. We say that the chain is \emph{transient} if $i$ is transient for all $i\in I$.
  \end{definition}
  \begin{theorem}[Polya's theorem on $\ZZ$]
    The simple random walk on $\ZZ$ is recurrent if and only if $p=q$.
  \end{theorem}
  \begin{proof}
    By \cref{SP:thmRecA} we need to study the convergence of $\sum p_{ii}^{(n)}=\sum_{ii}^{(2n)}$. Note that:
    \begin{equation*}
      p_{ii}^{(2n)}=\binom{2n}{n}p^nq^n
    \end{equation*}
    because we choose $n$ steps to the right from a total of $2n$ and the rest must be steps to the left. Finally, using \mcref{MA:stirling} one can check that:
    \begin{equation}\label{SP:stirling_polya1}
      p_{ii}^{(2n)}\sim \frac{1}{\sqrt{n}}{(4pq)}^n
    \end{equation}
    which lead to a convergent series if and only if $p\ne q$.
  \end{proof}
  \begin{lemma}\label{SP:2n-n_convinatoria}
    Let $n\in\NN$. Then:
    $$
      \sum_{m=0}^{n}\binom{n}{m}^2=\binom{2n}{n}
    $$
  \end{lemma}
  \begin{sproof}
    Equate the coefficients of $x^n$ of the two series
    $$
      \sum_{j=0}^{2n}\binom{2n}{j}x^j={[{(1+x)}^{n}]}^2={\left(\sum_{j=0}^n\binom{n}{j}x^j\right)}^2
    $$
    and use the fact that $\binom{n}{m}=\binom{n}{n-m}$.
  \end{sproof}
  \begin{theorem}[Polya's theorem on $\ZZ^2$]
    The simple random walk on $\ZZ^2$ is recurrent if and only if $\Prob(X_1=(1,0))=\Prob(X_1=(-1,0))=\Prob(X_1=(0,1))=\Prob(X_1=(0,-1))=1/4$.
  \end{theorem}
  \begin{sproof}
    We will proof only the implication to the left, in order to keep the proof short. Note that we have:
    $$
      % p_{ii}^{(2n)}=\sum_{m=0}^{n}\binom{2n}{2m}\binom{2m}{m}\binom{2n-2m}{n-m}\frac{1}{4^{2n}}=\frac{1}{4^{2n}}\binom{2n}{n}\sum_{m=0}^n \binom{n}{m}^2
      p_{ii}^{(2n)}=\sum_{m=0}^{n}\frac{(2n)!}{{(m!)}^2{(n-m)!}^2}\frac{1}{4^{2n}}=\frac{1}{4^{2n}}\binom{2n}{n}\sum_{m=0}^n \binom{n}{m}^2
    $$
    In the formula $m$ denotes the number of steps rightwards and leftwards, and $n-m$, the number of steps upwards and downwards. Now using \mcref{SP:2n-n_convinatoria,SP:stirling_polya1} we have:
    $$
      p_{ii}^{(2n)}=\frac{1}{4^{2n}}\binom{2n}{n}^2\sim \frac{1}{n}
    $$
  \end{sproof}
  \begin{theorem}[Polya's theorem on $\ZZ^3$]
    The simple random walk on $\ZZ^3$ is always transient.
  \end{theorem}
  \begin{corollary}
    Let $(X_n)$ be a time-homogeneous Markov chain and $i,j\in I$. Then, if $j$ is transient, we have $\Exp_i(N_j)<\infty$.
  \end{corollary}
  \begin{proof}
    $$
      \Exp_i(N_j)=\Exp_i\left(\sum_{n=1}^{\infty}1_{\{X_n=j\}}\right)=\sum_{n=1}^{\infty}p_{ij}^{(n)}<\infty
    $$
    where the last inequality follows from \mcref{SP:thmRecD}.
  \end{proof}
  \subsubsection{Limit distributions}
  \begin{definition}
    Let $(X_n)$ be a time-homogeneous Markov chain and $i\in I$ be recurrent. We denote $\mu_i:=\Exp_i(\tau_i)$. We say that $i$ is \emph{positive recurrent} if $\mu_i<\infty$ and \emph{null recurrent} if $\mu_i=\infty$.
  \end{definition}
  \begin{theorem}[Ergotic theorem]
    Let $(X_n)$ be a time-homogeneous Markov chain and $i\in I$ be positively recurrent. Then:
    $$
      \lim_{n\to\infty}\frac{1}{n}\sum_{m=1}^n p_{ii}^{(m)}=\frac{1}{\mu_i}
    $$
  \end{theorem}
  \begin{proof}
    By hypothesis $T_i^k$ has finite expectation and so by the \mcref{P:stronglawKolmo} we have:
    $$\frac{1}{k}\sum_{m=1}^{k}T_i^m=\frac{\tau_i^k}{k}\almoste{\longrightarrow}\mu_i$$
    Let $N_i^n=\sum_{m=1}^n\indi{\{X_m=i\}}\leq n$, which counts the number of visits of the state $i$ in the first $n$ steps. Note that if $N_i^n=k\leq n$, $\tau_i^k\leq n<\tau_i^{k+1}$ and so:
    $$
      \frac{k}{k+1}\frac{k+1}{\tau_i^{k+1}}=\frac{k}{\tau_i^{k+1}}<\frac{N_i^n}{n}\leq \frac{k}{\tau_i^k}
    $$
    Hence, taking the limit $k\to\infty$ we have: $$\displaystyle\lim_{n\to\infty}\frac{N_i^n}{n}=\lim_{k\to\infty}\frac{k}{\tau_i^k}\almoste{\longrightarrow}\frac{1}{\mu_i}$$ Moreover note that $\frac{N_i^n}{n}\leq 1$. Thus, by the \mcref{P:dominated} we have that:
    $$
      \Exp_i\left(\frac{N_i^n}{n}\right)=\frac{\sum_{m=1}^n \Prob_i(X_m=i)}{n}=\frac{\sum_{m=1}^n p_{ii}^{(m)}}{n}\almoste{\longrightarrow}\frac{1}{\mu_i}
    $$
  \end{proof}
  \begin{corollary}
    Let $(X_n)$ be a time-homogeneous Markov chain and $i\in I$ be positive recurrent such that $\displaystyle\exists\lim_{n\to\infty}p_{ii}^{(n)}$. Then:
    $$
      \lim_{n\to\infty} p_{ii}^{(n)}=\frac{1}{\mu_i}
    $$
  \end{corollary}
  \begin{sproof}
    Recall \mcref{MA:cesaro}.
  \end{sproof}
  \begin{theorem}[Ergotic theorem]\label{SP:ergotic2}
    Let $(X_n)$ be a time-homogeneous Markov chain and $i\in I$ be recurrent and aperiodic. Then, the limit $\displaystyle\lim_{n\to\infty}p_{ii}^{(n)}$ exists and:
    $$
      \lim_{n\to\infty}p_{ii}^{(n)}=\lim_{n\to\infty}\frac{1}{n}\sum_{n=1}^\infty p_{ii}^{(n)}=\frac{1}{\mu_i}
    $$
    In particular, if $i$ is positive recurrent, then $\displaystyle\lim_{n\to\infty}p_{ii}^{(n)}>0$ and if $i$ is null recurrent, then $\displaystyle\lim_{n\to\infty}p_{ii}^{(n)}=0$.
  \end{theorem}
  \begin{proposition}
    Let $(X_n)$ be a time-homogeneous Markov chain, $i\in I$ be recurrent and aperiodic and $j\in I$ be such that $i\leftrightarrow j$. Then:
    \begin{enumerate}
      \item $i$ positive recurrent $\implies$ $j$ positive recurrent.
      \item $i$ null recurrent $\implies$ $j$ null recurrent.
    \end{enumerate}
  \end{proposition}
  \begin{proof}
    By \mcref{SP:thmRec,SP:period_classes} we have that $j$ is recurrent and aperiodic. Thus, by \mnameref{SP:ergotic2}, the limits $\displaystyle \lim_{n\to\infty}p_{ii}^{(n)}$ and $\displaystyle \lim_{n\to\infty}p_{jj}^{(n)}$ exist. Moreover, since $i\leftrightarrow j$ $\exists r,s\in\NN$ such that $p_{ij}^{(r)}, p_{ji}^{(s)}>0$. By \mcref{SP:corolariChapKolmo} we have that $p_{jj}^{(n+r+s)}\geq C p_{ii}^{(n)}$. If $i$ is positive recurrent then:
    $$
      \lim_{n\to\infty}p_{jj}^{(n+r+s)}\geq C\lim_{n\to\infty}p_{ii}^{(n)}>0
    $$
    If $i$ is null and $j$ was positive, then $i$ would be positive by the previous argument, which is a contradiction.
  \end{proof}
  \begin{theorem}
    Let $(X_n)$ be a time-homogeneous Markov chain and $i\in I$ be recurrent and periodic of period $d$. Then:
    $$
      \lim_{n\to\infty} p_{ii}^{(nd)}=\frac{d}{\mu_i}
    $$
  \end{theorem}
  \begin{proof}
    $(Y_n):=(X_{nd})$ is a time-homogeneous Markov chain and $i\in I$ is recurrent and aperiodic. Thus, by \mnameref{SP:ergotic2} we have that $\displaystyle\lim_{n\to\infty}p_{ii}^{(nd)}=\frac{1}{\Exp_i(\tau_i^Y)}$. But:
    $$
      \tau_i^Y=\inf\{ n\geq 1: Y_n=i\}=\frac{1}{d}\inf\{n\geq 1: X_{n}=i\}=\frac{\tau_i}{d}
    $$
  \end{proof}
  \begin{theorem}
    Let $(X_n)$ be a time-homogeneous irreducible and aperiodic Markov chain. Then, we have exactly one of the following results:
    \begin{enumerate}
      \item All the states are transient and $\forall i,j\in I$: $$\lim_{n\to\infty} p_{ij}^{(n)}=\lim_{n\to\infty} \pi_j^{(n)}=0$$ Moreover $\sum_{n=1}^\infty p_{ij}^{(n)}<\infty$.
      \item All the states are null recurrent and $\forall i,j\in I$: $$\lim_{n\to\infty} p_{ij}^{(n)}=\lim_{n\to\infty} \pi_j^{(n)}=0$$ Moreover $\sum_{n=1}^\infty p_{ij}^{(n)}=\infty$.
      \item All the states are positive recurrent and $\forall i,j\in I$: $$\lim_{n\to\infty} p_{ij}^{(n)}=\lim_{n\to\infty} \pi_j^{(n)}=\frac{1}{\mu_j}$$
    \end{enumerate}
  \end{theorem}
  \begin{proof}
    It can be seen that $\displaystyle\lim_{n\to\infty}p_{ij}^{(n)}=\lim_{n\to\infty} p_{jj}^{(n)}$ $\forall i, j\in I$. We will prove that $\displaystyle\lim_{n\to\infty}p_{ij}^{(n)}=\lim_{n\to\infty} \pi_j^{(n)}$ $\forall i, j\in I$. We have that:
    \begin{multline*}
      \lim_{n\to\infty}\pi_j^{(n)}=\lim_{n\to\infty}\Prob(X_n=j)=\lim_{n\to\infty}\sum_{i\in I}p_{ij}^{(n)}\pi_i=\\=\sum_{i\in I}\lim_{n\to\infty}p_{ij}^{(n)}\pi_i=\sum_{i\in I}\frac{\pi_i}{\mu_j}=\frac{1}{\mu_j}
    \end{multline*}
    where we have used the dominated convergence theorem for series.
  \end{proof}
  \begin{corollary}\label{SP:coroClassificationStates}
    Let $(X_n)$ be a time-homogeneous irreducible and aperiodic Markov chain such that $I$ is finite. Then, all the states are positive recurrent.
  \end{corollary}
  \begin{sproof}
    Note that we must have $\sum_{j\in I}\pi_j^{(n)}=1$ $\forall n\in\NN$.
  \end{sproof}
  \begin{definition}
    Let $(X_n)$ be a time-homogeneous Markov chain. A vector $\vf\nu={(\nu_i)}_{i\in I}$ is called a \emph{stationary distribution} if:
    $$
      \vf\nu\geq 0\qquad\sum_{i\in I}\nu_i=1\qquad\vf\nu\vf P=\vf\nu
    $$
  \end{definition}
  \begin{remark}
    In general, we cannot guarantee the existence or uniqueness of stationary distributions.
  \end{remark}
  \begin{lemma}
    Let $(X_n)$ be a time-homogeneous Markov chain, $\vf\nu$ be a stationary distribution and suppose $\vf\pi^{(0)}=\vf\nu$. Then, $\vf\pi^{(n)}=\vf\nu$ $\forall n\in\NN$.
  \end{lemma}
  \begin{proof}
    $\displaystyle
      \vf\pi^{(n)}=\vf\nu\vf P^n=\vf\nu\vf P^{n-1}=\cdots=\vf\nu
    $
  \end{proof}
  \begin{theorem}
    Let $(X_n)$ be a time-homogeneous irreducible and aperiodic Markov chain. Then, $(X_n)$ is positive recurrent if and only if it admits a stationary distribution. Moreover, this distribution is unique, and it is given by $\nu_i=\frac{1}{\mu_i}$.
  \end{theorem}
  \begin{proof}
    We will only proof the case when $I$ is finite. By \mcref{SP:coroClassificationStates} we only need to prove the impication to the right. Since $\displaystyle\lim_{n\to\infty}p_{ij}^{(n)}=\frac{1}{\mu_j}$ $\forall i,j\in I$ we have that $\vf\nu={(1/\mu_i)}_{i\in I}\geq 0$ satisfies:
    \begin{align*}
      \sum_{j\in I}\nu_j        & =\sum_{j\in I}\lim_{n\to\infty}p_{ij}^{(n)}=\lim_{n\to\infty}\sum_{j\in I}p_{ij}^{(n)}=1 \\
      \sum_{i\in I}\nu_i p_{ij} & =\sum_{i\in I}\lim_{n\to\infty}p_{ki}^{(n)}p_{ij}=\lim_{n\to\infty}p_{kj}^{(n+1)}=\nu_j
    \end{align*}
    where we have used \mnameref{SP:ChapKolmo}. Hence, $\vf\nu$ is a stationary distribution. Now, for the uniqueness, suppose $\vf\nu$ is an arbitrary stationary distribution. Then, $\nu_j=\sum_{i\in I}\nu_i p_{ij}^{(n)}$ $\forall n\in\NN$. Thus, taking $n\to\infty$ we get that $\nu_j = \frac{1}{\mu_j}$ $\forall j\in I$.
  \end{proof}
  \subsection{Continuous-time Markov chains}
  \subsubsection{Introduction}
  \begin{definition}
    Let ${(X_t)}_{t\geq 0}$ be a stochastic process. We say that ${(X_t)}_{t\geq 0}$ is a \emph{continuous-time Markov chain} with state space $I$ (finite or countable) if $\forall n\in\NN$ and all $0\leq t_1<\cdots<t_n<t_{n+1}$ and all $i_1,\ldots,i_{n-1},i,j\in I$ we have that:
    \begin{multline*}
      \Prob(X_{t_{n+1}}=j\mid X_{t_n}=i, X_{t_{n-1}}=i_{n-1}\ldots,X_{t_1}=i_1)=\\=\Prob(X_{t_{n+1}}=j\mid X_{t_n}=i)
    \end{multline*}
    The chain is called homogeneous if $\Prob(X_{t_{n+1}}=j\mid X_{t_n}=i)$ does only depend on the difference $t_{n+1}-t_n$. That is, if $\forall s\leq t$ we have:
    $$
      \Prob(X_{t+s}=j\mid X_{s}=i)=\Prob(X_{t}=j\mid X_0=i)
    $$
    In order to simplify the lecture we will write CTHMC for continuous-time homogeneous Markov chains.
  \end{definition}
  \begin{definition}
    Let ${(X_t)}_{t\geq 0}$ be a CTHMC. We define the \emph{transition probabilities} as:
    $$
      p_{ij}(t)=\Prob(X_t=j\mid X_0=i)
    $$
    The transition matrix is $\vf{P}(t)=(p_{ij}(t))_{i,j\in I}$.
  \end{definition}
  \begin{proposition}[Chapman-Kolmogorov equation]\label{SP:ChapKolmo_continuous}
    Let ${(X_t)}_{t\geq 0}$ be a CTHMC. Then, $\vf{P}(t)$ is a stochastic matrix $\forall t\geq 0$ and $\forall s,t \geq 0$: $$\vf{P}(t+s)=\vf{P}(t)\vf{P}(s)$$
  \end{proposition}
  \begin{proof}
    \begin{align*}
      p_{ij}(t+s) & =\sum_{k\in I} \Prob(X_{t+s}=j,X_s=k\mid X_0=i) \\
      \begin{split}
        & =\sum_{k\in I} \Prob(X_{t+s}=j\mid X_s=k,X_0=i)\cdot\\
        &\hspace{3.5cm}\cdot\Prob(X_s=k\mid X_0=i) \\
      \end{split}         \\
                  & =\sum_{k\in I} p_{ik}(t)p_{kj}(s)
    \end{align*}
  \end{proof}
  \begin{proposition}
    Let ${(X_t)}_{t\geq 0}$ be a CTHMC. Then, for all $0\leq t_1 < \cdots < t_n$ and all $i_1,\ldots,i_{n}\in I$ we have that:
    \begin{multline*}
      \Prob(X_{t_n}=i_n,X_{t_{n-1}}=i_{n-1},\ldots,X_{t_1}=i_1)=\\
      =p_{i_1}(t_1)p_{i_1i_2}(t_2-t_1)\cdots p_{i_{n-1}i_n}(t_n-t_{n-1})
    \end{multline*}
    where $p_{i}(t):= \Prob(X_t=i)$.
  \end{proposition}
  \subsubsection{Poisson process}
  \begin{definition}
    Let $\lambda>0$. A stochastic process ${(N_t)}_{t\geq 0}$ is called a \emph{Poisson process} with parameter $\lambda$ if:
    \begin{enumerate}
      \item $N_0=0$.
      \item $N_t$ has \emph{independent increments}, that is $N_{t_1}, N_{t_2}-N_{t_1},\ldots,N_{t_n}-N_{t_{n-1}}$ are independent random variables for all $0\leq t_1<\cdots<t_n$ and all $n\in\NN$.
      \item $N_t$ has \emph{stationary increments}, that is $N_t-N_s\sim\text{Pois}(\lambda(t-s))$ $\forall 0\leq s\leq t$.
      \item For all $\omega\in\Omega$ the functions (called \emph{trajectories})
            $$
              \function{N_\cdot(\omega)}{[0,\infty)}{\NN\cup\{0\}}{t}{N_t(\omega)}
            $$
            are right-continuous (\emph{càd}).
    \end{enumerate}
  \end{definition}
  \begin{proposition}
    Let ${(X_t)}_{t\geq 0}$ be a stochastic process with independent increments. Then, ${(X_t)}_{t\geq 0}$ is a continuous-time Markov chain.
  \end{proposition}
  \begin{proof}
    \begin{align*}
      \Prob(X_{t_{n+1}} & =  j\mid X_{t_n}=i, X_{t_{n-1}}=i_{n-1}\ldots,X_{t_1}=i_1)       \\
                        & =\Prob(X_{t_{n+1}}-X_{t_n}=j-i\mid X_{t_n}-X_{t_{n-1}}=i-        \\
                        & \hspace{1cm}-i_{n-1},\ldots,X_{t_2}-X_{t_1}=i_2-i_1,X_{t_1}=i_1) \\
                        & =\Prob(X_{t_{n+1}}-X_{t_n}=j-i)                                  \\
                        & =\Prob(X_{t_{n+1}}=j\mid X_{t_n}=i)
    \end{align*}
  \end{proof}
  \begin{corollary}
    Let ${(N_t)}_{t\geq 0}$ be a Poisson process with parameter $\lambda$. Then, ${(N_t)}_{t\geq 0}$ is a CTHMC with transition probabilities:
    $$
      p_{ij}(t)=\Prob(N_t=j\mid N_0=i)=\frac{(\lambda t)^j}{j!}e^{-\lambda t}
    $$
  \end{corollary}
  \begin{proposition}
    Let ${(N_t^1)}_{t\geq 0}$ and ${(N_t^2)}_{t\geq 0}$ be two independent Poisson processes with parameters $\lambda_1$ and $\lambda_2$ respectively. Then, ${(N_t^1+N_t^2)}_{t\geq 0}$ is a Poisson process with parameter $\lambda_1+\lambda_2$.
  \end{proposition}
  \begin{proof}
    Let $N_t:=(N_t^1+N_t^2)$. We only check the independent increment, the other properties are easier. We need to check that for all $0\leq t_1< \cdots < t_n$ and all $n\in\NN$ the random variables $X_{t_1}:=N_{t_1},X_{t_2}:= N_{t_2}-N_{t_1},\ldots,X_{t_n}:=N_{t_n}-N_{t_{n-1}}$ are independent. We have that
    $$
      X_{t_\ell}=N_{t_\ell}^1-N_{t_{\ell-1}}^1+N_{t_\ell}^2-N_{t_{\ell-1}}^2=:Y_\ell^1+Y_\ell^2
    $$
    By hypothesis the variables $Y_\ell^1$ and $Y_\ell^2$ are independent. Moreover, since $N_t^i$ are Poisson processes, we have that $\{(Y_k^i)\}_{k=1,\ldots,n}$ pairwise independent, for $i=1,2$. Now using the characterization of independence with the characteristic function, we have:
    \begin{align*}
      \varphi_{X_{t_1},\ldots,X_{t_n}}(u_1,\ldots,u_n) & =\Exp\left(\exp{\ii\sum_{j=1}^nu_j X_j}\right)                                       \\
                                                       & =\Exp\left(\exp{\ii\sum_{j=1}^nu_jY_j^1}\exp{\ii\sum_{j=1}^nu_jY_j^2}\right)         \\
                                                       & =\prod_{j=1}^n\Exp\left(\exp{\ii u_jY_j^1}\right)\Exp\left(\exp{\ii u_jY_j^2}\right) \\
                                                       & = \prod_{j=1}^n\varphi_{X_j}(u_j)
    \end{align*}
  \end{proof}
  \begin{lemma}
    Let ${(N_t)}_{t\geq 0}$ be a Poisson process with parameter $\lambda$. Then: $$\Prob(N_h\geq 2)=\o{h}$$
  \end{lemma}
  \begin{proof}
    $\displaystyle
      \Prob(N_h\geq 2)=1-e^{-\lambda h}-\lambda h e^{-\lambda h}=\o{h}$
  \end{proof}
  \begin{proposition}
    Let ${(N_t)}_{t\geq 0}$ be a Poisson process with parameter $\lambda$. Then, the trajectories are almost surely non-decreasing and have jumps of size at most $1$.
  \end{proposition}
  \begin{proof}
    We need to see that the event $\{N_s\leq N_t: \forall t,s\in\RR, 0\leq s < t\}$ has probability $1$. We have:
    $$
      \bigcap_{0\leq s < t}\{N_s\leq N_t\}= \bigcap_{\substack{0\leq s < t\\s,t\in\QQ}}\{N_s\leq N_t\}
    $$
    because the trajectories are càd. Finally, since $\Prob(N_s\leq N_t)=\Prob(N_t-N_s\geq 0)=1$, the intersection has probability $1$. Now, let:
    \begin{align*}
      A     & :=\{\omega\in\Omega:N(\omega)\text{ has jumps of size}\geq 2\}                   \\
      A_R   & :=\{\omega\in\Omega:N(\omega)\text{ has jumps of size}\geq 2\text{ in $[0,R]$}\} \\
      B_R^n & :=\{\exists k\in\{1,\ldots,n\}: N_{\frac{kR}{n}}-N_{\frac{(k-1)R}{n}}\geq 2\}
    \end{align*}
    Note that $A=\bigcup_{R=1}^\infty A_R$ and $A_R\subseteq B_R^n$ $\forall n\geq 1$ because the trajectories are càd. Thus, $\forall R>0$:
    \begin{multline*}
      \Prob(A_R)\leq \Prob(B_R^n)=\Prob\left(\bigcup_{k=1}^n\left\{N_{\frac{kR}{n}}-N_{\frac{(k-1)R}{n}}\geq 2\right\}\right)\leq\\
      \leq\sum_{k=1}^n\Prob\left(N_{\frac{kR}{n}}-N_{\frac{(k-1)R}{n}}\geq 2\right)=n\Prob(N_{\frac{R}{n}}\geq 2)=\\=n\o{\frac{R}{n}}\overset{n\to\infty}{\longrightarrow}0
    \end{multline*}
    Hence, $\Prob(A)=0$.
  \end{proof}
  \begin{definition}
    Let ${(N_t)}_{t\geq 0}$ be a Poisson process with parameter $\lambda$. We define the \emph{holding times} as:
    $$
      T_k:=\inf\{t> T_{k-1}:N_t=k\}
    $$
    with $T_0:=0$. The \emph{inter-arrival times} are:
    $$
      S_k:=T_k-T_{k-1}
    $$
  \end{definition}
  \begin{lemma}
    Let ${(N_t)}_{t\geq 0}$ be a Poisson process with parameter $\lambda$. Then, $\Prob(T_k < \infty)=1$ $\forall k\in\NN\cup\{0\}$.
  \end{lemma}
  \begin{proof}
    Since the trajectories are càd:
    \begin{multline*}
      \Prob(T_k=\infty)=\Prob(\forall t\in\RR: N_t\leq k-1)\leq \Prob(N_1=0,\\N_2-N_1 =0,\ldots,N_n-N_{n-1}=0)=\exp{-\lambda n} \overset{n\to\infty}{\longrightarrow}0
    \end{multline*}
    because the inequality is true for all $n\in\NN$.
  \end{proof}
  \begin{theorem}
    Let ${(N_t)}_{t\geq 0}$ be a Poisson process with parameter $\lambda$. Then, the inter-arrival times $(S_k)$ are \iid random variables distributed as $\text{Exp}(\lambda)$.
  \end{theorem}
  \begin{proof}
    Let $\vf{T}:=(T_1,\ldots,T_n)$. Recall that:
    $$
      f_{\vf{T}}(\vf{t})=\frac{\partial^nF_{\vf{X}}}{\partial x_1\cdots\partial x_n}(\vf{t})=\lim_{\vf{h}\to \vf{0}^+}\frac{\Prob(\vf{T}\in \prod_{k=1}^n(t_k,t_k+h_k])}{h_1\cdots h_n}
    $$
    Assume that $t_k+h_k<t_{k+1}$ $\forall k\in\{1,\ldots,n-1\}$. Then:
    \begin{multline*}
      \Prob\left(\vf{T}\in \prod_{k=1}^n(t_k,t_k+h_k]\right)=\Prob(N_{t_1}=0, N_{t_1+h_1}-N_{t_1}=1, \\ N_{t_2}-N_{t_1+h_1}=0,\ldots,N_{t_{n}}-N_{t_{n-1}+h_{n-1}}=0,\\N_{t_n+h_n}-N_{t_n}>1)=\lambda^{n-1}h_1\cdots h_{n-1}\exp{-\lambda t_n}(1-\exp{-\lambda h_n})
    \end{multline*}
    Hence:
    $$
      f_{\vf{T}}(\vf{t})=\lambda^{n}\exp{-\lambda t_n}
    $$
    Now consider
    $$
      \function{\vf{g}}{\{0<t_1<\cdots<t_n\}}{{(0,\infty)}^n}{(t_1,\ldots,t_n)}{(t_1,t_2-t_1,\ldots,t_n-t_{n-1})}
    $$
    which is a diffeomorphism such that $\det \vf{Dg}(\vf{t})=1$. The density of $\vf{S}:=\vf{g}(\vf{T})$ is thus
    $$
      f_{\vf{S}}(\vf{s})=f_{\vf{T}}(\vf{g}^{-1}(\vf{s}))\indi{{(0,\infty)}^n}(\vf{s})=\prod_{k= 1}^n \lambda \exp{-\lambda s_k}\indi{(0,\infty)}(s_k)
    $$
    by \mcref{P:transRV}. And this last expression is the joint pdf of $n$ \iid $\text{Exp}(\lambda)$ variables.
  \end{proof}
  \begin{theorem}
    Let ${(S_k)}$ be a sequence of \iid random variables distributed as $\text{Exp}(\lambda)$. Consider the sequence $(T_n)$ defined as $T_0:=0$ and $T_n=\sum_{k=1}^{n}S_k$. Let $N_t:=\sup\{n\geq 1:T_n\leq t\}$. Then, ${(N_t)}_{t\geq 0}$ is a Poisson process with parameter $\lambda$. In this case, we can also express $N_t$ as:
    $$
      N_t=\sum_{n=1}^\infty n \indi{\{T_n\leq t<T_{n+1}\}}
    $$
  \end{theorem}
  \begin{sproof}
    We'll see only that $N_t\sim \text{Pois}(\lambda t)$. Let $k\in\NN\cup \{0\}$. Then, $\Prob(N_t=k)=\Prob(T_k\leq t<T_{k+1})$. Since $T_k=\sum_{i=1}^k S_i$, we have that $T_{k}$ and $S_{k+1}$ are independent. Hence, $f_{T_k,S_{k+1}}(x,y)=f_{T_k}(x)f_{S_{k+1}}(y)$ and since $S_{k+1}\sim \text{Exp}(\lambda)$ and $T_k\sim \Gamma(k,\lambda)$ (because is a sum of exponentials), we have that:
    $$
      f_{T_k,S_{k+1}}(x,y)=\frac{\lambda^k}{\Gamma(k)}t^{k-1}\exp{-\lambda x}\lambda \exp{-\lambda y}=\frac{\lambda^{k+1}t^{k-1}}{(k-1)!}\exp{-\lambda (x+y)}
    $$
    Finally:
    $$
      \Prob(N_t=k)=\iint_{A}f_{T_k,S_{k+1}}(x,y) \dd{x}\dd{y}=\frac{{(\lambda t)}^k}{k!}\exp{-\lambda t}
    $$
    where $A:=\{(x,y)\in{\RR_{\geq 0}}^2: x\leq t< x+y\}$.
  \end{sproof}
  \subsubsection{Kolmogorov's differential equations}
  From here on, we'll assume that the transition marices $\vf{P}(t)$ satisfy that $\displaystyle\lim_{h\to 0} \vf{P} (h)=\vf{I}$. That is, we have right continuity at $0$. This is equivalent to say that $\displaystyle\lim_{h\to 0} p_{ij}(h)=\delta_{ij}$.
  \begin{lemma}
    Let ${(X_t)}_{t\geq 0}$ be a CTHMC with transition matrix $\vf{P}(t)$. Then, $(p_{ij}(t))$ are continuous functions for all $i,j\in I$.
  \end{lemma}
  \begin{proof}
    The result follows from the inequality:
    $$
      \abs{p_{ij}(t+h) - p_{ij}(t)}\leq 1-p_{ii}(\abs{h})
    $$
    and the right-continuity at 0. Let's prove the inequality. Suppose that $h>0$. Then:
    \begin{align*}
      \abs{p_{ij}(t+h) - p_{ij}(t)} & = \abs{\sum_{k\in I} p_{ik}(h)p_{kj}(t)-p_{ij}(t)} \\
                                    & =\abs{\sum_{\substack{k \in I                      \\ k\neq i}} p_{ik}(h)p_{kj}(t)-p_{ij}(t)[1\! -\! p_{ii}(h)]}\\
                                    & =\abs{\sum_{\substack{k \in I                      \\ k\neq i}} p_{ik}(h)p_{kj}(t)+p_{ij}(t)\sum_{\substack{k \in I\\ k\neq i}}p_{ik}(h)}\\
                                    & \leq \sum_{\substack{k \in I                       \\ k\neq i}} p_{ik}(h)\abs{p_{kj}(t)-p_{ij}(t)}\\
                                    & \leq 1-p_{ii}(h)
    \end{align*}
    The case $h<0$ follows from considering $t'=t+h$.
  \end{proof}
  \begin{theorem}
    Let $\vf{P}(t)$ be a stochastic matrix such that:
    \begin{enumerate}\label{SP:StochMatrixProps}
      \item $\vf{P}(0) = \vf{I}$.
      \item $\vf{P}(t+s) = \vf{P}(t)\vf{P}(s)$ for all $t,s\geq 0$.
      \item $\displaystyle\lim_{h\to 0} \vf{P} (h)=\vf{I}$.
    \end{enumerate}
    Then, for any $i,j\in I$, the following limits exist:
    $$
      \begin{cases}
        q_{ij}:=\displaystyle\lim_{h\to 0} \frac{p_{ij}(h)}{h}\in[0,\infty) & \text{if } i\neq j \\
        q_i:= \displaystyle\lim_{h\to 0} \frac{1-p_{ii}(h)}{h}\in[0,\infty] & \text{if } i=j
      \end{cases}
    $$
    Note that if the limits are finite we have $q_{ij} = {p_{ij}}'(0)$ and $q_i = -{p_{ii}}'(0)$.
  \end{theorem}
  \begin{definition}
    Let ${(X_t)}_{t\geq 0}$ be a CTHMC with transition matrix $\vf{P}(t)$. Then, the \emph{infinitesimal generator} of ${(X_t)}_{t\geq 0}$ is the matrix $\vf{Q}$ defined as $\vf{Q}:={\left(q_{ij}\right)}_{i,j\in I}$, where $q_{ii}:=-q_i$. We define the \emph{infinitesimal transition scheme} as:
    $$
      \begin{cases}
        p_{ii}(h) = 1-q_ih+\o{h}  & \text{if } i=j     \\
        p_{ij}(h) = q_{ij}h+\o{h} & \text{if } i\neq j
      \end{cases}
    $$
  \end{definition}
  \begin{theorem}
    Let ${(X_t)}_{t\geq 0}$ be a CTHMC with infinitesimal generator $\vf{Q}$ and assume that $I$ is finite. Then, $\vf{P}'=\vf{Q}\vf{P}$ and $\vf{P}'=\vf{P}\vf{Q}$. The first equation is called the \emph{Kolmogorov's backward equation} and the second one the \emph{Kolmogorov's forward equation}.
  \end{theorem}
  \begin{proof}
    Note that since $I$ is finite, $q_i<\infty$ $\forall i\in I$. Indeed:
    $$
      q_i=\lim_{h\to 0}\frac{1-p_{ii}(h)}{h}=\sum_{\substack{k\in I\\k\ne i}}\lim_{h\to 0}\frac{p_{ik}(h)}{h}=\sum_{\substack{k\in I\\k\ne i}}q_{ik}< \infty
    $$
    Now, let $t\geq 0$, $h>0$ and $i,j\in I$. Then, using \mnameref{SP:ChapKolmo_continuous}
    \begin{multline*}
      p_{ij}(t+h)-p_{ij}(t)=\sum_{\substack{k\in I\\k\ne i}}p_{ik}(h)p_{kj}(t)+p_{ii}(h)p_{ij}(t)-p_{ij}(t)=\\=\sum_{\substack{k\in I\\k\ne i}}(q_{ik}h+\o{h})p_{kj}(t)+(1+q_{ii} h+\o{h})p_{ij}(t)-p_{ij}(t)=\\=\sum_{k\in I}q_{ik}h p_{kj}(t)+\o{h}
    \end{multline*}
    Dividing by $h$ and taking limits we get the result with the right derivative. Now take $t>0$ and $h<0$. Then, similarly:
    $$
      p_{ij}(t)-p_{ij}(t+h)=-\sum_{k\in I}q_{ik}h p_{kj}(t+h)+\o{h}
    $$
    Using the continuity of the $p_{ij}$'s we get the result with the left derivative. The other equation follows analogously by exchanging the roles of $h$ and $t$ in the Chapman-Kolmogorov equations.
  \end{proof}
  \begin{theorem}
    Let ${(X_t)}_{t\geq 0}$ be a CTHMC with infinitesimal generator $\vf{Q}$. Assume that $q_i<\infty$ and $q_i=\sum_{\substack{k\in I\\k\ne i}}q_{ik}$ for all $i\in I$. Then, $\vf{P}'=\vf{Q}\vf{P}$.
  \end{theorem}
  \begin{theorem}
    Let ${(X_t)}_{t\geq 0}$ be a CTHMC with infinitesimal generator $\vf{Q}$. Assume that $q_i<\infty$ and $q_i=\sum_{\substack{k\in I\\k\ne i}}q_{ik}$ for all $i\in I$ and that $\sum_{k\in I}p_{ik}(t)q_k<\infty$ for all $i\in I$ and $t\geq 0$. Then, $\vf{P}'=\vf{P}\vf{Q}$.
  \end{theorem}
  \begin{remark}
    Note that in this latter theorem if $\sup_{k\in I}q_k<\infty$, then $\sum_{k\in I}p_{ik}(t)q_k<\infty$ for all $i\in I$ and $t\geq 0$.
  \end{remark}
  \subsubsection{Jump processes}
  \begin{definition}
    Let ${(X_t)}_{t\geq 0}$ be a stochastic process with state space $E$ (not necessarily countable) and $\tilde\Omega$ be such that $\Prob(\tilde{\Omega})=1$. We say that ${(X_t)}_{t\geq 0}$ is a \emph{jump process} if $\forall \omega \in \tilde{\Omega}$ and $\forall t\geq 0$, $\exists \varepsilon>0$ such that $X_t(\omega)=X_{s}(\omega)$ for all $s\in[t,t+\varepsilon)$.
  \end{definition}
  \begin{definition}
    Let ${(X_t)}_{t\geq 0}$ be a jump process. We say that the jump process is \emph{regular} if $\forall C>0$, the number of jumps of $X_{\cdot}(\omega)$ in $[0,C]$ is finite for all $\omega\in\Omega$.
  \end{definition}
  \begin{theorem}
    Let ${(X_t)}_{t\geq 0}$ be a CTHMC and a regular jump process. Then, $\forall i\in I$, $q_i<\infty$ and $q_i=\sum_{\substack{k\in I\\k\ne i}}q_{ik}$.
  \end{theorem}
  \begin{definition}
    Let ${(X_t)}_{t\geq 0}$ be a CTHMC. Then, ${(X_t)}_{t\geq 0}$ is said to be \emph{stable} if $\forall i\in I$, $q_i<\infty$, and is said to be \emph{conservative} if $\forall i\in I$, $q_i=\sum_{\substack{k\in I\\k\ne i}}q_{ik}$.
  \end{definition}
  \begin{theorem}
    Let ${(X_t)}_{t\geq 0}$ be a CTHMC and a regular jump process. Then, the two Kolmogorov odes are satisfied.
  \end{theorem}
  \subsubsection{Limit and stationary distributions}
  \begin{definition}
    Let ${(X_t)}_{t\geq 0}$ be a CTHMC. We say that $\vf{\overline{p}}$ is a \emph{stationary distribution} for ${(X_t)}_{t\geq 0}$ if $\overline{p}_i\geq 0$ $\forall i\in I$, $\sum_{i\in I}\overline{p}_i =1$ and $\vf{\overline{p}}\vf{P}(t)=\vf{\overline{p}}$ $\forall t\geq 0$.
  \end{definition}
  \begin{lemma}
    Let ${(X_t)}_{t\geq 0}$ be a CTHMC and a regular jump process. Then:
    $$
      {p_j}'(t)=\sum_{k\in I} q_{kj}p_k(t)
    $$
    In particular if we have a stationary distribution $\vf{\overline{p}}$, then $\vf{\overline{p}}\vf{Q}=0$, or equivalently:
    $$
      \sum_{\substack{k\in I\\k\ne j}}\overline{p}_kq_{kj}=\overline{p}_jq_j
    $$
    This equation is called \emph{balance equation}.
  \end{lemma}
  \begin{proof}
    $$
      p_j(t) = \Prob(X_t=j) = \sum_{i\in I} p_i(0)p_{ij}(t)
    $$
    A result allows us to differentiate term by term and rearrange the following series (because ${(X_t)}_{t\geq 0}$ is a regular jump process):
    \begin{multline*}
      {p_j}'(t) = \sum_{i\in I} p_i(0){p_{ij}}'(t) = \sum_{i\in I} p_i(0)\sum_{k\in I}p_{ik}(t)q_{kj}  = \\= \sum_{k\in I}q_{kj}\sum_{i\in I}p_i(0)p_{ik}(t)=\sum_{k\in I}q_{kj}p_k(t)
    \end{multline*}
    If we have a stationary distribution, then ${\overline{p}_j}' (t)=0$.
  \end{proof}
  \begin{remark}
    In the CTHMC there is no periodic behaviour as in the discrete case. Indeed, given $t>0$ and $\delta>0$ small enough, $\exists n\in\NN\cup\{0\}$ such that $t=n\delta +h$ with $h\in[0,\delta)$. And so:
    $$
      p_{ii}(t)\geq p_{ii}{(n\delta)} p_{ii}(h) \geq \cdots\geq {(p_{ii}(\delta))}^n p_{ii}(h)>0
    $$
    where the last inequality is due to the fact that $\displaystyle\lim_{h\to 0}p_{ii}(h)=1$.
  \end{remark}
  \begin{definition}
    Let ${(X_t)}_{t\geq 0}$ be a CTHMC. We say that the chain is \emph{irreducible} if $\forall i,j\in I$, $\exists t_1,t_2>0$ such that $p_{ij}(t_1)>0$ and $p_{ji}(t_2)>0$.
  \end{definition}
  \begin{theorem}\label{SP:limit_distribution}
    Let $X$ be an irreducible CTHMC and a regular jump process. Then, we have exactly one of the following:
    \begin{enumerate}
      \item The balance equation has a unique solution $\vf{\overline{p}}$ (which must be the stationary distribution) and $\displaystyle \lim_{t\to\infty}p_{ij}(t)=\overline{p}_j$ $\forall i,j\in I$. In that case, $\vf{\overline{p}}$ is called a \emph{limit distribution}.
      \item The balance equation has no solution and in that case $\displaystyle \lim_{t\to\infty}p_{ij}(t)=0$ $\forall i,j\in I$.
    \end{enumerate}
  \end{theorem}
  \begin{remark}
    Note that if $I$ is finite, we are always in the first case since we always need to have $\sum_{j\in I}p_{ij}(t)=1$.
  \end{remark}
  \subsubsection{Birth and death processes}
  \begin{definition}
    Let $I=\NN\cup\{0\}$. A \emph{birth and death process} is a CTHMC and a regular jump process with the following infinitesimal transition scheme:
    $$
      \begin{cases}
        p_{i,i+1}(h)=\lambda_i h+\o{h}       & i\geq 0          \\
        p_{i,i-1}(h)=\mu_i h+\o{h}           & i\geq 1          \\
        p_{ii}(h)=1-\lambda_ih+\o{h}         & i=0              \\
        p_{ii}(h)=1-(\lambda_i+\mu_i)h+\o{h} & i\geq 1          \\
        p_{ij} = \o{h}                       & \text{otherwise}
      \end{cases}
    $$
    This model describes a population of individuals, each of whom having $\lambda_i h + \o{h}$ probability of giving birth to a new individual in the time interval $[t,t+h)$ and $\mu_i h + \o{h}$ probability of dying in the same time interval. The probability of having more than one birth or death in that interval is $\o{h}$. In this case the infinitesimal generator is:
    $$
      \vf{Q}=\begin{pmatrix}
        -\lambda_0 & \lambda_0          & 0                  & 0         & \cdots \\
        \mu_1      & -(\lambda_1+\mu_1) & \lambda_1          & 0         & \cdots \\
        0          & \mu_2              & -(\lambda_2+\mu_2) & \lambda_2 & \cdots \\
        \vdots     & \vdots             & \vdots             & \ddots    & \ddots
      \end{pmatrix}
    $$
    If $\lambda_i=0$ $\forall i\in I$, then we said that the process is a \emph{pure death process}. If $\mu_i=0$ $\forall i\in I$, then we said that the process is a \emph{pure birth process}.
  \end{definition}
  \begin{proposition}
    The Poisson process is a birth and death process with $\lambda_i=\lambda$ and $\mu_i=0$ $\forall i\in I$.
  \end{proposition}
  \begin{theorem}
    Consider a birth and death process. Then, a limit distribution $\vf{\overline{p}}$ exists if $\lambda_i>0$ and $\mu_i>0$ $\forall i\in I$ and
    $$
      \sum_{i\in I}\frac{\lambda_0\lambda_1\cdots\lambda_{i-1}}{\mu_1\mu_2\cdots\mu_i}<\infty
    $$
    This distribution is given by:
    \begin{equation}\label{SP:limit_distribution_birth_death}
      \overline{p}_i=\frac{\lambda_0\lambda_1\cdots\lambda_{i-1}}{\mu_1\mu_2\cdots\mu_i}\overline{p}_0 \qquad i\geq 1
    \end{equation}
    with $\overline{p}_0=\left(1+\sum_{i\in I}\frac{\lambda_0\lambda_1\cdots\lambda_{i-1}}{\mu_1\mu_2\cdots\mu_i}\right)^{-1}$.
  \end{theorem}
  \begin{proof}
    First let's prove by induction that if $\vf{\overline{p}}$ is a stationary distribution, then the components are those of \mcref{SP:limit_distribution_birth_death}. Indeed, for $i=1$, using the balance equation we have $\lambda_0 \overline{p}_0=\mu_1\overline{p}_1$. Now, suppose that the hypothesis holds $\forall i\leq j$. Then, we have:
    \begin{align*}
      (\lambda_j+\mu_j) \overline{p}_j                                                      & = \lambda_{j-1}\overline{p}_{j-1}+\mu_{j+1}\overline{p}_{j+1}                                                      \\
      (\lambda_j+\mu_j) \frac{\lambda_0\cdots\lambda_{j-1}}{\mu_1\cdots\mu_j}\overline{p}_0 & = \lambda_{j-1}\frac{\lambda_0\cdots\lambda_{j-2}}{\mu_1\cdots\mu_{j-1}}\overline{p}_0+\mu_{j+1}\overline{p}_{j+1} \\
      \frac{\lambda_0\cdots\lambda_{j-1}\lambda_j}{\mu_1\cdots\mu_j}\overline{p}_0          & = \mu_{j+1}\overline{p}_{j+1}
    \end{align*}
    The first argument is determined from the condition $1=\sum_{i\in I} \overline{p}_i=\overline{p}_0+\overline{p}_0\sum_{i\in I}\frac{\lambda_0\lambda_1\cdots\lambda_{i-1}}{\mu_1\mu_2\cdots\mu_i}$. Now if we see that for $\lambda_i>0$ and $\mu_i>0$ $\forall i\in I$ the chain is irreducible, then the theorem will be proved by \mcref{SP:limit_distribution}. But this is clear because, for example if $i <j$ we have:
    \begin{align*}
      p_{ij}((j-i)h) & \geq p_{i,i+1}(h)p_{i+1,i+2}(h)\cdots p_{j-1,j}(h)              \\
                     & =\lambda_i\lambda_{i+1}\cdots\lambda_{j-1}h^{j-i}+\o{h^{j-i}}>0
    \end{align*}
    if $\lambda_i>0$ $\forall i\in I$ and for some $h$ small enough. The case $i>j$ is analogous.
  \end{proof}
  \begin{theorem}[Reuter criterion]
    Consider an infinitesimal generator for a birth and death process. Then,  there is a CTHMC of regular jumps with this infinitesimal generator if and only if:
    $$
      \sum_{n=1}^\infty \left[\frac{1}{\lambda_n}+\frac{\mu_n}{\lambda_n\lambda_{n-1}}+ \cdots+ \frac{\mu_n\cdots \mu_1}{\lambda_n\cdots\lambda_0}\right]=\infty
    $$
  \end{theorem}
  \subsection{Brownian motion}
  \subsubsection{Gaussian processes}
  \begin{proposition}\label{SP:Gaussian_vector}
    Let $\vf{x}\in \RR^n$ be a random vector. Then, $\vf{x}$ is a \emph{Gaussian vector}, that is it distributes as an $n$-dimensional normal, if and only if there exists $k\in\NN$, $\vf{A}\in\mathcal{M}_{n\times k}(\RR)$, $\vf{z}\in\RR^k$ with \iid components distributed as $N(0,1)$, and $\vf\mu\in\RR^n$ such that: $$\vf{x}=\vf{A}\vf{z}+\vf\mu$$
  \end{proposition}
  \begin{definition}
    A stochastic process ${(X_t)}_{t\geq 0}$ is called a \emph{Gaussian process} if for all $t_1,\ldots,t_n\geq 0$ the random vector $(X_{t_1},\ldots,X_{t_n})$ is Gaussian.
  \end{definition}
  \begin{definition}
    Let ${(X_t)}_{t\geq 0}$ be a Gaussian process.
    Then, the \emph{mean function} is defined as:
    $$
      \function{\mu}{[0,\infty)}{\RR}{t}{\Exp(X_t)=:\mu_t}
    $$
    and the \emph{covariance function} is defined as:
    $$
      \function{C}{[0,\infty)\times[0,\infty)}{\RR}{(s,t)}{\cov(X_s,X_t)=\Exp(X_sX_t)-\mu_s\mu_t}
    $$
  \end{definition}
  \subsubsection{Brownian motion}
  \begin{definition}
    A stochastic process ${(B_t)}_{t\geq 0}$ is called a \emph{Brownian motion} (or a \emph{Wiener process}) with parameter $\lambda$ if:
    \begin{enumerate}
      \item $B_0=0$.
      \item $B_t$ has independent increments.
      \item $B_t$ has stationary increments with distribution $B_t-B_s\sim N(0,\sigma^2(t-s))$ $\forall 0\leq s\leq t$ with $\sigma>0$.
      \item The trajectories $t\to B_t$ are continuous.
    \end{enumerate}
    The Brownian motion is said to be \emph{standard} if $\sigma=1$.
  \end{definition}
  \begin{proposition}
    Let $B:={(B_t)}_{t\geq 0}$ be a standard Brownian motion. Then, $B$ is a Gaussian process with mean function $\mu_t=0$ and covariance function $C(s,t)=\min(s,t)$.
  \end{proposition}
  \begin{proof}
    Let $0< t_1<\cdots<t_n$. We can write the vector $\vf{b}:=\transpose{(B_{t_1},\ldots,B_{t_n})}$ as:
    $$
      \vf{b}=\begin{pmatrix}
        1      & 0      & \cdots & 0      \\
        1      & \ddots & \ddots & \vdots \\
        \vdots & \ddots & 1      & 0      \\
        1      & \cdots & 1      & 1
      \end{pmatrix}
      \begin{pmatrix}
        B_{t_1}           \\
        B_{t_2} - B_{t_1} \\
        \vdots            \\
        B_{t_n} - B_{t_{n-1}}
      \end{pmatrix}
    $$
    And so $\vf{b}$ is Gaussian because is a linear combination of Gaussian. Now in the general, let $s_1, \ldots, s_n\geq 0$. We can write any vector $(B_{s_1}, \ldots, B_{s_n})$ as a linear transformation of the vector $(B_{t_1}, \ldots, B_{t_n})$ with $0< t_1<\cdots<t_n$. On the other hand, it is clear that $\mu_t=\Exp(B_t)=\Exp(B_t-B_0)=0$ and if $s\leq t$: $$\Exp(B_sB_t)=\Exp(B_s(B_t-B_s))+\Exp(B_s^2)=\mu_s\mu_{t-s}+s=s$$
  \end{proof}
  \begin{proposition}
    Let $B:={(B_t)}_{t\geq 0}$ be a Gaussian process with $B_0=0$, mean function $\mu_t=0$ and covariance function $C(s,t)=\min(s,t)$. Then, $B$ is a standard Brownian motion.
  \end{proposition}
  \begin{proof}
    Since Gaussian uncorrelated variables are independent, it suffices to show that the covariance matrix of $(B_{t_1}, B_{t_2}-B_{t_1}, \ldots, B_{t_n}-B_{t_{n-1}})$ is:
    $$
      \begin{pmatrix}
        t_1    & 0       & \cdots & 0            \\
        0      & t_2-t_1 & \ddots & \vdots       \\
        \vdots & \ddots  & \ddots & 0            \\
        0      & \cdots  & 0      & t_n- t_{n-1}
      \end{pmatrix}
    $$
    for all $0<t_1<\cdots<t_n$. On the one hand, if $t_i<t_j$, then $t_{i-1}<t_i\leq t_{j-1}<t_j$ and:
    \begin{multline*}
      \Exp((B_{t_i}-B_{t_{i-1}})(B_{t_j}-B_{t_{j-1}}))=\Exp(B_{t_i}B_{t_j})-\Exp(B_{t_i}B_{t_{j-1}})-\\-\Exp(B_{t_{i-1}}B_{t_j})+\Exp(B_{t_{i-1}}B_{t_{j-1}})=t_i-t_{i}-t_{i-1}+t_{i-1}=0
    \end{multline*}
    On the other hand:
    \begin{multline*}
      \Exp\left({(B_{t_i}-B_{t_{i-1}})}^2\right)= \Exp(B_{t_i}^2)-2\Exp(B_{t_i}B_{t_{i-1}})+\Exp(B_{t_{i-1}}^2)=\\=t_i-t_{i-1}
    \end{multline*}
  \end{proof}
  \begin{proposition}
    Let $B:={(B_t)}_{t\geq 0}$ be a standard Brownian motion. Then, the following stochastic processes are also standard Brownian motions:
    \begin{enumerate}
      \item $\forall c\in \RR^*$, ${(cB_{t/c^2})}_{t\geq 0}$
      \item ${(-B_t)}_{t\geq 0}$
      \item ${(B_{t+s}-B_s)}_{t\geq 0}$ for all $s\geq 0$.
      \item $$
              Y_t = \begin{cases}
                t B_{1/t} & \text{if } t>0 \\
                0         & \text{if } t=0
              \end{cases}
            $$
    \end{enumerate}
  \end{proposition}
  \begin{definition}
    Let ${(X_t)}_{t\in T}$ and ${(Y_t)}_{t\in T}$ be two stochastic processes. We say that ${(X_t)}_{t\in T}$ and ${(Y_t)}_{t\in T}$ are \emph{stochastically equivalent} if $\forall t\in T$ we have: $$\Prob(X_t=Y_t)=1$$ In that case we also say that ${(X_t)}_{t\in T}$ is a \emph{version} of ${(Y_t)}_{t\in T}$ (or viceversa). We say that ${(X_t)}_{t\in T}$ and ${(Y_t)}_{t\in T}$ are \emph{indistinguishable} if: $$
      \Prob(X_t=Y_t\ \forall t\in T)=1
    $$
  \end{definition}
  \begin{remark}
    Note that if the set $T$ is finite or countable, then the two notions are equivalent because:
    $$
      \Prob(X_t=Y_t\ \forall t\in T)=\Prob\left(\bigcap_{t\in T} \{X_t=Y_t\}\right)=1
    $$
  \end{remark}
  \begin{proposition}
    Let $({X_t})_{t\in T}$ and $({Y_t})_{t\in T}$ be equivalent stochastic processes. Then, $\forall n\in\NN$ and all $t_1,\ldots,t_n\in T$ we have:
    $$
      \vf{X}:=(X_{t_1},\ldots,X_{t_n})\overset{\mathrm{d}}{=} (Y_{t_1},\ldots,Y_{t_n})=:\vf{Y}
    $$
  \end{proposition}
  \begin{proof}
    Let $B\in\mathcal{B}(\RR^n)$ and $A:=\{ X_{t_i} = Y_{t_i}\ \forall i\}$. Using that $\Prob(A)=1$ we have:
    \begin{align*}
      \Prob(\vf{X}\in B) & =\Prob(\vf{X}\in B, A)+ \Prob(\vf{X}\in B, A^c) \\
                         & =\Prob(\vf{Y}\in B, A)+ 0                       \\
                         & =\Prob(\vf{Y}\in B, A)+ \Prob(\vf{Y}\in B, A^c) \\
                         & =\Prob(\vf{Y}\in B)
    \end{align*}
  \end{proof}
  \begin{corollary}
    Let $B$ be a standard Brownian motion and $\overline{B}$ be a version of $B$. Then, $\overline{B}$ is also a standard Brownian motion.
  \end{corollary}
  \begin{theorem}[Kolmogorov's continuity theorem]\label{SP:kolmogorov_continuity}
    Let ${(X_t)}_{t\geq 0}$ be a stochastic process such that $\exists \alpha,\beta, C>0$ such that:
    $$
      \Exp(\abs{X_t-X_s}^\alpha)\leq C\abs{t-s}^{1+\beta}
    $$
    for all $t,s\geq 0$. Then, there exists a version of ${(X_t)}_{t\geq 0}$ with continuous trajectories.
  \end{theorem}
  \begin{lemma}\label{SP:post_kolmo}
    Let $X\sim N(0,\sigma^2)$. Then, $\Exp(\abs{X}^n)=C_n\sigma^n$ where:
    $$
      C_n=\Exp(\abs{Z}^n)=\Gamma\left(\frac{n+1}{2}\right)\frac{2^{n/2}}{\sqrt{\pi}}
    $$
    and $Z\sim N(0,1)$.
  \end{lemma}
  \begin{corollary}
    Let $B:={(B_t)}_{t\geq 0}$ be a standard Brownian motion. Then, there exists a version of $B$ with continuous trajectories.
  \end{corollary}
  \begin{proof}
    We use \cref{SP:kolmogorov_continuity,SP:post_kolmo} with $\alpha=3$ and $\beta=1/2$.
  \end{proof}
  \begin{proposition}
    Let $B:= {(B_t)}_{t\geq 0}$ be a standard Brownian motion. Then, for any interval $[a,b]\subset \RR$:
    $$
      \Prob(\omega\in \Omega:B_\cdot(\omega)\text{ is monotone on }[a,b])=0
    $$
  \end{proposition}
  \begin{proof}
    Let $A=\{\omega\in\Omega:B_\cdot(\omega)\text{ is monotone on }[a,b]\}$. Using the density and continuity of $B$ we have:
    \begin{multline*}
      A=\{B_s\leq B_t:\forall s,t \in\QQ, a\leq s< t\leq b\}+  \\+ \{B_s\geq B_t:\forall s,t \in\QQ, a\leq s< t\leq b\}
    \end{multline*}
    Hence, given $n\in\NN$ and a partition ${\{t_i\}}_{0\leq i\leq n}$ of $[a,b]$ we have:
    \begin{multline*}
      A\subseteq \{ B_{t_i+1} - B_{t_i}\geq 0: i=0,\ldots,n-1\}+ \\ + \{ B_{t_i+1} - B_{t_i}\leq 0: i=0,\ldots,n-1\}
    \end{multline*}
    Therefore, using the independence of the increments of $B$ and the symmetry of the normal distribution we have:
    $$
      \Prob(A)\leq 2\prod_{i=0}^{n-1} \Prob(B_{t_{i+1}}-B_{t_i}\geq 0)=2{\left(\frac{1}{2}\right)}^n\overset{n\to \infty}{\longrightarrow} 0
    $$
  \end{proof}
  \begin{proposition}
    Let $B:= {(B_t)}_{t\geq 0}$ be a standard Brownian motion. Then, $\forall t\geq 0$ the set
    $$
      A:=\left\{\omega\in\Omega:\limsup_{h\to 0}\frac{\abs{B_{t+h}(\omega)-B_t(\omega)}}{h}=+\infty\right\}
    $$
    which may not belong in the $\sigma$-algebra, contains an event of probability $1$.
  \end{proposition}
  \begin{proof}
    Note that $A\supseteq \{\omega\in\Omega:\sup_{n\in\NN}\frac{\abs{B_{t+1/n}(\omega)-B_t(\omega)}}{1/n}=+\infty\}=\bigcap_{M\geq 1} A_{M}$ where:
    $$
      A_M:=\left\{\omega\in\Omega:\sup_{n\in\NN}\frac{\abs{B_{t+1/n}(\omega)-B_t(\omega)}}{1/n}\geq M\right\}
    $$
    If we see that $\Prob(A_M)=1$ for all $M\geq 1$ we are done.
    \begin{multline*}
      \Prob(A_M)\geq \Prob \left(\frac{\abs{B_{t+1/n}(\omega)-B_t(\omega)}}{1/n}\geq M\right) = \\ = \Prob\left(\abs{Z}\geq \frac{M}{\sqrt{n}}\right)=2 \left(1-\Phi\left(\frac{M}{\sqrt{n}}\right)\right)\overset{n\to\infty}{\longrightarrow} 1
    \end{multline*}
    where the first inequality holds $\forall n\in\NN$, $Z\sim N(0,1)$ and $\Phi$ is the cumulative distribution function of the standard normal distribution.
  \end{proof}
  \begin{theorem}[Paley-Wiener-Zygmund theorem]
    The Brownian trajectories are almost surely nowhere differentiable. Namely, the set
    \begin{multline*}
      \left\{
      \omega\in\Omega:\forall t\geq 0, \limsup_{h\to 0^+}\frac{{B_{t+h}(\omega)-B_t(\omega)}}{h}=+\infty\text{ or }\right.\\
      \left.\liminf_{h\to 0^+}\frac{{B_{t+h}(\omega)-B_t(\omega)}}{h}=-\infty
      \right\}
    \end{multline*}
    contains an event of probability $1$. And the same occurs for the left limit $h\to 0^-$ (in this case we need to exclude $t=0$).
  \end{theorem}
  \begin{figure}[H]
    \centering
    \includestandalone[mode=image|tex,width=0.75\linewidth]{Images/brownianMotion}
    \caption{A Brownian motion simulated with 7500 increments. Observe the ``non-differentiability'' of the path.}
    \label{fig:BrownianMotion}
  \end{figure}
  \begin{definition}
    Let $B$ be a standard Brownian motion and $a>0$. We define:
    $$
      \tau_a:=\inf\{t\geq 0:B_t\geq a\}
    $$
    If $a<0$ we define: $$\tau_a:=\inf\{t\geq 0:B_t\leq a\}$$
  \end{definition}
  \begin{remark}
    Note that if $\tau_a(\omega)<\infty$, then $B_{\tau_a(\omega)}(\omega)=a$ by the continuity of the trajectories.
  \end{remark}
  \begin{lemma}\label{SP:distrTauA}
    Let $B$ be a standard Brownian motion. Then, $\forall t\geq 0$ and $a>0$:
    $$
      \Prob(\tau_a\leq t)=\Prob\left(\max_{0\leq s\leq t}B_s\geq a\right)=2\Prob(B_t\geq a)
    $$
    If $a<0$ we have:
    $$
      \Prob(\tau_a\leq t)=\Prob\left(\min_{0\leq s\leq t}B_s\leq a\right)=2\Prob(B_t\leq a)
    $$
  \end{lemma}
  \begin{corollary}
    Let $B$ be a standard Brownian motion and $a\in\RR^*$. Then, $\Prob(\tau_a<\infty)=1$.
  \end{corollary}
  \begin{proof}
    Assume $a>0$, the other case is similar. Then:
    \begin{multline*}
      \Prob(\tau_a<\infty)=\Prob\left(\bigcup_{n=1}^\infty\{\tau_a\leq n\}\right)=\lim_{n\to\infty}\Prob(\tau_a\leq n)=\\
      =2\lim_{n\to\infty}\Prob(B_n\geq a)=2\lim_{n\to\infty}\left(1-\Phi\left(\frac{a}{\sqrt{n}}\right)\right)=1
    \end{multline*}
  \end{proof}
  \begin{proposition}
    Let $B$ be a standard Brownian motion. Then:
    $$
      \Prob\left(\sup_{t\geq 0}B_t=+\infty,\inf_{t\geq 0}B_t=-\infty\right)=1
    $$
  \end{proposition}
  \begin{proof}
    It suffices to prove only $\Prob(\sup_{t\geq 0}B_t=+\infty)=1$. Note that:
    $$
      \Prob\left(\sup_{t\geq 0}B_t=+\infty\right)=\Prob\left(\bigcap_{n=1}^\infty\left\{\sup_{t\geq 0}B_t\geq n\right\}\right)
    $$
    Let's see that all the events $A_n:=\{\sup_{t\geq 0}B_t\geq n\}$ in the intersection have probability 1:
    \begin{multline*}
      \Prob(A_n)\geq \Prob\left(\max_{0\leq t\leq s} B_t\geq n\right)=2\Prob(B_s\geq n)=\\=2\left(1-\Phi\left(\frac{n}{\sqrt{s}}\right)\right)\overset{s\to\infty}{\longrightarrow} 1
    \end{multline*}
  \end{proof}
  \begin{corollary}
    The Brownian trajectories have infinite zeros almost surely, and they tend to infinity.
  \end{corollary}
  \begin{proof}
    Let $B:=\{B_t:t\geq 0\}$ be a standard Brownian motion and let $A=\{\omega\in\Omega:B_{\cdot}(\omega)\text{ has finite zeros}\}\subseteq \bigcup_{n=1}^\infty\{\omega\in\Omega:B_{\cdot}(\omega)\text{ doesn't vanish in $[n,\infty)$}\}$. Let's see that all the events $A_n:=\{B_{\cdot}\text{ doesn't vanish in $[n,\infty)$}\}$ in the union have probability 0.
    \begin{multline*}
      \Prob(A_n)=\Prob(B_{\cdot}>0\text{ in $[n,\infty)$})+\Prob(B_{\cdot}<0\text{ in $[n,\infty)$})\leq\\\leq \Prob\left(\inf_{t\geq n}B_t\ne-\infty\right)+\Prob\left(\sup_{t\geq n}B_t\ne+\infty\right)=0
    \end{multline*}
  \end{proof}
  \begin{corollary}
    The Brownian trajectories pass through every point $a\in\RR$ infinitely many times almost surely.
  \end{corollary}
  \begin{proposition}
    Let $B$ be a standard Brownian motion. Then, $\forall h>0$:
    $$
      \Prob\left(\max_{0\leq t\leq h}B_t>0,\min_{0\leq t\leq h}B_t<0\right)=1
    $$
  \end{proposition}
  \begin{proof}
    It suffices to prove $\Prob\left(\max_{0\leq t\leq h}B_t>0\right)=1$. Let $a>0$. Then:
    \begin{multline*}
      \Prob\left(\max_{0\leq t\leq h}B_t>0\right)\geq \Prob\left(\max_{0\leq t\leq h}B_t>a\right) =2\Prob(B_h>a)=\\=2\left(1-\Phi\left(\frac{a}{\sqrt{h}}\right)\right)\overset{a\to 0}{\longrightarrow} 1
    \end{multline*}
  \end{proof}
  \begin{proposition}
    Let $B$ be a standard Brownian motion and $a\in\RR^*$. Then, $\Exp(\tau_a)=\infty$.
  \end{proposition}
  \begin{proof}
    Using the symmetry of the Brownian motion, we have:
    $$
      F_{\tau_a}(t)=\Prob(\tau_a\leq t) =2\Prob(B_t<-a) =\frac{2}{\sqrt{2\pi}}\int_{-\infty}^{-\frac{a}{\sqrt{t}}} e^{-\frac{x^2}{2}}\dd{x}
    $$
    and $F_{\tau_a}(0)=0$. An easy check of the hypothesis of \mcref{P:Fprime} shows that the density of $\tau_a$ is ${F_{\tau_a}}'$ and so:
    $$
      \Exp(\tau_a)=\frac{a}{\sqrt{2\pi}}\int_{0}^{\infty} \frac{e^{-\frac{a^2}{2t}}}{\sqrt{t}}\dd{t}=\infty
    $$
    because it diverges at $\infty$.
  \end{proof}
  \begin{definition}
    A \emph{$d$-dimensional standard Brownian motion} is a $d$-dimensional stochastic process $\vf{B}=(B^1,\dots,B^d)$ such that $\forall i\in\{1,\dots,d\}$, $B^i$ is a standard Brownian motion, and it is independent of the other components.
  \end{definition}
  \begin{theorem}
    Let $\vf{B}$ be a $d$-dimensional Brownian motion. Then:
    \begin{enumerate}
      \item If $d=2$, then $B$ is recurrent, that is $\forall \vf{x}\in\RR^2$ and $\forall \delta>0$ $\exists (\tau_n)\in\RR$, with $\displaystyle\lim_{n\to\infty} \tau_n=+\infty$, such that: $$\Prob(B_{\tau_n}\in B_\delta(\vf{x})\ \forall n\in\NN)=1$$ Here $B_\delta(\vf{x})$ denotes the open ball of radius $\delta$ centered at $\vf{x}$.
      \item If $d\geq 3$, then $B$ is transient, that is $\forall M>0$, $\exists T>0$ such that: $$\Prob(B_t\in B_M(\vf{0})\ \forall t\geq T)=0$$
    \end{enumerate}
  \end{theorem}
  \begin{theorem}[Law of the iterated logarithm]
    Let $B$ be a standard Brownian motion. Then:
    $$
      \limsup_{t\to\infty}\frac{B_t}{\sqrt{2t\log\log t}}\almoste{=}\liminf_{t\to\infty}\frac{B_t}{\sqrt{2t\log\log t}}\almoste{=}1
    $$
  \end{theorem}
  \begin{corollary}
    Let $B$ be a standard Brownian motion. Then:
    $$
      \limsup_{h\to 0} \frac{B_h}{\sqrt{2h\log\log\frac{1}{h}}}\almoste{=}\liminf_{h\to 0} \frac{B_h}{\sqrt{2h\log\log\frac{1}{h}}}\almoste{=}1
    $$
  \end{corollary}
  \begin{sproof}
    Recall that $xB_{1/x}$ is a standard Brownian motion.
  \end{sproof}
  \begin{proposition}
    Let $S_n=\sum_{i=1}^n X_i$ be a simple random walk with $\Prob(X_i=1)=\Prob(X_i=-1)=\frac{1}{2}$ and $B=(B_t)$ be a standard Brownian motion. We define the following sequence of stochastic processes:
    $$
      {Y_t^n}:=\frac{1}{\sqrt{n}}\left[S_{\floor{nt}}+(nt-\floor{nt})X_{\floor{nt}+1}\right]
    $$
    Then, $Y_t^n\overset{\mathrm{d}}{\longrightarrow} B_t$.
  \end{proposition}
  \subsubsection{Existence of Brownian motion}
  \begin{definition}[Finite-dimensional distributions]
    Let $(\Omega, \mathcal{A}, \Prob)$ be a probability space and $X: I\times\Omega\rightarrow (E,\mathcal{E})$ be a stochastic process. The \emph{finite-dimensional distributions} of $X$ are the probability measures $\Prob_{t_1,\dots,t_n}$ defined on $(E^n,\mathcal{E}^n)$ by:
    $$
      \Prob_{t_1,\dots,t_n}(B):=\Prob((X_{t_1},\dots,X_{t_n})\in B)
    $$
    for all $B\in\mathcal{E}^n$.
  \end{definition}
  \begin{lemma}
    Let $(\Omega, \mathcal{A}, \Prob)$ be a probability space and $X: I\times\Omega\rightarrow (E,\mathcal{E})$ be a stochastic process. Then, the finite-dimensional distributions satisfy the following \emph{consistency condition}:
    \begin{enumerate}
      \item For all $n\in\NN$, $t_1,\dots,t_n\in I$, $B_1,\dots,B_n\in\mathcal{E}$ and $\sigma\in\S_n$, we have:
            \begin{multline*}
              \Prob_{t_1,\dots,t_n}(B_1\times\dots\times B_n)=\\=\Prob_{t_{\sigma(1)},\dots,t_{\sigma(n)}}(B_{\sigma(1)}\times\dots\times B_{\sigma(n)})
            \end{multline*}
      \item  For all $n\in\NN$, $t_1,\dots,t_n\in I$ and $B_1,\dots,B_{n-1}\in\mathcal{E}$, we have:
            \begin{multline*}
              \Prob_{t_1,\dots,t_n}(B_1\times\dots\times B_{n-1}\times E)=\\=\Prob_{t_1,\dots,t_{n-1}}(B_1\times\dots\times B_{n-1})
            \end{multline*}
    \end{enumerate}
  \end{lemma}
  \begin{theorem}[Kolmogorov extension theorem]
    Let $I$ be a set and $\{\Prob_{t_1,\dots,t_n}:n\in\NN,t_1,\ldots,t_n\in I\}$ be a family of probabilities defined on $\mathcal{B}(\RR^n)$ satisfying the consistency conditions. Then, there exists a probability space $(\Omega, \mathcal{A}, \Prob)$ and a stochastic process $X: I\times\Omega\rightarrow (\RR,\mathcal{B}(\RR))$ such that $\Prob_{t_1,\dots,t_n}$ is the finite-dimensional distribution of $X$ for all $n\in\NN$ and $t_1,\dots,t_n\in I$.
  \end{theorem}
\end{multicols}
\end{document}