\documentclass[../../../main.tex]{subfiles}

\begin{document}
\begin{multicols}{2}[\section{Discrete mathematics}]
    \subsection{Generating functions and recurrence relations}
    \subsubsection*{Generating functions}
    \begin{definition}
        Let $(a_n)$ be a sequence of real numbers. We define its \textit{ordinary generating function} as the following formal power series: $$a_0+a_1x+a_2x^2+a_3x^3+\cdots=\sum_{n=0}^\infty a_nx^n$$
    \end{definition}
    \begin{prop}
        Let $\displaystyle\sum_{n=0}^\infty a_nx^n,\sum_{n=0}^\infty b_nx^n$ be two formal power series. Then:
        \begin{itemize}
            \item $\displaystyle\sum_{n=0}^\infty a_nx^n+\sum_{n=0}^\infty b_nx^n=\sum_{n=0}^\infty (a_n+b_n)x^n$
            \item $\displaystyle\lambda\sum_{n=0}^\infty a_nx^n=\sum_{n=0}^\infty\lambda a_nx^n$
            \item $\displaystyle\left(\sum_{n=0}^\infty a_nx^n\right)\left(\sum_{n=0}^\infty b_nx^n\right)=\sum_{n=0}^\infty (a_0b_n+a_1b_{n-1}+\cdots +a_nb_0)x^n$
            \item $\displaystyle\left(\sum_{n=0}^\infty a_nx^n\right)'=\sum_{n=1}^\infty na_nx^{n-1}$
        \end{itemize}
    \end{prop}
    \begin{prop}[Closed forms]
        We can write the following ordinary generating functions with their corresponding closed forms:
        \begin{itemize}
            \item $\displaystyle\sum_{n=0}^Nx^n=\frac{1-x^{N+1}}{1-x}$
            \item $\displaystyle\sum_{n=0}^\infty x^n=\frac{1}{1-x}$
            \item $\displaystyle\sum_{n=0}^\infty\binom{n+k-1}{n}x^n=\left(\frac{1}{1-x}\right)^k$
        \end{itemize}
    \end{prop}
    \begin{prop}
        Suppose $A$ and $B$ are two finite disjoint sets. We set some restrictions for the non-ordered selection of elements of $A\cup B$. For every $n\geq 0$, let:
        \begin{itemize}
            \item $a_n$ be the number of non-ordered selection of $n$ elements of $A$ satisfying the restrictions.
            \item $b_n$ be the number of non-ordered selection of $n$ elements of $B$ satisfying the restrictions.
            \item $c_n$ be the number of non-ordered selection of $n$ elements of $A\cup B$ satisfying the restrictions.
        \end{itemize}
        And let $f(x)$, $g(x)$, $h(x)$ be the ordinary generating functions of $(a_n)$, $(b_n)$, $(c_n)$, respectively. Then we have: $$h(x)=f(x)g(x)$$
    \end{prop}
    \begin{definition}
        Let $(a_n)$ be a sequence of real numbers. We define its \textit{exponential generating function} as the following formal power series: $$a_0+a_1x+a_2\frac{x^2}{2!}+a_3\frac{x^3}{3!}+\cdots=\sum_{n=0}^\infty a_n\frac{x^n}{n!}$$
    \end{definition}
    \begin{definition}
        Let $(a_n)$ be a sequence of real numbers such that $a_i=1$ $\forall i$. Then its exponential generating function associated is the so called \textit{exponential series}: $$\exp{x}=\sum_{n=0}^\infty \frac{x^n}{n!}$$
    \end{definition}
    \begin{prop}
        The exponential series has the following properties:
        \begin{enumerate}
            \item $\exp{x+y}=\exp{x}\exp{y}$ $\forall x,y\in\RR $.
            \item $(\exp{x})^n=\exp{nx}$ $\forall x,n\in\RR $.
        \end{enumerate}
    \end{prop}
    \begin{prop}
        Suppose $A$ and $B$ are two finite disjoint sets. We set some restrictions for the ordered selection of elements of $A\cup B$. For every $n\geq 0$, let:
        \begin{itemize}
            \item $a_n$ be the number of ordered selection of $n$ elements of $A$ satisfying the restrictions.
            \item $b_n$ be the number of ordered selection of $n$ elements of $B$ satisfying the restrictions.
            \item $c_n$ be the number of ordered selection of $n$ elements of $A\cup B$ satisfying the restrictions.
        \end{itemize}
        And let $f(x)$, $g(x)$, $h(x)$ be the exponential generating functions of $(a_n)$, $(b_n)$, $(c_n)$, respectively. Then we have: $$h(x)=f(x)g(x)$$
    \end{prop}
    \subsubsection*{Recurrence relations}
    \begin{definition}
        Let $(a_n)$ be a sequence of real numbers. A \textit{recurrence relation of order $k$ for $(a_n)$} is an expression that express $a_n$ in terms of $k$ consecutive terms of the sequence, $a_{n-1},\ldots,a_{n-k}$, for $k\leq n$. We say a sequence is \textit{recurrent} if it satisfies a recurrence relation or, equivalently, if it's a solution of the recurrence relation.
    \end{definition}
    \begin{definition}
        The \textit{initial values} of a recurrence relation of order $k$ are the values of the first $k$ terms for which the recurrence relation is still not valid, that is, the values $a_0,a_1,\ldots,a_{k-1}$.
    \end{definition}
    \begin{lemma}
        The solution of a recurrence relation of order $k$ with $k$ initial conditions is unique.
    \end{lemma}
    \begin{definition}
        A \textit{linear recurrence relation of order $k$} is a recurrence relation that can be written as the form: $$a_n+c_1a_{n-1}+\cdots c_ka_{n-k}=g(n)$$ where $c_1,\ldots c_k\in\RR , c_k\ne 0$ and $g:\NN \rightarrow\NN $ is an arbitrary function.
    \end{definition}
    \begin{definition}
        We say a linear recurrence relation is \textit{homogeneous} if $g(n)=0$, that is, if it's of the form: $$a_n+c_1a_{n-1}+\cdots c_ka_{n-k}=0\quad\text{with }c_k\ne 0$$
    \end{definition}
    \begin{prop}
        The general solution to a recurrence relation $$a_n+c_1a_{n-1}+\cdots c_ka_{n-k}=g(n)$$ can be expressed as: $$(a_n^\text{part})+(a_n^\text{hom}),$$ where $(a_n^\text{part})$ is a particular solution of the recurrence relation and $(a_n^\text{hom})$ is the general solution of its associated homogeneous recurrence relation.
    \end{prop}
    \begin{prop}
        Given $c_1,\ldots,c_k\in\RR $, the set of sequences that are solution of the homogeneous linear recurrence relation $a_n+c_1a_{n-1}+\cdots+c_ka_{n-k}=0$ form a real vector space.
    \end{prop}
    \begin{definition}
        Let $a_n+c_1a_{n-1}+\cdots+c_ka_{n-k}=0$ be a homogeneous linear recurrence relation of order $k$. The \textit{characteristic polynomial} of the recurrence is: $$x^k+c_1x^{k-1}+\cdots+c_k=0$$
    \end{definition}
    \begin{prop}
        Consider an homogeneous linear recurrence relation with characteristic polynomial $$(x-r_1)(x-r_2)\cdots(x-r_k)=0$$ where $r_1,\ldots,r_k\in\CC $ are different complex numbers. Then the general term of the sequences that satisfy the recurrence relation is: $$a_n=\lambda_1r_1^n+\cdots+\lambda_kr_k^n$$ for arbitrary numbers $\lambda_1,\ldots,\lambda_k\in\CC $.
    \end{prop}
    \subsection{Graph theory}
    \begin{definition}
        A \textit{graph} $G$ is an structure based on a set $V(G)$ of vertices and a set $E(G)$ of edges, which are non-ordered pairs of vertices.
    \end{definition}
    \begin{definition}
        Let $G$ be a graph. The \textit{order of $G$} is $n=|V(G)|$ and the \textit{size of $G$} is $m=|E(G)|$.
    \end{definition}
    \begin{definition}
        Let $G$ be a graph. Two vertices $a,b\in V(G)$ are said to be \textit{adjacent} to one another if exists an edge $e\in E(G)$ that connects them. In this case we say the edge $e$ is \textit{incident} on vertices $a$ and $b$.
    \end{definition}
    \begin{definition}
        An edge that connects a vertex with itself is called a \textit{loop}.
    \end{definition}
    \begin{definition}
        Two or more edges incidents with the same vertices are called \textit{multiple edges}.
    \end{definition}
    \begin{definition}
        A graph $G$ is \textit{finite} if $V(G)$ and $E(G)$ are finite.
    \end{definition}
    \begin{definition}
        A graph is \textit{simple} if it has neither multiples edges nor loops.
    \end{definition}
    \begin{definition}
        A \textit{complete graph} is a graph in which each pair of different vertices is joined by an edge. We denote by $K_n$ the complete graph of order $n$.
    \end{definition}
    \begin{definition}
        Let $G$ be a finite graph. The \textit{degree of a vertex} is the number of edges that are incident to it. If $v\in V(G)$ we denote the degree of $v$ by $\deg v$ or $\deg_Gv$\footnote{Observe that with this definition every loop counts as two edges.}.
    \end{definition}
    \begin{lemma}[Handshaking lemma]
        For every graph $G$ we have: $$\sum_{v\in V(G)}\deg v=2|E(G)|$$
    \end{lemma}
    \begin{corollary}
        In any graph, the number of odd-degree vertices is even.
    \end{corollary}
    \begin{definition}
        Let $G$ be a graph with $V(G)=\{v_1,\ldots,v_n\}$. The \textit{degree sequence of $G$} is the decreasing sequence: $$(\deg v_{i_1},\ldots,\deg v_{i_n})$$
    \end{definition}
    \begin{definition}
        We say a graph $G$ is \textit{$k$-regular} if $\deg v=k$ $\forall v\in V(G)$.
    \end{definition}
    \begin{definition}
        Let $G$ be a graph. A graph $F$ is an \textit{induced subgraph of $G$} if $V(F)\subseteq V(G)$ and $E(F)\subseteq E(G)$.
    \end{definition}
    \begin{definition}
        A \textit{walk of length $k$} in a graph $G$ is a sequence of vertices $(u_1,\ldots,u_k)$ where $u_iu_{i+1}\in E(G)$ for $i=1,\ldots,k-1$.
    \end{definition}
    \begin{definition}
        A walk in a graph is \textit{closed} if it starts and ends in the same vertex.
    \end{definition}
    \begin{definition}
        A walk in a graph is a \textit{trail} if all the edges of the walk are distinct.
    \end{definition}
    \begin{definition}
        A walk in a graph is a \textit{path} if all the vertices (and therefore the edges) of the walk are distinct.
    \end{definition}
    \begin{definition}
        A closed walk in a graph is a \textit{closed trail} if all the edges of the closed walk are distinct.
    \end{definition}
    \begin{definition}
        A closed path is called a \textit{cycle}.
    \end{definition}
    \begin{prop}
        Let $G$ be a graph. Given $u,v\in V(G)$, there exists a walk between $u$ and $v$ if and only if there exists a path between $u$ and $v$.
    \end{prop}
    \begin{definition}
        Let $G$ be a graph. Given $u,v\in V(G)$, we say that $u$ and $v$ are connected if there is a path in $G$ between $u$ and $v$.
    \end{definition}
    \begin{prop}
        The relation $u\sim v$ if and only if $u$ and $v$ are connected is an equivalence relation. The equivalent classes are the \textit{connected components of $G$}.
    \end{prop}
    \begin{definition}
        A graph $G$ is \textit{connected} if $\forall u,v\in V(G)$, $u$ and $v$ are connected.
    \end{definition}
    \begin{definition}
        A graph $G$ is \textit{bipartite} if $V(G)=X\sqcup Y$ and $\forall e\in E(G)$ we have $e=xy$ with $x\in X$ and $y\in Y$.
    \end{definition}
    \begin{definition}
        Let $G$ be a graph such that $E(G)\ne\varnothing$. Take an edge $e\in E(G)$. We denote by $G-e$ the induced graph of $G$ such that: $$V(G-e)=V(G)\quad\text{and}\quad E(G-e)=E(G)\setminus\{e\}$$
    \end{definition}
    \begin{definition}
        Given a connected graph $G$, we say that $e\in E(G)$ is a \textit{bridge of $G$} if $G-e$ is non-connected.
    \end{definition}
    \begin{prop}
        Let $G$ be a connected graph. $e\in E(G)$ is a bridge if and only if $e$ doesn't belong to any cycle of $G$.
    \end{prop}
    \begin{definition}
        Let $G$ be a connected graph. An \textit{Eulerian trail} in $G$ is a trail that contain all the edges of $G$. An \textit{Eulerian circuit} in $G$ is a closed Eulerian trail. $G$ is called \textit{Eulerian} if it admits an eulerian circuit.
    \end{definition}
    \begin{theorem}[Euler theorem]
        Let $G$ be a connected graph. $G$ is Eulerian $\iff\deg v=2k$ $\forall v\in V(G)$, $k\in\NN $.
    \end{theorem}
    \begin{definition}
        Let $G$ be a graph of order $n$ with $V(G)=\{v_1,\ldots,v_n\}$. We define the \textit{adjacency matrix of $G$}, $\mathblack{A}(G)\in\mathcal{M}_n(\RR )$, as $a_{ij}$ to be the number of edges incident with $v_i$ and $v_j$.
    \end{definition}
    \begin{prop}
        Let $G$ be a graph of order $n$ with $V(G)=\{v_1,\ldots,v_n\}$ and let $\mathblack{A}(G)=(a_{ij})$ be the adjacency matrix of $G$. Then:
        \begin{enumerate}
            \item $\mathblack{A}(G)$ is symmetric.
            \item $\displaystyle\sum_{j=1}^n a_{jk}=\sum_{j=1}^n a_{kj}=\deg v_k,\quad k=1,\ldots,n$.
            \item For $k\in\NN $, consider $\mathblack{A}(G)^k=(b_{ij}^k)$. Then $b_{ij}^k$ is equal to the number of walks of length $k$ between vertices $v_i$ and $v_j$.
        \end{enumerate}
    \end{prop}
    \begin{definition}
        A \textit{tree} is an acyclic connected graph, that is, a connected graph that has no cycles.
    \end{definition}
    \begin{definition}
        Let $T$ be a tree. A \textit{leave} of $T$ is a vertex of degree 1.
    \end{definition}
    \begin{definition}
        Let $G$ be a graph. A \textit{generator tree} is a induced subgraph $T$ of $G$ such that $|V(G)|=|V(T)|$ and $T$ is a tree.
    \end{definition}
    \begin{prop}
        Let $G$ be a graph such that $|V(G)|=n\geq 2$. The following are equivalent:
        \begin{enumerate}
            \item $G$ is a tree.
            \item $G$ is connected and every edge of $G$ is a bridge.
            \item $G$ is connected and $|E(G)|=n-1$.
            \item $G$ is acyclic and $|E(G)|=n-1$.
            \item For $v_i,v_j\in V(G)$, $i\ne j$, there exists a unique path between $v_i,v_j$.
            \item $G$ is acyclic but adding a new edge creates exactly one cycle.
        \end{enumerate}
    \end{prop}
    \begin{definition}
        Let $G$ be a connected graph. $G$ is called \textit{traversable} if admits an Eulerian trail.
    \end{definition}
    \begin{theorem}
        Let $G$ be a connected graph. $G$ is traversable if and only if $G$ has exactly to odd-degree vertices.
    \end{theorem}
    \begin{definition}
        Two graphs $G$, $H$ are said to be \textit{isomorphic} if exists a bijective map $f:V(G)\rightarrow V(H)$ such that $vv'\in E(G)\iff f(v)f(v')\in E(H)$.
    \end{definition}
    \begin{prop}
        Two finite isomorphic graphs have the same order, size and degree sequence.
    \end{prop}
    \begin{theorem}
        Two graphs $G$, $H$ are isomorphic if and only if exists a permutation matrix $\mathblack{P}$ such that: $$\mathblack{P}\mathblack{A}(G)\transpose{P}=\mathblack{A}(H)$$ where $\mathblack{A}(G)$, $\mathblack{A}(H)$ are adjacency matrices of $G$, $H$, respectively.
    \end{theorem}
    \subsection{Linear programming}
    \begin{definition}
        Given vectors $\mathblack{c},\mathblack{u},\mathblack{v}\in\RR ^n$, $\mathblack{b}\in\RR ^m$ and a matrix $\mathblack{A}\in\mathcal{M}_{m\times n}(\RR )$, we define the \textit{linear programming to maximize}\footnote{Analogously we can define a \textit{linear programming to minimize} changing the objective function to a minimize function.} as: $$\text{LP}=\left\{\begin{array}{rcl}
                \max:              & z=\transpose{c}x                       & \textit{(objective function)} \\
                \text{subject to}: & \mathblack{A}x\lesseqgtr \mathblack{b} & \textit{(restrictions)}       \\
                                   & \mathblack{u}\leq x\leq \mathblack{v}  &
            \end{array}\right.$$
    \end{definition}
    \begin{definition}
        Given vectors $\mathblack{c},\mathblack{u},\mathblack{v}\in\RR ^n$, $\mathblack{b}\in\RR ^m$ and a matrix $\mathblack{A}\in\mathcal{M}_{m\times n}(\RR )$, we define the \textit{canonical form of a linear programming to maximize} as: $$\text{LP}=\left\{\begin{array}{rcl}
                \max:              & z=\transpose{c}x                      & \textit{(objective function)} \\
                \text{subject to}: & \mathblack{A}x\leq \mathblack{b}      & \textit{(restrictions)}       \\
                                   & \mathblack{u}\leq x\leq \mathblack{v} &
            \end{array}\right.$$
        Analogously we define the \textit{canonical form of a linear programming to minimize} as: $$\text{LP}=\left\{\begin{array}{rc}
                \min:              & z=\transpose{c}x                      \\
                \text{subject to}: & \mathblack{A}x\geq \mathblack{b}      \\
                                   & \mathblack{u}\leq x\leq \mathblack{v}
            \end{array}\right.$$
    \end{definition}
    \begin{definition}
        Given a linear program, the \textit{feasible region} of the program is the set: $$\mathfrak{F}=\{x\in\RR ^n:\mathblack{A}x\lesseqgtr \mathblack{b},\mathblack{u}\leq x\leq \mathblack{v}\}$$ That is, the set of the points that satisfy the conditions of the problem.
    \end{definition}
    \begin{prop}
        Given an $x\in\RR ^n$, $x$ is a \textit{feasible solution} of the linear program if and only if $x\in\mathfrak{F}$.
    \end{prop}
    \begin{definition}
        A \textit{polyhedron} $P$ is a set of $\RR ^n$ that can be expressed as an intersection of a finite collection of half-spaces, that is: $$P=\{x\in\RR ^n:\mathblack{A}x\geq \mathblack{b}, \mathblack{A}\in\mathcal{M}_{m\times n}(\RR ),\mathblack{b}\in\RR ^m\}$$ A \textit{polytope} is a non-empty and bounded polyhedron. The feasible region of any linear program is a polyhedron.
    \end{definition}
    \begin{definition}
        Let $P\subset\RR ^n$ be a polyhedron. A point $x\in\RR ^n$ is an extreme point of $P$ if there is neither a pair of points $y,z\in P$, nor a scalar $\lambda\in[0,1]$ such that $x=\lambda y+(1-\lambda)z$.
    \end{definition}
    \begin{definition}
        Let LP be a linear program. We define the \textit{standard form of LP} as:
        $$\text{LP}=\left\{
            \begin{array}{rc}
                \min:              & z=\transpose{c}x             \\
                \text{subject to}: & \mathblack{A}x=\mathblack{b} \\
                                   & x\geq 0
            \end{array}\right.$$
    \end{definition}
    \begin{definition}
        Let $\displaystyle \text{LP}=\min_{x\in\RR ^n}\{\transpose{c}x:\mathblack{A}x=\mathblack{b},x\geq 0\}$. Feasible solution in which free variables or non-basic variable equal zero with respect to basis of basic variables are called \textit{basic feasible solutions}.
    \end{definition}
    \begin{prop}
        If a linear program admits feasible solutions, exists a basic feasible solution. If a linear program admits an optimal solution, exists an optimal basic feasible solution.
    \end{prop}
    \begin{theorem}
        Let $P$ be a non-empty polyhedron of a linear program in standard form with maximum rank and let $x\in P$. Then $x$ is an extreme point of $P$ if and only if $x$ is a basic feasible solution.
    \end{theorem}
    \begin{definition}[Simplex method: Phase I]
        Given a linear program in standard form:
        $$\text{LP}=\left\{
            \begin{array}{rc}
                \min:              & z=\transpose{c}x             \\
                \text{subject to}: & \mathblack{A}x=\mathblack{b} \\
                                   & x\geq 0
            \end{array}\right.$$ its associated problem in phase I ($\text{LP}_1$) is: $$\text{LP}_1=\left\{\begin{array}{rc}
                \min:              & \displaystyle w=\sum_{i=1}^my_i               \\
                \text{subject to}: & \mathblack{A}x+\mathblack{I}_my=\mathblack{b} \\
                                   & x,y\geq 0
            \end{array}\right.$$
        A condition necessary for LP having basic feasible solutions is that the optimal solution of $\text{LP}_1$ must be $w=0$. In fact, if $w\ne 0$, then the original linear program has no feasible solutions\footnote{This phase is useful to find, if there is, an initial basic feasible solution.}.
    \end{definition}
    \begin{prop}[Simplex method: Phase II]
        Suppose in a simplex table with positive pivots and therefore independent-terms vector $\mathblack{d}\geq 0$, there is a coefficient $c_j<0$. $$\left(\begin{array}{c|c}
                    *             & \transpose{d} \\
                    \hline
                    \mathblack{c} & z-z_0
                \end{array}\right)$$
    \end{prop}
    To find a basic feasible solution with lower cost, we make the following change of variable:
    \begin{enumerate}
        \item The variable in column $j$ becomes a basic variable.
        \item The variable in row $i$ such that: $$\frac{d_i}{a_{ij}}=\min\left\{\frac{d_k}{a_{kj}}:a_{kj}>0\right\}$$ becomes a non-basic variable. If this variable does not exists, that is, $a_{kj}\leq0$ $\forall k$ then the linear program is not bounded.
    \end{enumerate}
    \begin{definition}
        Let $\text{LP}=\displaystyle\min_{x\in\RR ^n}\{\transpose{c}x:\mathblack{A}x\geq \mathblack{b},x\geq 0\}$. We define the \textit{dual program of LP} as: $$\text{LP}^*=\left\{
            \begin{array}{rc}
                \max:              & z=\transpose{b}y                 \\
                \text{subject to}: & \transpose{A}y\leq \mathblack{c} \\
                                   & y\geq 0
            \end{array}\right.$$ The linear program LP is called \textit{primal}.
    \end{definition}
    \begin{theorem}[Weak duality theorem]
        Let $x$ be a feasible solution of the primal linear program and $y$ a feasible solution of the dual linear program. Then we have:
        \begin{itemize}
            \item $\transpose{c}x\leq \transpose{d}y$ if the primal linear program is in canonical form to maximize.
            \item $\transpose{c}x\geq \transpose{d}y$ if the primal linear program is in canonical form to minimize.
        \end{itemize}
    \end{theorem}
    \begin{corollary}
        Let $x$, $y$ be feasible solutions of the primal and dual linear programs respectively such that $\transpose{c}x=\transpose{d}y$. Then $x$ and $y$ are optimal solutions.
    \end{corollary}
    \begin{theorem}[Strong duality theorem]
        Any linear program has an optimal solution if and only if its dual linear program does, and in this case, the values coincide.
    \end{theorem}
    \begin{theorem}[Complementary property]
        Suppose that the optimal table of the primal linear program is of the form:
        $$\left(
            \begin{array}{@{\,} c|c @{\,}}
                    *             & \transpose{d} \\
                    \hline
                    \mathblack{c} & z-z_0         \\
                \end{array}\right)$$ where $\mathblack{c}=(c_1,\ldots,c_{n+m})$ and $\mathblack{d}=(d_1,\ldots,d_m)$ with $c_i\geq0$, $i=1,\ldots,n+m$. If $(y_1,\ldots y_m,t_1^*,\ldots,t_n^*)$ is the optimal solution of the dual linear program, expressed in standard form, then: $$c_1=t_1^*,\ldots,c_n=t_n^*, c_{n+1}=y_1,\ldots,c_{n+m}=y_m$$
    \end{theorem}
\end{multicols}
\end{document}